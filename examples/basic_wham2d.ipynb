{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the basic usage of ThermoLIB to construct a 2D free energy profile from umbrella sampling simulations with 2D bias potentials using the WHAM methodology, including error estimation from the theory of the maximum likelihood estimator (MLE). We will also illustrate how we can project the 2D FES onto a 1D FEP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'type' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthermolib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthermodynamics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FreeEnergySurface2D, SimpleFreeEnergyProfile\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthermolib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthermodynamics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Histogram2D\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthermolib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_wham_input, decorrelate\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/thermolib/__init__.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#! /usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Van Speybroeck. Usage of this package should be authorized by prof. Van\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Van Speybroeck.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkinetics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mthermodynamics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/thermolib/kinetics/__init__.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#! /usr/bin/env python\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Van Speybroeck. Usage of this package should be authorized by prof. Van\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Van Speybroeck.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/thermolib/kinetics/rate.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmolmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminimizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_delta\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmolmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munit_cells\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnitCell\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m blav, h5_read_dataset\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merror\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianDistribution, LogGaussianDistribution, Propagator\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/thermolib/tools.py:502\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    499\u001b[0m     lmax \u001b[38;5;241m=\u001b[39m lmax[[i\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(s[lmax[i:i\u001b[38;5;241m+\u001b[39mdmax]]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(lmax),dmax)]]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lmin,lmax\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_blav\u001b[39m(data: np\u001b[38;5;241m.\u001b[39mndarray, blocksizes: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fitrange: \u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, np\u001b[38;5;241m.\u001b[39minf], model_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03m        Routine to implement block averaging in order to estimate the correlated error bar on the average of the data series as well as the corresponding integrated correlation time. This proceeds as follows:\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;124;03m        - The correlation time (`corrtime`) represents the characteristic time scale of the correlations in the original sample data.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m#define model function for naive errors if not specified\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'type' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "from thermolib.thermodynamics.fep import FreeEnergySurface2D, SimpleFreeEnergyProfile\n",
    "from thermolib.thermodynamics.histogram import Histogram2D\n",
    "from thermolib.tools import read_wham_input, decorrelate\n",
    "from thermolib.thermodynamics.trajectory import ColVarReader\n",
    "\n",
    "import numpy as np, matplotlib.pyplot as pp, time\n",
    "\n",
    "from molmod.units import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some file/path variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'basic_wham2d_' #will be added to all figures made in this notebook\n",
    "fn_meta = 'data/HZSM5_link/wham_input_2D.txt' #location of the plumed metadata file containing all information of the umbrella sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basic WHAM application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read the input trajectories and define the corresponding bias potentials of each biased simulations included in the metadata file. This is done using the ``read_wham_input`` routine in the code block below. Assuming a metadata file with lines in the form of:\n",
    "\n",
    "    U14 2.85 -1.4 2000.0 1000.0\n",
    "\n",
    "we interpret the metadata file using the keywords of the ``read_wham_input`` routine below as follows. A simulation was done with a 2D bias potential of type ``'Parabola2D'`` centered around ``Q01 = 2.85`` and ``Q02 = -1.4`` and with strengths ``kappa1 = 2000.0`` and ``kappa2 = 1000.0``  was given the label ``u14``. In the code block below, we define the unit of ``Q01`` and ``Q02`` both as ``au`` and those of ``kappa1`` and ``kappa2`` both as ``kjmol``. Furthermore, the corresponding trajectory of Q values during this simulation is stored in a file with path ``colvars/COLVAR_U14.dat`` relative to the metadata file directory. This file is then read by ``colvar_reader`` which is an instance of ``ColVarReader`` class and assumes the file to be a colvar file that stores the values of Q1 and in columns ``1`` and ``2`` respectively of a numpy file, both in units ``au``. Finally, the temperature is also read from the metadata file from the line (usually the first line) that starts with ``T``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "colvar_reader = ColVarReader([1,2], units=['au','au'], verbose=True)\n",
    "temp, biasses, trajectories = read_wham_input(\n",
    "    fn_meta, colvar_reader, 'colvars/colvar_%s.dat', \n",
    "    bias_potential='Parabola2D', q01_unit='au', q02_unit='au', kappa1_unit='kjmol', kappa2_unit='kjmol',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output for the ``read_wham_input`` routine shows (at least if the keyword ``verbose`` is set to ``True``) for each simulation from which file the CV data is read, how many samples are in that simulation as well as which bias potential is used. Next, we construct the 2D probability histogram on the given 2D CV grid (defined by ``bins1`` and ``bins2``) using the WHAM routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "bins = [np.arange(1,4.025,0.025), np.arange(-2.5,0.025,0.025)]\n",
    "hist = Histogram2D.from_wham(bins, trajectories, biasses, temp, verbosity='medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the histogram, we can construct the corresponding free energy profile. We assume the profile contains a single transition state maximum within the Q-range of ``[-0.2,0.2]``, and a reactant state minimum for lower Q value and product state minimum for higher Q value. This is encoded in the class ``SimpleFreeEnergyProfile``. We then also define the energy reference by setting the reactant state minimum to zero and plot the resulting profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fes = FreeEnergySurface2D.from_histogram(hist, temp)\n",
    "fes.set_ref(ref='min')\n",
    "fes.plot(cmap='rainbow', flims=[0,130], ncolors=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection onto 1D profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Along predefined direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to project the 2D FES in terms of CV1 and CV2 onto a 1D FEP in terms of a single Q, for which we can choose different forms. However, based on how the 2D FES looks like, the only choices for Q that makes sense (i.e. Q is able to distinguish between reactant, transition state and product), is projecting onto Q=CV1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_cv1 = fes.project_cv1(return_class=SimpleFreeEnergyProfile)\n",
    "fep_cv1.process_states(lims=[-np.inf,2.4,3.0,np.inf])\n",
    "fep_cv1.set_ref(ref='r')\n",
    "fep_cv1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Along any custom direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above projection used a predefined direction of projection, i.e. onto CV1. However, we can define and perform a projection onto any preferred direction using the ``project_function`` routine of the ``FreeEnergySurface2D`` class. To illustrate how this routine works, we first reproduce the projection onto CV1, but using the custom direction approach. Afterwards, we project onto a more exotic direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce project_cv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The routine ``project_function`` simply requires a function of the form $f(CV_1,CV_2)$ to defined the direction of projection, i.e. it will construct a free energy profile in terms of the collective variable $Q=f(CV_1,CV_2)$. In case we want to project onto CV1, we simply need to choose $f(CV_1,CV_2)=CV_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(cv1,cv2):\n",
    "    return cv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, the ``project_function`` routine needs one additional argument, i.e. the grid of the new CV to project on. As the resulting FEP depends on the chosen grid, for the purpose of reproduction, I chose the grid of Q=CV1 identical to the one determined automatically by the ``project_cv1`` routine previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = fep_cv1.cvs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_cv1_bis = fes.project_function(function, cvs, return_class=SimpleFreeEnergyProfile)\n",
    "fep_cv1_bis.process_states(lims=[-np.inf,2.4,3.0,np.inf])\n",
    "fep_cv1_bis.set_ref(ref='r')\n",
    "fep_cv1_bis.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we get exactly the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More exotic projection direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we go on to a more exotic direction of projection:\n",
    "\n",
    "$f(CV_1,CV_2) = \\sqrt{(CV1-1.6)^2 + (CV2+1.4)^2} - \\sqrt{(CV1-3.6)^2 + (CV2+0.8)^2}$\n",
    "\n",
    "which could be interpreted as the difference in 'distance' between the reactant and product state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(cv1,cv2):\n",
    "    dR = np.sqrt((cv1-1.6)**2 + (cv2+1.2)**2)\n",
    "    dP = np.sqrt((cv1-3.6)**2 + (cv2+0.8)**2)\n",
    "    return dR-dP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always visualize the projection direction by plotting the contours of the chosen function $f(CV_1,CV_2)$ on top of the 2D FES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fes.plot(plot_additional_function_contours=[function, [-2.0, -1.5, -0.5, 0, 0.5, 1.5, 2.0]], cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_fun = fes.project_function(function, np.arange(-2.20,2.25,0.05), delta=0.05, return_class=SimpleFreeEnergyProfile)\n",
    "fep_fun.process_states(lims=[-np.inf,0.0,1.0,np.inf])\n",
    "fep_fun.set_ref(ref='r')\n",
    "fep_fun.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With error estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now redo the above procedure of construction of the 2D FES and projection onto CV1 including and MLE-F error estimation. However, we therefore, first require the correlation times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrtimes_2d = decorrelate(trajectories, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now estimate the 2D FES with error. However, we specify an additional parameter, `error_p_thresshold=0.0001`. This means that a certain bin is deactivated (i.e. excluded from histogram construction) if there is not a single simulation for which the (biased) probability in that bin is above the thresshold. This is to avoid that along the edges of the sampled region, we find bins with a high free energy but an error on the free energy equal to or larger than the free energy. These points indeed need to be avoided because otherwise many random samples will be generated that have (wrongly) associated a very low free energy to those edge points (which should be high in free energy). Such behavior would lead to large (but wrong) fluctuations in propagated observables (such as the projected free energy profile in this example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [np.arange(1,4.025,0.025), np.arange(-2.5,0.025,0.025)]\n",
    "hist_err = Histogram2D.from_wham(bins, trajectories, biasses, temp, error_estimate='mle_f_cov', corrtimes=corrtimes_2d, Nscf=10000, error_p_threshold=0.0001, verbosity='medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fes_err = FreeEnergySurface2D.from_histogram(hist_err, temp)\n",
    "fes_err.set_ref(ref='min')\n",
    "fes_err.plot(obss=['error-lower', 'error-mean', 'error-upper', 'error-half-upper-lower'], cmap='rainbow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_cv1_err = fes_err.project_cv1(return_class=SimpleFreeEnergyProfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_cv1_err.process_states(lims=[-np.inf,2.6,3.0,np.inf])\n",
    "fep_cv1_err.set_ref(ref='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_cv1_err.plot(flims=[-30,120])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last step (projection, processing states) takes some more time now because of the error propagation that is requires. Furthermore, we see that error on the 1D FEP is relatively large and more peculiar, the microstates for the reactant and product minima (the red squares on the graph on the bottom left and right) have a particular large error bar and fall on the edge (reactant) or even outside (product) the error bar of the profile. This is because various random profiles of the FEP give rise to minima at largely varying positions, which could be understood in terms of multiple large yet separated downward spikes in the FEP error. For example in the product state, we have to spikes going down all the way to 0 kjmol, one at approx 3.55 and one at approx 3.9. So upon taking random samples of the FEP (which is done for error propagation of the FEP error towards the microstate minima and maxima errors), there will be some of them with a min at 3.55 and some of them at a 3.9, which on average will give rise to a minimum located in between."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6035c5c19054a81448179272e55352f2864f929f76fb7fd7f7119786402a08c9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
