{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thermolib.thermodynamics.fep import BaseFreeEnergyProfile, plot_feps\n",
    "from thermolib.thermodynamics.histogram import Histogram1D,plot_histograms\n",
    "from thermolib.tools import read_wham_input, blav\n",
    "\n",
    "import numpy as np, matplotlib.pyplot as pp\n",
    "\n",
    "from molmod.units import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# WHAM with error estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Comparison with external WHAM script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define parabolic bias potentials and read corresponding trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature set at 573.000000\n",
      "Added bias potential nr. 1 (Parabola with kappa = 500.000 kjmol , q0 = -8.000e-01 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U1.dat\n",
      "Added bias potential nr. 2 (Parabola with kappa = 1000.000 kjmol , q0 = -6.000e-01 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U2.dat\n",
      "Added bias potential nr. 3 (Parabola with kappa = 1000.000 kjmol , q0 = -4.000e-01 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U3.dat\n",
      "Added bias potential nr. 4 (Parabola with kappa = 1000.000 kjmol , q0 = -2.000e-01 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U4.dat\n",
      "Added bias potential nr. 5 (Parabola with kappa = 1000.000 kjmol , q0 = 0.000e+00 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U5.dat\n",
      "Added bias potential nr. 6 (Parabola with kappa = 1000.000 kjmol , q0 = 2.000e-01 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U6.dat\n",
      "Added bias potential nr. 7 (Parabola with kappa = 1000.000 kjmol , q0 = 4.000e-01 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U7.dat\n",
      "Added bias potential nr. 8 (Parabola with kappa = 1000.000 kjmol , q0 = 6.000e-01 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U8.dat\n",
      "Added bias potential nr. 9 (Parabola with kappa = 500.000 kjmol , q0 = 8.000e-01 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U9.dat\n",
      "Added bias potential nr. 10 (Parabola with kappa = 500.000 kjmol , q0 = 1.000e+00 au)\n",
      "Read corresponding trajectory data from /home/louis/hpc/data/shared/massimo/for_Louis/colvar_U10.dat\n"
     ]
    }
   ],
   "source": [
    "#read temperature and bias potentials from wham_input.txt file\n",
    "fn = '/home/louis/hpc/data/shared/massimo/for_Louis/wham_input.txt'\n",
    "temp, biasses, trajectories = read_wham_input(fn, path_template_colvar_fns='colvar_%s.dat', kappa_unit='kjmol', q0_unit='au', stride=10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do WHAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "bins = np.arange(-1.2, 1.42, 0.02)\n",
    "hist_p = Histogram1D.from_wham(bins, trajectories, biasses, temp, error_estimate='mle_p', Nscf=1000, convergence=1e-6, verbose=False)\n",
    "hist_f = Histogram1D.from_wham(bins, trajectories, biasses, temp, error_estimate='mle_f', Nscf=1000, convergence=1e-6, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct and plot free energy profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_p = BaseFreeEnergyProfile.from_histogram(hist_p, temp=temp)\n",
    "fep_p.set_ref(ref='min')\n",
    "fep_f = BaseFreeEnergyProfile.from_histogram(hist_f, temp=temp)\n",
    "fep_f.set_ref(ref='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with free energy profile generated by external wham script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_ext = BaseFreeEnergyProfile.from_txt('/home/louis/hpc/data/shared/massimo/for_Louis/fes.dat', temp, cvcol=0, fcol=1, cv_unit='au', f_unit='kjmol')\n",
    "fep_ext.set_ref(ref='min')\n",
    "#fep_ext.plot('fep_US_external.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feps('fep_US_compare_error.png', [fep_p,fep_f,fep_ext], labels=['ThermoLIB (mle-p)', 'ThermoLIB (mle-f)', 'WHAMscript'], colors=[None,None,'0.3'], temp=temp, flim=140*kjmol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ext = Histogram1D.from_fep(fep_ext, temp=temp)\n",
    "hist_p.ps/max(hist_p.ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Comparison single histogram method for 'unbiases' simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will apply the WHAM reconstruction to a single unbiased simulation and compare the free energy profile and its error with the direct construction of the single histogram implemented in ThermoLIB. To apply the WHAM reconstructio to a single simulation, we are going to split the simulation into 10 subsequent trajectories and apply WHAM with zero-values biasses.\n",
    "\n",
    "However, for the input data we will use the simulation trajectory of a single umbrella from the umbrella simulation above. Even though this simulation was biases, it doesn't matter for the purpose at hand, i.e. we will suppose it is not biased at all but represents the equilibrium simulation of some system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_single = '/home/louis/hpc/data/shared/massimo/for_Louis/colvar_U8.dat'\n",
    "traj_single = np.loadtxt(fn_single)[:,1]\n",
    "bins = np.arange(0.4, 1.11, 0.01)\n",
    "temp = 573*kelvin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct histogram construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_single = Histogram1D.from_single_trajectory(traj_single, bins, error_estimate='mle_p')\n",
    "fep_single = BaseFreeEnergyProfile.from_histogram(hist_single, temp=temp)\n",
    "fep_single.set_ref(ref='min')\n",
    "#fep_single.plot('fep_single_direct.png', flim=35*kjmol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WHAM 'reconstruction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 'trajectories' and 'biases' of pseudo umbrellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nblocks = 5\n",
    "trajectories = [None,]*nblocks\n",
    "biasses = [None,]*nblocks\n",
    "len_block = len(traj_single)//nblocks\n",
    "for iblock in range(nblocks):\n",
    "    block = traj_single[iblock*len_block:(iblock+1)*len_block]\n",
    "    trajectories[iblock] = block\n",
    "    biasses[iblock] = lambda q: np.zeros(len(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_wham = Histogram1D.from_wham(bins, trajectories, biasses, temp, error_estimate='mle_p', plower_lim=1e-60, Nscf=1000, convergence=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fep_wham = BaseFreeEnergyProfile.from_histogram(hist_wham, temp=temp)\n",
    "fep_wham.set_ref(ref='min')\n",
    "#fep_wham.plot('fep_single_wham.png', flim=35*kjmol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feps('fep_single_compare_error.png', [fep_single,fep_wham], labels=['single','WHAM'], flim=35*kjmol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impact correlation on WHAM reconstuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/home/louis/hpc/data/shared/massimo/for_Louis/wham_input.txt'\n",
    "bins = np.arange(-1.2, 1.42, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, biasses, trajectories_1 = read_wham_input(fn, kappa_unit='kjmol', q0_unit='au', stride=1)\n",
    "hist_1 = Histogram1D.from_wham(bins, trajectories_1, biasses, temp, error_estimate='mle_p', plower_lim=1e-60, Nscf=1000, convergence=1e-6)\n",
    "fep_1 = BaseFreeEnergyProfile.from_histogram(hist_1, temp=temp)\n",
    "fep_1.set_ref(ref='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, biasses, trajectories_100 = read_wham_input(fn, kappa_unit='kjmol', q0_unit='au', stride=100)\n",
    "hist_100 = Histogram1D.from_wham(bins, trajectories_100, biasses, temp, error_estimate='mle_p', plower_lim=1e-60, Nscf=1000, convergence=1e-6)\n",
    "fep_100 = BaseFreeEnergyProfile.from_histogram(hist_100, temp=temp)\n",
    "fep_100.set_ref(ref='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feps('fep_US_correlation.png', [fep_100,fep_1], labels=['stride=100', 'stride=1'], flim=140*kjmol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we try to estimate the correlation time from block averaging of the collective variable itself during the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, error, corrtime = blav(trajectories[1][::1], blocksizes=np.arange(1,5000,1), fn_plot='trajectory_U2blav.png', plot_ac=True, ac_range=np.arange(0,5000,1), acft_plot_range=[0,0.1])\n",
    "print('Correlation time = %.3f timesteps' %corrtime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute the WHAM profile 10 times, each time with trajectories at 1 in 100 sub sampling but shifted over 10 steps with respect to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = '/home/louis/hpc/data/shared/massimo/for_Louis/wham_input.txt'\n",
    "bins = np.arange(-1.2, 1.42, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histograms = []\n",
    "for start in np.arange(0,100,10):\n",
    "    print(\"Constructing WHAM FEP for start=%i\" %start)\n",
    "    temp, biasses, trajectories = read_wham_input(fn, kappa_unit='kjmol', q0_unit='au', start=start, stride=100)\n",
    "    hist = Histogram1D.from_wham(bins, trajectories, biasses, temp)\n",
    "    histograms.append(hist)\n",
    "hist = Histogram1D.from_average(histograms, error_estimate='std')\n",
    "plot_histograms('histograms_US_correlation_2.png', [hist]+histograms, labels=['Average']+['start=%i' %i for i in np.arange(0,100,10)], temp=temp, flim=140*kjmol,\n",
    "               colors    =['k']+[None,]*10,\n",
    "               linewidths=[2  ]+[1   ,]*10,\n",
    "               linestyles=['-']+['--',]*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now devide the original data in 5 subsequent blocks and compute the WHAM FEP for each block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nblocks = 5\n",
    "blocksize = 10000\n",
    "histograms = []\n",
    "labels = []\n",
    "for iblock in range(nblocks):\n",
    "    start, end = iblock*blocksize, (iblock+1)*blocksize\n",
    "    print(\"Constructing histogram for block [%i,%i]\" %(start,end))\n",
    "    temp, biasses, trajectories = read_wham_input(fn, kappa_unit='kjmol', q0_unit='au', start=start, end=end, stride=1)\n",
    "    hist = Histogram1D.from_wham(bins, trajectories, biasses, temp)\n",
    "    histograms.append(hist)\n",
    "    labels.append(\"Block[%i,%i]\"%(start,end))\n",
    "hist_blockavg = Histogram1D.from_average(histograms, error_estimate='std', nsigma=2)\n",
    "plot_histograms('histogram_US_correaltion_3.png', [hist_blockavg]+histograms, labels=['Average']+labels, temp=temp, flim=140*kjmol, \n",
    "                colors    =['k']+[None,]*nblocks, \n",
    "                linestyles=['-']+['--',]*nblocks, \n",
    "                linewidths=[4  ]+[1   ,]*nblocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feps = []\n",
    "Nboot = 1000\n",
    "temp, biasses, trajectories = read_wham_input(fn, kappa_unit='kjmol', q0_unit='au')\n",
    "for iboot in range(Nboot):\n",
    "    new_trajectories = []\n",
    "    for traj in trajectories:\n",
    "        Nsteps = len(traj)\n",
    "        indices = np.random.uniform(0,Nsteps,Nsteps)\n",
    "        new_trajectories.append(traj[indices]) \n",
    "    hist = Histogram1D.from_wham(bins, new_trajectories, biasses, temp, estimate_error='mle_f')\n",
    "    feps.append(BaseFreeEnergyProfile.from_histogram(hist,temp))\n",
    "hist = Histogram1D.from_average(histograms, error_estimate='std')\n",
    "plot_histograms('histograms_US_bootstrapping.png', [hist]+histograms, labels=['Average']+['start=%i' %i for i in np.arange(0,100,10)], temp=temp, flim=140*kjmol,\n",
    "               colors    =['k']+[None,]*10,\n",
    "               linewidths=[2  ]+[1   ,]*10,\n",
    "               linestyles=['-']+['--',]*10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6035c5c19054a81448179272e55352f2864f929f76fb7fd7f7119786402a08c9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
