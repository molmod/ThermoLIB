%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[a4paper,11pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsable pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}


\title{ThermoLIB Documentation}
\date{Sep 15, 2021}
\release{v1.0.0}
\author{Louis Vanduyfhuys}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxAtStartPar
ThermoLIB is a library developed at the \sphinxhref{https://molmod.ugent.be/}{Center for Molecular Modeling} (CMM)for the application of Statistical Physics, Thermodynamics and/or kinetic theory to molecular simulations. The library consists of several sub modules:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Thermodynamics} \sphinxhyphen{} Module for reading, constructing, transforming and manipulating free energy profiles. Functions include construction of free energy profiles (FEPs) from histogram(s) (including error estimation), identification of (meta)stable macrostates and computation of their free energy, transformation of FEPs from one collective variable (CV) to another, (de)projection of an free energy surface (FES) to a lower/higher dimensional FES.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Kinetics} \sphinxhyphen{} Module for computing the rate factor required in transition state theory (TST) required to compute the reaction rate constant. This factor is related to the time derivative of the collective variable in the transition state. Together with thermodynamic observables such as the free energy of the reactant state and transition state, the TST\sphinxhyphen{}reaction rate can be computed.

\end{itemize}


\chapter{How to cite ThermoLIB}
\label{\detokenize{index:how-to-cite-thermolib}}
\sphinxAtStartPar
If you used ThermoLIB in your research, please refer to ThermoLIB as follows:


\chapter{Installation Guide}
\label{\detokenize{index:installation-guide}}
\sphinxAtStartPar
ThermoLIB is developed and tested on modern Linux environments. The installation instructions given in {\hyperref[\detokenize{ig:seclab-ig}]{\sphinxcrossref{\DUrole{std,std-ref}{this guide}}}} are given for a Linux system only. If you want to use ThermoLIB on other operating systems such as Windows or OSX, you should have a minimal computer geek status to get it working. We are always interested in hearing from your installation adventures.


\section{Installation Guide}
\label{\detokenize{ig:installation-guide}}\label{\detokenize{ig:seclab-ig}}\label{\detokenize{ig::doc}}
\sphinxAtStartPar
Here you can find information on the packages required for a successfull installation of ThermoLIB as well as details on how to download and install ThermoLIB on a Linux system. On Windows 10, ThermoLIB was tested for \sphinxhref{https://docs.microsoft.com/en-us/windows/wsl/install-win10}{Windows Subsystem for Linux \sphinxhyphen{} version 2}. For a pure Windows\sphinxhyphen{}based installation, we cannot garantue any assistance but we are offcourse interested to hear about your adventures.


\subsection{Dependencies}
\label{\detokenize{ig:dependencies}}

\subsubsection{MolMod Dependency}
\label{\detokenize{ig:molmod-dependency}}
\sphinxAtStartPar
\sphinxhref{http://molmod.github.com/molmod/}{MolMod} is a Python library used by most Python programs developed at the CMM. It must be installed before ThermoLIB can be used. Installation and download instructions can be found in the
\sphinxhref{http://molmod.github.com/molmod/tutorial/install.html}{molmod documentation}. The instructions below only work if the MolMod package is installed.


\subsubsection{External Dependencies}
\label{\detokenize{ig:external-dependencies}}
\sphinxAtStartPar
Some software packages should be installed before ThermoLIB can be installed and/or used. It is recommended to use the software package management of your Linux distribution to install these dependencies.

\sphinxAtStartPar
The following software must be installed:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Python3 \textless{}= 3.7 (including the development files): \sphinxurl{http://www.python.org/}

\item {} 
\sphinxAtStartPar
Numpy \textgreater{}= 1.0: \sphinxurl{http://numpy.scipy.org/}

\item {} 
\sphinxAtStartPar
Scipy \textgreater{}= 0.14: \sphinxurl{http://www.scipy.org/}

\item {} 
\sphinxAtStartPar
matplotlib \textgreater{}= 1.0.0: \sphinxurl{http://matplotlib.sourceforge.net}

\item {} 
\sphinxAtStartPar
scikit\sphinxhyphen{}learn \textgreater{}= 0.24.2: \sphinxurl{https://scikit-learn.org/}

\end{itemize}

\sphinxAtStartPar
On Ubuntu distributions, this can be installed with the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{sudo} \PYG{n}{apt}\PYG{o}{\PYGZhy{}}\PYG{n}{get} \PYG{n}{install} \PYG{n}{python3} \PYG{n}{python3}\PYG{o}{\PYGZhy{}}\PYG{n}{numpy} \PYG{n}{python3}\PYG{o}{\PYGZhy{}}\PYG{n}{scipy} \PYG{n}{python3}\PYG{o}{\PYGZhy{}}\PYG{n}{matplotlib} \PYG{n}{python3}\PYG{o}{\PYGZhy{}}\PYG{n}{sklearn}
\end{sphinxVerbatim}

\sphinxAtStartPar
In order to get the LaTeX support in the plots made by ThermoLIB, you also need the following packages installed
\begin{itemize}
\item {} 
\sphinxAtStartPar
latex: \sphinxurl{https://www.latex-project.org/}

\item {} 
\sphinxAtStartPar
cm\sphinxhyphen{}super: \sphinxurl{https://www.ctan.org/tex-archive/fonts/ps-type1/cm-super/}

\end{itemize}

\sphinxAtStartPar
which can be installed on Ubuntu using the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{sudo} \PYG{n}{apt}\PYG{o}{\PYGZhy{}}\PYG{n}{get} \PYG{n}{install} \PYG{n}{texlive} \PYG{n}{texlive}\PYG{o}{\PYGZhy{}}\PYG{n}{latex}\PYG{o}{\PYGZhy{}}\PYG{n}{extra} \PYG{n}{texlive}\PYG{o}{\PYGZhy{}}\PYG{n}{fonts}\PYG{o}{\PYGZhy{}}\PYG{n}{recommended} \PYG{n}{dvipng} \PYG{n}{cm}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{super}
\end{sphinxVerbatim}


\subsection{Downloading ThermoLIB}
\label{\detokenize{ig:downloading-thermolib}}

\subsubsection{Stable releases}
\label{\detokenize{ig:stable-releases}}
\sphinxAtStartPar
A stable release of ThermoLIB, which includes all features described on this website, can be downloaded through various means.
\begin{itemize}
\item {} 
\sphinxAtStartPar
For members of Ghent University with an active UGent GitHUB account, the latest releases of ThermoLIB can be downloaded from the \sphinxhref{https://github.ugent.be/lvduyfhu/ThermoLIB/tags}{UGent GitHUB page}.

\item {} 
\sphinxAtStartPar
For GitHUB users not member of Ghent University, stable ThermoLIB releases can be downloaded from the general GitHUB page (\sphinxstylestrong{TODO}).

\item {} 
\sphinxAtStartPar
Various main releases can also be downloaded from the links below (\sphinxstylestrong{TODO}):

\end{itemize}

\sphinxAtStartPar
After downloading the archive, choose a suitable directory, e.g. \sphinxcode{\sphinxupquote{\textasciitilde{}/build}}, and unpack the archive:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mkdir} \PYG{o}{\PYGZhy{}}\PYG{n}{p} \PYG{o}{\PYGZti{}}\PYG{o}{/}\PYG{n}{build}
\PYG{n}{cd} \PYG{o}{\PYGZti{}}\PYG{o}{/}\PYG{n}{build}
\PYG{n}{tar} \PYG{o}{\PYGZhy{}}\PYG{n}{xvzf} \PYG{n}{ThermoLIB}\PYG{o}{\PYGZhy{}}\PYG{n}{X}\PYG{o}{.}\PYG{n}{X}\PYG{o}{.}\PYG{n}{X}\PYG{o}{.}\PYG{n}{tar}\PYG{o}{.}\PYG{n}{gz}
\PYG{n}{cd} \PYG{n}{ThermoLIB}\PYG{o}{\PYGZhy{}}\PYG{n}{X}\PYG{o}{.}\PYG{n}{X}\PYG{o}{.}\PYG{n}{X}
\end{sphinxVerbatim}


\subsubsection{Latest development version (experts only)}
\label{\detokenize{ig:latest-development-version-experts-only}}
\sphinxAtStartPar
The latest development version of QuickFF can only be downloaded using Git. This also allows you to upload your own changes in the form of a pull request. Git is free and open\sphinxhyphen{}source distributed revision control system to easily handle programming projects shared between several people. Further information about git (including downloads and tutorials) can be found \sphinxhref{http://git-scm.com/}{here}. The official git URL for ThermoLIB is \sphinxstylestrong{TODO}. To \sphinxtitleref{clone} the ThermoLIB repository, go to your favorite directory for source code, e.g. \sphinxcode{\sphinxupquote{\textasciitilde{}/build}}, and execute the following commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{n}{git}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{n}{TODO}\PYG{o}{.}\PYG{n}{git} \PYG{n}{thermolib}
\PYG{n}{cd} \PYG{n}{thermolib}
\end{sphinxVerbatim}

\sphinxAtStartPar
The source code can be updated with the latest patches with the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{pull}
\end{sphinxVerbatim}

\sphinxAtStartPar
This will also update the version history so that the progress can easily be tracked. This version history can be visualized using the \sphinxtitleref{gitk} program. This program can be downloaded with the following command (Ubuntu):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{sudo} \PYG{n}{apt}\PYG{o}{\PYGZhy{}}\PYG{n}{get} \PYG{n}{install} \PYG{n}{gitk}
\end{sphinxVerbatim}

\sphinxAtStartPar
Once, \sphinxtitleref{gitk} is installed, the version history can be visualized by going to the directory containing the quickff repository and running the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{gitk}
\end{sphinxVerbatim}


\subsection{Installing ThermoLIB}
\label{\detokenize{ig:installing-thermolib}}
\sphinxAtStartPar
Once you downloaded the source code and installed all required packages, ThermoLIB can be installed. To do so, simply go to the directory in which you extracted the ThermoLIB source files (the directory containing the file \sphinxtitleref{setup.py}) and run the following command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{python} \PYG{n}{setup}\PYG{o}{.}\PYG{n}{py} \PYG{n}{install}
\end{sphinxVerbatim}


\chapter{User Guide}
\label{\detokenize{index:user-guide}}
\sphinxAtStartPar
A manual elaborating on how to use ThermoLIB for the construction, transformation and projection of free energy profiles, computation of kinetic rate constants and more.


\section{User Guide \sphinxhyphen{} Thermodynamics}
\label{\detokenize{ug_thermo:user-guide-thermodynamics}}\label{\detokenize{ug_thermo:seclab-ug-thermo}}\label{\detokenize{ug_thermo::doc}}
\sphinxAtStartPar
In this user guide we will outline how to use the various features of ThermoLIB related to equilibrium thermodynamics. The central thermodynamic object in ThermoLIB is a {\hyperref[\detokenize{ug_thermo:seclab-ug-1dfep}]{\sphinxcrossref{\DUrole{std,std-ref}{free energy profile (FEP) in one dimension (1D)}}}} or a {\hyperref[\detokenize{ug_thermo:seclab-ug-2dfes}]{\sphinxcrossref{\DUrole{std,std-ref}{free energy surface (FES) in two dimensions (2D)}}}}. In the following subsections, we discuss both in detail separately.


\subsection{Constructing a 1D Histogram}
\label{\detokenize{ug_thermo:constructing-a-1d-histogram}}\label{\detokenize{ug_thermo:seclab-ug-1dhist}}
\sphinxAtStartPar
In many cases, a free energy profile will be computed by means of first constructing a corresponding histogram as model for the probability density. We first provide further details on how such histogram can be constructed (including an estimation of its error).


\subsubsection{without error estimation}
\label{\detokenize{ug_thermo:without-error-estimation}}
\sphinxAtStartPar
A histogram can be computed from a trajectory of CV values generated by a molecular simulation (such as molecular dynamics or Monte Carlo). To this end, we use {\hyperref[\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{the Histogram1D class}}}}} as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{thermolib}\PYG{n+nn}{.}\PYG{n+nn}{thermodynamics}\PYG{n+nn}{.}\PYG{n+nn}{histogram} \PYG{k+kn}{import} \PYG{n}{Histogram1D}
\PYG{n}{histogram} \PYG{o}{=} \PYG{n}{Histogram1D}\PYG{o}{.}\PYG{n}{from\PYGZus{}single\PYGZus{}trajectory}\PYG{p}{(}\PYG{n}{cv\PYGZus{}data}\PYG{p}{,} \PYG{n}{bins}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Herein, \sphinxstyleemphasis{cv\_data} represents a numpy array containig the CV values along the trajectory. This array can be computed from an XYZ trajectory file using the routine {\hyperref[\detokenize{rg:thermolib.tools.trajectory_xyz_to_CV}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{trajectory\_xyz\_to\_CV}}}}}. Furthermore, \sphinxstyleemphasis{bins} represents the argument of the same name defined in \sphinxhref{https://numpy.org/doc/stable/reference/generated/numpy.histogram.html}{the numpy.histogram routine}, hence for more information on its meaning and allowed values we refer to its documentation. We can plot the resulting histogram using {\hyperref[\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D.plot}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{its plot routine}}}}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{histogram}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{histogram\PYGZus{}noerror.png}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
One can even add an additional pane in the plot with the corresponding free energy profile by specifying the temperature at which the simulation trajectory was generated:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{histogram}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{histogram\PYGZus{}noerror.png}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{temp}\PYG{o}{=}\PYG{n}{temp}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
More information on the construction of a histogram and its optional features can be found in the reference guide of {\hyperref[\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{Histogram1D}}}}}.


\subsubsection{with error estimation}
\label{\detokenize{ug_thermo:with-error-estimation}}
\sphinxAtStartPar
With a few extra keyword arguments, we can include an estimation of the error bar. Two methods are distinguished:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Estimating the error using the asymptotic normality of the maximum likelihood estimator applied to the entire trajectory.

\item {} 
\sphinxAtStartPar
First divide the trajectory into blocks, construct a histogram for each block and estimate total histogram and its error through the average and standard deviation of the block histograms.

\end{itemize}

\sphinxAtStartPar
More details on the theory behind these methods can be found in the theory section. In the following subsections, we describe how to perform such error estimates using ThermoLIB.


\paragraph{from asymptotic normality of the MLE}
\label{\detokenize{ug_thermo:from-asymptotic-normality-of-the-mle}}
\sphinxAtStartPar
The construction of a histogram including an error estimation from the entire trajectory (using the asymptotic normality of the maximum likelihood estimator) is done by setting the keyword \sphinxcode{\sphinxupquote{error\_estimate=\textquotesingle{}single\textquotesingle{}}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{thermolib}\PYG{n+nn}{.}\PYG{n+nn}{thermodynamics}\PYG{n+nn}{.}\PYG{n+nn}{histogram} \PYG{k+kn}{import} \PYG{n}{Histogram1D}
\PYG{n}{histogram} \PYG{o}{=} \PYG{n}{Histogram1D}\PYG{o}{.}\PYG{n}{from\PYGZus{}single\PYGZus{}trajectory}\PYG{p}{(}\PYG{n}{cv\PYGZus{}data}\PYG{p}{,} \PYG{n}{bins}\PYG{p}{,} \PYG{n}{error\PYGZus{}estimate}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{single}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{histogram}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{histogram\PYGZus{}single.png}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Specifying the \sphinxcode{\sphinxupquote{temp}} argument in the histogram plot routine will include an additional pane with the correspondig free energy profile and its error estimate.


\paragraph{from block analysis}
\label{\detokenize{ug_thermo:from-block-analysis}}
\sphinxAtStartPar
Alternative error estimation can be based on block analysis. Herein, we first divide the trajectory in a number of blocks (as defined by the \sphinxcode{\sphinxupquote{nblocks}} keyword) and compute a histogram for each block. Afterwards, the total histogram and its error are estimated through the average and standard deviation of these histograms. This can be done as illustrated in the following code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{thermolib}\PYG{n+nn}{.}\PYG{n+nn}{thermodynamics}\PYG{n+nn}{.}\PYG{n+nn}{histogram} \PYG{k+kn}{import} \PYG{n}{Histogram1D}
\PYG{n}{histogram} \PYG{o}{=} \PYG{n}{Histogram1D}\PYG{o}{.}\PYG{n}{from\PYGZus{}single\PYGZus{}trajectory}\PYG{p}{(}\PYG{n}{cv\PYGZus{}data}\PYG{p}{,} \PYG{n}{bins}\PYG{p}{,} \PYG{n}{error\PYGZus{}estimate}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{blocked}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{nblocks}\PYG{o}{=}\PYG{l+m+mi}{6}\PYG{p}{)}
\PYG{n}{histogram}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{histogram\PYGZus{}blocked.png}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{temp}\PYG{o}{=}\PYG{n}{temp}\PYG{p}{)}
\end{sphinxVerbatim}


\subsection{Constructing a 1D free energy profile}
\label{\detokenize{ug_thermo:constructing-a-1d-free-energy-profile}}\label{\detokenize{ug_thermo:seclab-ug-1dfep}}
\sphinxAtStartPar
The base object of a 1D free energy surface is an instance of the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{BaseFreeEnergyProfile}}}}}. This class implements all basic features of 1D free energy profiles such as:
\begin{itemize}
\item {} 
\sphinxAtStartPar
making a plot of the free energy profile using the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.plot}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{BaseFreeEnergyProfile.plot}}}}} routine or the one of a deriving class

\item {} 
\sphinxAtStartPar
cropping the range of a collective variable using the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.crop}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{BaseFreeEnergyProfile.crop}}}}} routine.

\item {} 
\sphinxAtStartPar
recollecting the collective variable into newly defined intervals using the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.recollect}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{BaseFreeEnergyProfile.recollect}}}}} routine.

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{ug_thermo:seclab-ug-transformation}]{\sphinxcrossref{\DUrole{std,std-ref}{transformation towards other collective variables}}}}

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{ug_thermo:seclab-ug-deprojection}]{\sphinxcrossref{\DUrole{std,std-ref}{deprojection of a 1D FEP towards a 2D FES}}}}

\item {} 
\sphinxAtStartPar
…

\end{itemize}

\sphinxAtStartPar
as is included in this documentation. This class serves as a master class from which deriving classes will inherit all these features. The deriving classes will further implement additional features that require assumptions of the free energy profile. At this moment, only one deriving class is implemented, the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{SimpleFreeEnergyProfile}}}}} which represents the FEP of a simple process with a single reactant, transition and product state. As such these states can be detected by means of the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.process_states}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{SimpleFreeEnergyProfile.process\_states}}}}} routine and will then be automatically shown on the plot produced by the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.plot}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{SimpleFreeEnergyProfile.plot}}}}} plot routine.

\sphinxAtStartPar
There are several ways to construct a free energy profile. The following sections in this will use the routines of BaseFreeEnergyProfile and can hence also be applied to SimpleFreeEnergyProfile.


\subsubsection{using the constructor}
\label{\detokenize{ug_thermo:using-the-constructor}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{thermolib}\PYG{n+nn}{.}\PYG{n+nn}{thermodynamics}\PYG{n+nn}{.}\PYG{n+nn}{fep} \PYG{k+kn}{import} \PYG{n}{BaseFreeEnergyProfile}
\PYG{n}{fep} \PYG{o}{=} \PYG{n}{BaseFreeEnergyProfile}\PYG{p}{(}\PYG{n}{cv}\PYG{p}{,} \PYG{n}{f}\PYG{p}{,} \PYG{n}{temp}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Herein, \sphinxstyleemphasis{cv} and \sphinxstyleemphasis{f} represent equal\sphinxhyphen{}length numpy arrays containing respectively the collective variable and free energy on a grid. By default these arrays should be defined in atomic units. More control over these units is possible using the optional arguments as described in {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{the reference guide entry of this routine}}}}}. Furthermore, \sphinxstyleemphasis{temp} represents the temperature (in atomic units, i.e. Kelvin) at which the free energy profile is evaluated.


\subsubsection{reading from a text file}
\label{\detokenize{ug_thermo:reading-from-a-text-file}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{thermolib}\PYG{n+nn}{.}\PYG{n+nn}{thermodynamics}\PYG{n+nn}{.}\PYG{n+nn}{fep} \PYG{k+kn}{import} \PYG{n}{BaseFreeEnergyProfile}
\PYG{n}{fep} \PYG{o}{=} \PYG{n}{BaseFreeEnergyProfile}\PYG{o}{.}\PYG{n}{from\PYGZus{}txt}\PYG{p}{(}\PYG{n}{fn}\PYG{p}{,} \PYG{n}{temp}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
Herein, \sphinxstyleemphasis{fn} represents the name of a text file containing the values of the collective variable and the corresponding free energy on a grid. By default, the \sphinxstyleemphasis{cv} and \sphinxstyleemphasis{f} values should be respectively in the first and second column separated by one or multiple whitespaces. More control on the columns from which to read the data as well as the delimiter and more can be found in {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.from_txt}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{the reference guide entry of this routine}}}}}. Furthermore, \sphinxstyleemphasis{temp} represents the temperature (in atomic units, i.e. Kelvin) at which the free energy profile is evaluated.


\subsubsection{from a trajectory histogram}
\label{\detokenize{ug_thermo:from-a-trajectory-histogram}}
\sphinxAtStartPar
The free energy profile can also be constructed from a histogram that was computed from a trajectory of CV values generated by a molecular simulation (such as molecular dynamics or Monte Carlo). To this end, we first contruct a histogram as outlined in {\hyperref[\detokenize{ug_thermo:seclab-ug-1dhist}]{\sphinxcrossref{\DUrole{std,std-ref}{the user guide on histogram construction}}}} and compute the free energy profile from this histogram as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{thermolib}\PYG{n+nn}{.}\PYG{n+nn}{thermodynamics}\PYG{n+nn}{.}\PYG{n+nn}{fep} \PYG{k+kn}{import} \PYG{n}{BaseFreeEnergyProfile}
\PYG{k+kn}{from} \PYG{n+nn}{thermolib}\PYG{n+nn}{.}\PYG{n+nn}{thermodynamics}\PYG{n+nn}{.}\PYG{n+nn}{histogram} \PYG{k+kn}{import} \PYG{n}{Histogram1D}
\PYG{n}{histogram} \PYG{o}{=} \PYG{n}{Histogram1D}\PYG{o}{.}\PYG{n}{from\PYGZus{}single\PYGZus{}trajectory}\PYG{p}{(}\PYG{n}{cv\PYGZus{}data}\PYG{p}{,} \PYG{n}{bins}\PYG{p}{)}
\PYG{n}{temp} \PYG{o}{=} \PYG{l+m+mi}{300}\PYG{o}{*}\PYG{n}{kelvin}
\PYG{n}{fep} \PYG{o}{=} \PYG{n}{BaseFreeEnergyProfile}\PYG{o}{.}\PYG{n}{from\PYGZus{}histogram}\PYG{p}{(}\PYG{n}{histogram}\PYG{p}{,} \PYG{n}{temp}\PYG{p}{)}
\end{sphinxVerbatim}

\sphinxAtStartPar
As outlined previously, the routine \sphinxcode{\sphinxupquote{from\_single\_trajectory}} can also estamate the error on the histogram. If so, the free energy profile generated from the resulting histogram will also contain the correpsonding error which in turn will be included in any plots of the free energy profile made with its plot routine.


\subsection{2D free energy surface}
\label{\detokenize{ug_thermo:d-free-energy-surface}}\label{\detokenize{ug_thermo:seclab-ug-2dfes}}

\subsection{Transformations}
\label{\detokenize{ug_thermo:transformations}}\label{\detokenize{ug_thermo:seclab-ug-manipulations}}

\subsubsection{Transforming FEP between collective variables}
\label{\detokenize{ug_thermo:transforming-fep-between-collective-variables}}\label{\detokenize{ug_thermo:seclab-ug-transformation}}

\subsubsection{Projecting 2D FES to 1D FEP}
\label{\detokenize{ug_thermo:projecting-2d-fes-to-1d-fep}}

\subsubsection{Deprojecting 1D FEP to 2D FES}
\label{\detokenize{ug_thermo:deprojecting-1d-fep-to-2d-fes}}\label{\detokenize{ug_thermo:seclab-ug-deprojection}}

\section{User Guide \sphinxhyphen{} Kinetics}
\label{\detokenize{ug_kin:user-guide-kinetics}}\label{\detokenize{ug_kin:seclab-ug-kin}}\label{\detokenize{ug_kin::doc}}
\sphinxAtStartPar
In this user guide we will outline how to use the various features of ThermoLIB related to kinetics.


\subsection{Reaction rate from equilibrium simulations}
\label{\detokenize{ug_kin:reaction-rate-from-equilibrium-simulations}}\label{\detokenize{ug_kin:seclab-ug-kin-eq}}

\subsection{Alternative computation of reaction rate}
\label{\detokenize{ug_kin:alternative-computation-of-reaction-rate}}\label{\detokenize{ug_kin:seclab-ug-kin-alt}}

\chapter{Tutorials}
\label{\detokenize{index:tutorials}}
\sphinxAtStartPar
Various tutorials giving practical examples on how to use ThermoLIB.


\section{Tutorials}
\label{\detokenize{tutorials:tutorials}}\label{\detokenize{tutorials:seclab-tut}}\label{\detokenize{tutorials::doc}}
\sphinxAtStartPar
Here we will give some practical examples on how to use ThermoLIB.


\chapter{Reference Guide}
\label{\detokenize{index:reference-guide}}
\sphinxAtStartPar
A reference guide generated from the documentation strings in the source code. It includes an overview of all modules included in QuickFF. This information is based on the documentation provided in the source code.


\section{Reference Guide}
\label{\detokenize{rg:reference-guide}}\label{\detokenize{rg::doc}}\phantomsection\label{\detokenize{rg:seclab-rg-modules}}
\sphinxAtStartPar
An overview is provived of all modules included in ThermoLIB. The information below is based on the documentation provided in the source code.


\subsection{Thermodynamics Modules}
\label{\detokenize{rg:thermodynamics-modules}}

\subsubsection{Free energy profiles \textendash{} \sphinxstyleliteralintitle{\sphinxupquote{thermodynamics.fep}}}
\label{\detokenize{rg:free-energy-profiles-thermodynamics-fep}}\label{\detokenize{rg:seclab-rg-modules-fep}}

\paragraph{1D Free energy profile}
\label{\detokenize{rg:d-free-energy-profile}}\index{BaseFreeEnergyProfile (class in thermolib.thermodynamics.fep)@\spxentry{BaseFreeEnergyProfile}\spxextra{class in thermolib.thermodynamics.fep}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.fep.}}\sphinxbfcode{\sphinxupquote{BaseFreeEnergyProfile}}}{\emph{\DUrole{n}{cvs}}, \emph{\DUrole{n}{fs}}, \emph{\DUrole{n}{temp}}, \emph{\DUrole{n}{fupper}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{flower}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{cv\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{f\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{cv\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV\textquotesingle{}}}}{}
\sphinxAtStartPar
Base class to define a free energy profile F(q) (stored in self.fs) as function of a certain collective variable (CV) denoted by q (stored in self.cvs).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} the collective variable values

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{f}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} the free energy values

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the temperature at which the free energy is constructed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{flower}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} the lower limit of the error bar on the free energy values

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fupper}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} the upper limit of the error bar on the free energy values

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=au}}) \textendash{} the units for printing of CV values. Units are defined using \sphinxhref{https://molmod.github.io/molmod/reference/const.html\#module-molmod.units}{the molmod routine}.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{f\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=kjmol}}) \textendash{} the units for printing of free energy values. Units are defined using \sphinxhref{https://molmod.github.io/molmod/reference/const.html\#module-molmod.units}{the molmod routine molmod.units}.

\end{itemize}

\end{description}\end{quote}
\index{compute\_probdens() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile method)@\spxentry{compute\_probdens()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.compute_probdens}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{compute\_probdens}}}{}{}
\sphinxAtStartPar
Compute the probability density profile associated with the free energy profile:
\begin{equation*}
\begin{split}p(q) = \frac{1}{q_0Z}\exp\left(-\beta F(q)\right)\end{split}
\end{equation*}
\sphinxAtStartPar
with
\begin{equation*}
\begin{split}Z = \frac{1}{q_0}\int_{-\infty}^{+\infty}\exp\left(-\beta F(q)\right)dq\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, \(q_0\) represents an arbitrary constant to account for the fact that the partition function should in principle be dimensionless. However, it can be chosen freely and has no impact on the final free energy profile (appart from meaningless a vertical shift). Therefore, in this implementation it is chosen as \(q_0=1\).

\end{fulllineitems}

\index{crop() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile method)@\spxentry{crop()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.crop}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{crop}}}{\emph{\DUrole{n}{cvrange}}, \emph{\DUrole{n}{return\_new\_fes}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Crop the free energy profile to the limits given by cvrange and throw away cropped data. If return\_new\_fes is set to false, a copy of the cropped profile will be returns, otherwise the current profile will be cropped and overwritten.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cvrange}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}) \textendash{} the range of the collective variable defining the new range to which the FEP will be cropped.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_new\_fes}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} If set to False, the cropped data will be written to the current instance (overwritting the original data). If set to True, a new instance will be initialized with the cropped data, defaults to False

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
an instance of the current class if the keyword argument \sphinxtitleref{return\_new\_fes} is set to True. Otherwise, None is returned.

\end{description}\end{quote}

\end{fulllineitems}

\index{from\_average() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile class method)@\spxentry{from\_average()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.from_average}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_average}}}{\emph{\DUrole{n}{feps}}, \emph{\DUrole{n}{error\_estimate}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{nsigma}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
\sphinxAtStartPar
Start from a set of free energy profiles and compute and return the averaged free energy profile. If error\_estimate is set to ‘std’, an error on the freee energy profile will be computed from the standard deviation within the set of profiles.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{feps}} \textendash{} set of free energy profiles to be averaged

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{error\_estimate}} \textendash{} 
\sphinxAtStartPar
indicate if and how to perform error analysis. One of following options is available:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{std} \textendash{} compute error from the standard deviation within the set of profiles.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{None} \textendash{} do not estimate the error.

\end{itemize}


\end{itemize}

\end{description}\end{quote}

\sphinxAtStartPar
Defaults to None, i.e. no error estimate.
:type error\_estimate: str, optional
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nsigma}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} only relevant when error estimation is turned on (i.e. when keyword \sphinxcode{\sphinxupquote{error\_estimate}} is not None), this option defines how large the error interval should be in terms of the standard deviation sigma. A \sphinxcode{\sphinxupquote{nsigma=2}} implies a 2\sphinxhyphen{}sigma error bar (corresponding to 95\% confidence interval) will be returned. Defaults to 2

\item[{Returns}] \leavevmode
\sphinxAtStartPar
averages free energy profile

\item[{Return type}] \leavevmode
\sphinxAtStartPar
identical as the mother class of the current routine

\end{description}\end{quote}

\end{fulllineitems}

\index{from\_histogram() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile class method)@\spxentry{from\_histogram()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.from_histogram}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_histogram}}}{\emph{\DUrole{n}{histogram}}, \emph{\DUrole{n}{temp}}}{}
\sphinxAtStartPar
Use the estimated probability histogram to construct the corresponding free energy profile at the given temperature.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{histogram}} ({\hyperref[\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{histogram.Histogram1D}}}}}) \textendash{} histogram from which the free energy profile is computed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the temperature at which the histogram input data was simulated

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
free energy profile corresponding to the estimated probability histogram

\item[{Return type}] \leavevmode
\sphinxAtStartPar
cls

\end{description}\end{quote}

\end{fulllineitems}

\index{from\_txt() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile class method)@\spxentry{from\_txt()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.from_txt}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_txt}}}{\emph{\DUrole{n}{fn}}, \emph{\DUrole{n}{temp}}, \emph{\DUrole{n}{cvcol}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{fcol}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{cv\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{f\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{cvrange}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{delimiter}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{reverse}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cut\_constant}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Read the free energy profile as function of a collective variable from a txt file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} the name of the txt file containing the data

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the temperature at which the free energy is constructed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cvcol}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=0}}) \textendash{} the column in which the collective variable is stored

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fcol}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=1}}) \textendash{} the column in which the free energy is stored.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=au}}) \textendash{} 
\sphinxAtStartPar
the units in which the CV are stored. Units are defined using \sphinxhref{https://molmod.github.io/molmod/reference/const.html\#module-molmod.units}{the molmod routine}.


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{f\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=kjmol}}) \textendash{} 
\sphinxAtStartPar
the units in which the free energy are stored. Units are defined using \sphinxhref{https://molmod.github.io/molmod/reference/const.html\#module-molmod.units}{the molmod routine}


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cvrange}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=None}}) \textendash{} only read free energy for CVs in the given range

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delimiter}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=None}}) \textendash{} The delimiter used in the txt input file to separate columns. The default is set to None, corresponding to the default of \sphinxhref{https://numpy.org/doc/1.20/reference/generated/numpy.loadtxt.html}{the numpy.loadtxt routine} (i.e. whitespace).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{reverse}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=False}}) \textendash{} if set to True, reverse the X axis (usefull to make sure reactant is on the left)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cut\_constant}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=False}}) \textendash{} if set to True, the data points at the start and end of the data array that are constant will be cut. Usefull to cut out unsampled areas for large and small CV values.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{macrostate() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile method)@\spxentry{macrostate()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.macrostate}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{macrostate}}}{\emph{\DUrole{n}{cvrange}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{indexes}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Return the contribution to the partition function and free energy corresponding to the macrostate in the given range of cvs. This contribution is computed as follows.
\begin{align*}\!\begin{aligned}
\begin{aligned}
    Z_A &= \frac{1}{q_0}\int_A \exp\left(-\beta F(q)\right)dq \\\\
&= Z\cdot\int_A p(q)dq \\\\
F_A &= -k_B T\log{Z_A}
\end{aligned}\\
\end{aligned}\end{align*}\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cvrange}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the range of the collective variable defining the macrostate. Either cvrange or indices should be defined, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{indexes}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the indexes of the collective variable defining the macrostate. Either cvrange or indices should be defined, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} set to true to turn on verbosity, defaults to False

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{mean} (float) \sphinxhyphen{} the expected (=mean) value of the collective variable in the macrostate

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{std} (float) \sphinxhyphen{} the thermal fluctuation (=standard deviation) of the CV in the macrostate

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{Z} (float) \sphinxhyphen{} the contribution of the macrostate to the partition function

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{F} (float) \sphinxhyphen{} the free energy of the given macrostate

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{plot() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile method)@\spxentry{plot()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.plot}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{plot}}}{\emph{\DUrole{n}{fn}}, \emph{\DUrole{n}{flim}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Make a plot of the free energy profile.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Name of the file of the figure. Supported file formats are determined by the supported formats of the \sphinxhref{https://matplotlib.org/stable/api/\_as\_gen/matplotlib.pyplot.savefig.html}{matplotlib.pyplot.savefig routine}

\end{description}\end{quote}

\end{fulllineitems}

\index{recollect() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile method)@\spxentry{recollect()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.recollect}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{recollect}}}{\emph{\DUrole{n}{new\_cvs}}, \emph{\DUrole{n}{fn\_plt}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{return\_new\_fes}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Redefine the CV array to the new given array. For each interval of new CV values, collect all old free energy values for which the corresponding CV value falls in this new interval and average out. As such, this routine can be used to filter out noise on a given free energy profile by means of averaging.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{new\_cvs}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} Array of new CV values

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn\_plt}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} File name for comparison plot of old and new profile., defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_new\_fes}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} If set to False, the recollected data will be written to the current instance (overwritting the original data). If set to True, a new instance will be initialized with the recollected data., defaults to False

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
Returns an instance of the current class if the keyword argument \sphinxtitleref{return\_new\_fes} is set to True. Otherwise, None is returned.

\end{description}\end{quote}

\end{fulllineitems}

\index{savetxt() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile method)@\spxentry{savetxt()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.savetxt}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{savetxt}}}{\emph{\DUrole{n}{fn\_txt}}}{}
\sphinxAtStartPar
Save the free energy profile as txt file

\end{fulllineitems}

\index{set\_ref() (thermolib.thermodynamics.fep.BaseFreeEnergyProfile method)@\spxentry{set\_ref()}\spxextra{thermolib.thermodynamics.fep.BaseFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile.set_ref}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_ref}}}{\emph{\DUrole{n}{ref}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}min\textquotesingle{}}}}{}
\sphinxAtStartPar
Set the energy reference of the free energy profile.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ref}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} the choice for the energy reference, currently only ‘min’ or ‘m’ is implemented resulting in setting the reference to the minimum in the free energy profile. Defaults to ‘min’

\item[{Raises}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{IOError}} \textendash{} invalid value for keyword argument ref is given. See doc above for choices.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{SimpleFreeEnergyProfile (class in thermolib.thermodynamics.fep)@\spxentry{SimpleFreeEnergyProfile}\spxextra{class in thermolib.thermodynamics.fep}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.fep.}}\sphinxbfcode{\sphinxupquote{SimpleFreeEnergyProfile}}}{\emph{\DUrole{n}{cvs}}, \emph{\DUrole{n}{fs}}, \emph{\DUrole{n}{temp}}, \emph{\DUrole{n}{fupper}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{flower}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{cv\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{f\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{cv\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV\textquotesingle{}}}}{}
\sphinxAtStartPar
Class implementing a 1D FEP representing a simple bi\sphinxhyphen{}stable profile with 2 minima representing the reactant and process states and 1 local maximum representing the transition state.

\sphinxAtStartPar
As such, this class offers all features of the parent class {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{BaseFreeEnergyProfile()}}}}} as well as the additional feature to automatically identify the micro/macrostates corresponding to reactant state, transition state and product state (the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.process_states}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{process\_states()}}}}} routine).

\sphinxAtStartPar
See {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{BaseFreeEnergyProfile()}}}}} for constructor arguments and documentation.
\index{\_find\_R\_TS\_P() (thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method)@\spxentry{\_find\_R\_TS\_P()}\spxextra{thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile._find_R_TS_P}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_find\_R\_TS\_P}}}{\emph{\DUrole{n}{ts\_range}\DUrole{o}{=}\DUrole{default_value}{{[}\sphinxhyphen{} inf, inf{]}}}}{}
\sphinxAtStartPar
Internal routine called by {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.process_states}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{process\_states()}}}}} to find:
\begin{itemize}
\item {} 
\sphinxAtStartPar
the transition state (TS) as the local maximum within the given ts\_range

\item {} 
\sphinxAtStartPar
the reactant (R) as local minimum left of TS

\item {} 
\sphinxAtStartPar
the product (P) as local minimum right of TS

\end{itemize}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ts\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} range for the cv in which to look for the transition state as a local maximum, defaults to {[}\sphinxhyphen{}np.inf,np.inf{]}

\item[{Raises}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ValueError}} \textendash{} the transition state cannot be found in the range defined by ts\_range.

\end{description}\end{quote}

\end{fulllineitems}

\index{plot() (thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method)@\spxentry{plot()}\spxextra{thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.plot}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{plot}}}{\emph{\DUrole{n}{fn}}, \emph{\DUrole{n}{rate}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{micro\_marker}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}s\textquotesingle{}}}, \emph{\DUrole{n}{micro\_color}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}r\textquotesingle{}}}, \emph{\DUrole{n}{micro\_size}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}4\textquotesingle{}}}, \emph{\DUrole{n}{macro\_linestyle}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\sphinxhyphen{}\textquotesingle{}}}, \emph{\DUrole{n}{macro\_color}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}b\textquotesingle{}}}}{}
\sphinxAtStartPar
Plot the free energy profile including visualization of the microstates (markers) and macrostates (lines) defined by {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.set_microstates}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{set\_microstates()}}}}} and {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.set_macrostates}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{set\_macrostates()}}}}} respectively
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} file name of the resulting plot, the extension of the file name will determine the format (png or pdf)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{rate}} ({\hyperref[\detokenize{rg:thermolib.kinetics.rate.RateFactorEquilibrium}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{thermolib.kinetics.rate.RateFactorEquilibrium}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{thermolib.kinetics.rate.RateFactorAlternative}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} rate factor instance from \sphinxcode{\sphinxupquote{thermolib.kinetics}} module which will allow to include indication of reaction rate and phenomenological free energy barriers, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{micro\_marker}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} matplotlib marker style for indicating microstates, defaults to ‘s’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{micro\_color}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} matplotlib marker color for indicating microstates, defaults to ‘r’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{micro\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} matplotlib marker size for indicating microstates, defaults to ‘4’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{macro\_linestyle}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} matplotlib line style for indicating macrostates, defaults to ‘\sphinxhyphen{}‘

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{macro\_color}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} matplotlib line color for indicating macrostates, defaults to ‘b’

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{process\_states() (thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method)@\spxentry{process\_states()}\spxextra{thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.process_states}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process\_states}}}{\emph{\DUrole{n}{ts\_range}\DUrole{o}{=}\DUrole{default_value}{{[}\sphinxhyphen{} inf, inf{]}}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Routine to find the reactant (R), transition state (TS) and product state (P) through application of the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile._find_R_TS_P}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{\_find\_R\_TS\_P()}}}}} routine and add the corresponding micro and macrostates. These will afterwards be shown on the free energy plot using the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.plot}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{plot()}}}}} routine.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ts\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} range for the cv in which to look for the transition state as a local maximum, defaults to {[}\sphinxhyphen{}np.inf,np.inf{]}

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} set to True to increase verbosity, defaults to False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_macrostates() (thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method)@\spxentry{set\_macrostates()}\spxextra{thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.set_macrostates}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_macrostates}}}{\emph{\DUrole{n}{cvs}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Routine to define macrostates, i.e. regions on the 1D FEP. This routine is called by {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.process_states}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{process\_states()}}}}} to add the macrostates found by the latter. These macrostates will be visualized as horizontal linesegments on a plot made by the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.plot}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{plot()}}}}} routine with free energy contributions as computed by the \sphinxcode{\sphinxupquote{macrostate()}} routine.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cvs}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} list of integers giving defining the index of the boundaries between subsequent macrostates.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} set to True to increase verbosity, defaults to False

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_microstates() (thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method)@\spxentry{set\_microstates()}\spxextra{thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.set_microstates}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_microstates}}}{\emph{\DUrole{n}{indices}}}{}
\sphinxAtStartPar
Routine to define microstates, i.e. points on the 1D FEP. This routine is called by {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.process_states}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{process\_states()}}}}} to add the microstates found by the latter. These microstates will be visualized as points with corresponding free energy value on a plot made by the {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.plot}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{plot()}}}}} routine.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{indices}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} list of indices corresponding to the index of the microstates in the self.cvs and self.fs arrays

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_ref() (thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method)@\spxentry{set\_ref()}\spxextra{thermolib.thermodynamics.fep.SimpleFreeEnergyProfile method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.SimpleFreeEnergyProfile.set_ref}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_ref}}}{\emph{\DUrole{n}{ref}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}min\textquotesingle{}}}}{}
\sphinxAtStartPar
Set the energy reference of the free energy profile.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ref}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} 
\sphinxAtStartPar
the choice for the energy reference, should be one of:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{m} or \sphinxstyleemphasis{min} for the global minimum

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{r} or \sphinxstyleemphasis{reactant} for the reactant minimum

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{ts}, \sphinxstyleemphasis{trans\_state} or \sphinxstyleemphasis{transition} for the transition state maximum

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{p} or \sphinxstyleemphasis{product} for the product minimum

\end{itemize}

\sphinxAtStartPar
The options r, ts and p are only available if the reactant, transition state and product have already been found by the routine find\_states, defaults to ‘min’


\item[{Raises}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{IOError}} \textendash{} invalid value for keyword argument ref is given. See doc above for choices.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\paragraph{2D Free energy surface}
\label{\detokenize{rg:d-free-energy-surface}}\index{FreeEnergySurface2D (class in thermolib.thermodynamics.fep)@\spxentry{FreeEnergySurface2D}\spxextra{class in thermolib.thermodynamics.fep}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.fep.}}\sphinxbfcode{\sphinxupquote{FreeEnergySurface2D}}}{\emph{\DUrole{n}{cv1s}}, \emph{\DUrole{n}{cv2s}}, \emph{\DUrole{n}{fs}}, \emph{\DUrole{n}{temp}}, \emph{\DUrole{n}{fupper}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{flower}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{cv1\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{cv2\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{f\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{cv1\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV1\textquotesingle{}}}, \emph{\DUrole{n}{cv2\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV2\textquotesingle{}}}}{}
\sphinxAtStartPar
Class implementing a 2D free energy surface F(cv1,cv2) (stored in self.fs) as function of two collective variables (CV) denoted by cv1 (stored in self.cv1s) and cv2 (stored in self.cv2s).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1s}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} array containing the values for the first collective variable CV1

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2s}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} array the values for the second collective variable CV2

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fs}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} 2D array containing the free energy values corresponding to the given values of CV1 and CV2

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} temperature at which the free energy is given

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fupper}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} upper value of error bar on free energy

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{flower}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} lower value of error bar on free energy

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} 
\sphinxAtStartPar
unit in which the input array cv1 is given (units are defined using \sphinxhref{https://molmod.github.io/molmod/reference/const.html\#module-molmod.units}{the molmod routine}), defaults to ‘au’


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} 
\sphinxAtStartPar
unit in which the input array cv2 is given (units are defined using \sphinxhref{https://molmod.github.io/molmod/reference/const.html\#module-molmod.units}{the molmod routine}), defaults to ‘au’


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{f\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} 
\sphinxAtStartPar
unit in which the input array f is given (units are defined using \sphinxhref{https://molmod.github.io/molmod/reference/const.html\#module-molmod.units}{the molmod routine}), defaults to ‘kjmol’


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} label for CV1 axis on plots, defaults to ‘CV1’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} label for CV2 axis on plots, defaults to ‘CV2’

\end{itemize}

\end{description}\end{quote}
\index{compute\_probdens() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{compute\_probdens()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.compute_probdens}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{compute\_probdens}}}{}{}
\sphinxAtStartPar
Compute the probability density profile associated with the free energy profile as given below and store internally in \sphinxtitleref{self.ps}
\begin{equation*}
\begin{split}p(q) = \frac{\exp\left(-\beta F(q)\right)}{\int_{-\infty}^{+\infty}\exp\left(-\beta F(q)\right)dq}\end{split}
\end{equation*}
\end{fulllineitems}

\index{copy() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{copy()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.copy}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{copy}}}{}{}
\sphinxAtStartPar
Make and return a copy of the current FreeEnergySurface2D instance.
\begin{quote}\begin{description}
\item[{Returns}] \leavevmode
\sphinxAtStartPar
a copy of the current instance

\item[{Return type}] \leavevmode
\sphinxAtStartPar
{\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D}]{\sphinxcrossref{FreeEnergySurface2D}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{crop() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{crop()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.crop}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{crop}}}{\emph{\DUrole{n}{cv1range}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{cv2range}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{return\_new\_fes}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Crop the free energy surface by removing all data for which either cv1 or cv2 is beyond a given range.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1range}} (\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{type}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} range of cv1 that will remain after cropping, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2range}} (\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{type}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} range of cv2 that will remain after cropping, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_new\_fes}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} if set to false, the cropping process will be applied on the existing instance, otherwise a copy will be returned, defaults to False

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
None or new instance of {\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{FreeEnergySurface2D}}}}} representing cropped FES, depending on \sphinxcode{\sphinxupquote{return\_new\_fes}}

\end{description}\end{quote}

\end{fulllineitems}

\index{detect\_clusters() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{detect\_clusters()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.detect_clusters}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{detect\_clusters}}}{\emph{\DUrole{n}{eps}\DUrole{o}{=}\DUrole{default_value}{1.5}}, \emph{\DUrole{n}{min\_samples}\DUrole{o}{=}\DUrole{default_value}{8}}, \emph{\DUrole{n}{metric}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}euclidean\textquotesingle{}}}, \emph{\DUrole{n}{fn\_plot}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{delete\_clusters}\DUrole{o}{=}\DUrole{default_value}{{[}\sphinxhyphen{} 1{]}}}}{}
\sphinxAtStartPar
Routine to apply \sphinxhref{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html}{the DBSCAN clustering algoritm as implemented in the Scikit Learn package} to the (CV1,CV2) grid points that correspond to finite free energies (i.e. not nan or inf) to detect clusters of neighboring points.

\sphinxAtStartPar
The DBSCAN algorithm first identifies the core samples, defined as samples for which at least \sphinxcode{\sphinxupquote{min\_samples}} other samples are within a distance of \sphinxcode{\sphinxupquote{eps}}. Next, the data is divided into clusters based on these core samples. A cluster is defined as a set of core samples that can be built by recursively taking a core sample, finding all of its neighbors that are core samples, finding all of their neighbors that are core samples, and so on. A cluster also has a set of non\sphinxhyphen{}core samples, which are samples that are neighbors of a core sample in the cluster but are not themselves core samples. Intuitively, these samples are on the fringes of a cluster. Each cluster is given an integer as label.

\sphinxAtStartPar
Any sample that is not a core sample, and is at least \sphinxcode{\sphinxupquote{eps}} in distance from any core sample, is considered an outlier by the algorithm and is what we here consider an isolated point/region. These points get the cluster label of \sphinxhyphen{}1.

\sphinxAtStartPar
Finally, all data points belonging to a cluster with label specified in \sphinxcode{\sphinxupquote{delete\_clusters}} will have theire free energy set to nan. A safe choice here is to just delete isolated regions, i.e. the point in cluster with label \sphinxhyphen{}1 (which is the default).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{eps}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} DBSCAN parameter representing maximum distance between two samples for them to be considered neighbors (for more, see \sphinxhref{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html}{DBSCAN documentation}), defaults to 1.5

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_samples}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} 
\sphinxAtStartPar
DBSCAN parameter representing the number of samples in a neighborhood for a point to be considered a core point (for more, see \sphinxhref{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html}{DBSCAN documentation}), defaults to 8


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{metric}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} 
\sphinxAtStartPar
DBSCAN parameter representing the metric used when calculating distance (for more, see \sphinxhref{https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html}{DBSCAN documentation}), defaults to ‘euclidean’


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn\_plot}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} if specified, a plot will be made (and written to \sphinxcode{\sphinxupquote{fn\_plot}}) visualizing the resulting clusters, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delete\_clusters}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} list of cluster names whos members will be deleted from the free energy surface data, defaults to {[}\sphinxhyphen{}1{]} meaning only isolated points (not belonging to a cluster) will be deleted.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{from\_histogram() (thermolib.thermodynamics.fep.FreeEnergySurface2D class method)@\spxentry{from\_histogram()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.from_histogram}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_histogram}}}{\emph{\DUrole{n}{histogram}}, \emph{\DUrole{n}{temp}}}{}
\sphinxAtStartPar
Use the estimated 2D probability histogram to construct the corresponding 2D free energy surface at the given temperature.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{histogram}} (\sphinxstyleliteralemphasis{\sphinxupquote{histogram.Histogram2D}}) \textendash{} histogram from which the free energy profile is computed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the temperature at which the histogram input data was simulated

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
free energy profile corresponding to the estimated probability histogram

\item[{Return type}] \leavevmode
\sphinxAtStartPar
cls

\end{description}\end{quote}

\end{fulllineitems}

\index{from\_txt() (thermolib.thermodynamics.fep.FreeEnergySurface2D class method)@\spxentry{from\_txt()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.from_txt}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_txt}}}{\emph{\DUrole{n}{fn}}, \emph{\DUrole{n}{temp}}, \emph{\DUrole{n}{cv1\_col}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{cv2\_col}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{f\_col}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{cv1\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{cv2\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{f\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{cv1\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV1\textquotesingle{}}}, \emph{\DUrole{n}{cv2\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV2\textquotesingle{}}}, \emph{\DUrole{n}{cv1\_range}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{cv2\_range}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{delimiter}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Read the free energy surface on a 2D grid as function of two collective variables from a txt file.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} the name of the txt file containing the data

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the temperature at which the free energy is constructed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the column in which the first collective variable is stored, defaults to 0

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the column in which the second collective variable is stored, defaults to 1

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{f\_col}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the column in which the free energy is stored, defaults to 2

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the unit in which the first CV values are stored, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the unit in which the second CV values are stored, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{f\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the unit in which the free energy values are stored, defaults to ‘kjmol’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the label for the CV1 axis in plots, defaults to ‘CV1’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the label for the CV2 axis in plots, defaults to ‘CV2’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple/list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} {[}CVmin,CVmax{]} indicating to only read free energy for which the first CV in the given range, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{tuple/list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} {[}CVmin,CVmax{]} indicating to only read free energy for which the second CV in the given range, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delimiter}} (\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{type}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} {[}description{]}, defaults to None

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
2D free energy surface

\item[{Return type}] \leavevmode
\sphinxAtStartPar
{\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D}]{\sphinxcrossref{FreeEnergySurface2D}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{plot() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{plot()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.plot}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{plot}}}{\emph{\DUrole{n}{fn\_png}}, \emph{\DUrole{n}{obs}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}F\textquotesingle{}}}, \emph{\DUrole{n}{cv1\_lims}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{cv2\_lims}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{lims}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{ncolors}\DUrole{o}{=}\DUrole{default_value}{8}}, \emph{\DUrole{n}{scale}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}lin\textquotesingle{}}}}{}
\sphinxAtStartPar
Simple routine to make a 2D contour plot of either the free energy F or probability distribution P as specified in \sphinxcode{\sphinxupquote{obs}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn\_png}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} File name to write the plot to. The extension determines the format (PNG or PDF).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{obs}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{choices=}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{\textquotesingle{}F\textquotesingle{}}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{\textquotesingle{}P\textquotesingle{}}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} Specification which observable should be plotted, should be ‘F’ for free energy or ‘P’ for probability. Defaults to ‘F’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv1\_lims}} (\sphinxstyleliteralemphasis{\sphinxupquote{tupple/list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} range defining the plot limits of CV1, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv2\_lims}} (\sphinxstyleliteralemphasis{\sphinxupquote{tupple/list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} range defining the plot limits of CV1, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lims}} (\sphinxstyleliteralemphasis{\sphinxupquote{tupple/list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} range defining the plot limits for the observable, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ncolors}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} number of different colors included in contour plot, defaults to 8

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{scale}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{choices=}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{\textquotesingle{}lin\textquotesingle{}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{\textquotesingle{}log\textquotesingle{}}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} scal for the observable, should be ‘lin’ for linear or ‘log’ for logarithmic. Ddefaults to ‘lin’

\end{itemize}

\item[{Raises}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{IOError}} \textendash{} if invalid observable is given, see doc above for possible choices.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{IOError}} \textendash{} if invalid scale is given, see doc above for possible choices.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{project\_average() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{project\_average()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.project_average}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{project\_average}}}{\emph{cv\_unit=\textquotesingle{}au\textquotesingle{}}, \emph{return\_class=\textless{}class \textquotesingle{}thermolib.thermodynamics.fep.BaseFreeEnergyProfile\textquotesingle{}\textgreater{}}}{}
\sphinxAtStartPar
Construct a 1D free energy profile representing the projection of the 2D FES F2(CV1,CV2) onto the average q=(CV1+CV2)/2 of the collective variables:
\begin{equation*}
\begin{split}F1(q) = -k_B T \log\left( 2\int_{-\infty}^{+\infty} e^{-\beta F2(x,2q-x}dx \right)\end{split}
\end{equation*}
\sphinxAtStartPar
with \(q=0.5\dot(CV1+CV2)\). This projection is implemented by first projecting the probability density and afterwards reconstructing the free energy.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit for the new CV for plotting purposes, defaults to au.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_class}} (\sphinxstyleliteralemphasis{\sphinxupquote{python class object}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class of which an instance will finally be returned. Defaults to BaseFreeEnergyProfile

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
projected 1D free energy profile

\item[{Return type}] \leavevmode
\sphinxAtStartPar
see return\_class argument

\end{description}\end{quote}

\end{fulllineitems}

\index{project\_cv1() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{project\_cv1()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.project_cv1}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{project\_cv1}}}{\emph{return\_class=\textless{}class \textquotesingle{}thermolib.thermodynamics.fep.BaseFreeEnergyProfile\textquotesingle{}\textgreater{}}}{}
\sphinxAtStartPar
Construct a 1D free energy profile representing the projection of the 2D FES F2(CV1,CV2) onto q=CV1. This is implemented as follows:
\begin{equation*}
\begin{split}F1(q) = -k_B T \log\left( \int_{-\infty}^{+\infty} e^{-\beta F2(q,y}dy \right)\end{split}
\end{equation*}\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_class}} (\sphinxstyleliteralemphasis{\sphinxupquote{python class object}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class of which an instance will finally be returned. Defaults to BaseFreeEnergyProfile

\item[{Returns}] \leavevmode
\sphinxAtStartPar
projected 1D free energy profile

\item[{Return type}] \leavevmode
\sphinxAtStartPar
see return\_class argument

\end{description}\end{quote}

\end{fulllineitems}

\index{project\_cv2() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{project\_cv2()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.project_cv2}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{project\_cv2}}}{\emph{return\_class=\textless{}class \textquotesingle{}thermolib.thermodynamics.fep.BaseFreeEnergyProfile\textquotesingle{}\textgreater{}}}{}
\sphinxAtStartPar
Construct a 1D free energy profile representing the projection of the 2D FES F2(CV1,CV2) onto q=CV2. This is implemented as follows:
\begin{equation*}
\begin{split}F1(q) = -k_B T \log\left( \int_{-\infty}^{+\infty} e^{-\beta F2(x,q}dx \right)\end{split}
\end{equation*}\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_class}} (\sphinxstyleliteralemphasis{\sphinxupquote{python class object}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class of which an instance will finally be returned. Defaults to BaseFreeEnergyProfile

\item[{Returns}] \leavevmode
\sphinxAtStartPar
projected 1D free energy profile

\item[{Return type}] \leavevmode
\sphinxAtStartPar
see return\_class argument

\end{description}\end{quote}

\end{fulllineitems}

\index{project\_difference() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{project\_difference()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.project_difference}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{project\_difference}}}{\emph{sign=1}, \emph{cv\_unit=\textquotesingle{}au\textquotesingle{}}, \emph{return\_class=\textless{}class \textquotesingle{}thermolib.thermodynamics.fep.BaseFreeEnergyProfile\textquotesingle{}\textgreater{}}}{}
\sphinxAtStartPar
Construct a 1D free energy profile representing the projection of the 2D FES onto the difference of collective variables:
\begin{equation*}
\begin{split}F1(q) = -k_B T \log\left( \int_{-\infty}^{+\infty} e^{-\beta F2(x,x+q)}dx \right)\end{split}
\end{equation*}
\sphinxAtStartPar
with \(q=CV2-CV1\). This projection is implemented by first projecting the probability density and afterwards reconstructing the free energy.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sign}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} If sign is set to 1, the projection is done on q=CV2\sphinxhyphen{}CV1, if it is set to \sphinxhyphen{}1, projection is done to q=CV1\sphinxhyphen{}CV2 instead. Defaults to 1

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit for the new CV for plotting purposes, defaults to au.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_class}} (\sphinxstyleliteralemphasis{\sphinxupquote{python class object}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class of which an instance will finally be returned. Defaults to BaseFreeEnergyProfile

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
projected 1D free energy profile

\item[{Return type}] \leavevmode
\sphinxAtStartPar
see return\_class argument

\end{description}\end{quote}

\end{fulllineitems}

\index{project\_function() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{project\_function()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.project_function}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{project\_function}}}{\emph{function}, \emph{cvs}, \emph{delta=0.001}, \emph{cv\_label=\textquotesingle{}CV\textquotesingle{}}, \emph{cv\_unit=\textquotesingle{}au\textquotesingle{}}, \emph{return\_class=\textless{}class \textquotesingle{}thermolib.thermodynamics.fep.BaseFreeEnergyProfile\textquotesingle{}\textgreater{}}}{}
\sphinxAtStartPar
Routine to implement the general projection of a 2D FES onto a collective variable defined by the given function (which takes the original two CVs as arguments).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{function}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}) \textendash{} function in terms of the original CVs to define the new CV to project upon

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cvs}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} grid for the new CV

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delta}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} width of the single\sphinxhyphen{}bin approximation of the delta function applied in the projection formula. Defaults to 1e\sphinxhyphen{}3 a.u.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} label for the new CV, defaults to CV.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit for the new CV for plotting purposes, defaults to au.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{return\_class}} (\sphinxstyleliteralemphasis{\sphinxupquote{python class object}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} The class of which an instance will finally be returned. Defaults to BaseFreeEnergyProfile

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
projected 1D free energy profile

\item[{Return type}] \leavevmode
\sphinxAtStartPar
see return\_class argument

\end{description}\end{quote}

\end{fulllineitems}

\index{rotate() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{rotate()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.rotate}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{rotate}}}{\emph{\DUrole{n}{interpolate}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Transform the free energy profile in terms of the following two new collective variables:
\begin{equation*}
\begin{split}\begin{aligned}
    u &= \frac{CV_1+CV_2}{2} \\
    v &= CV_2 - CV_1
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
This transformation represents a simple rotation (and mirroring). From probability theory we find the transformation formula:
\begin{equation*}
\begin{split}F_\text{rot}(u,v) = F\left(u-\frac{v}{2}, u+\frac{v}{2}\right))\end{split}
\end{equation*}
\sphinxAtStartPar
The uniform (u,v)\sphinxhyphen{}grid introduces new grid points in between the original (cv1,cv2) grid points. If interpolate is True, the free energy for these points is interpolated if all four neighbors have defined (i.e. not nan) free energies.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{interpolate}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} if set to true, interpolate undefined grid points (arrising due to rotation) between neighbors, defaults to True

\item[{Returns}] \leavevmode
\sphinxAtStartPar
rotated free energy surface

\item[{Return type}] \leavevmode
\sphinxAtStartPar
{\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D}]{\sphinxcrossref{FreeEnergySurface2D}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{savetxt() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{savetxt()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.savetxt}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{savetxt}}}{\emph{\DUrole{n}{fn\_txt}}}{}
\sphinxAtStartPar
Save the free energy profile as txt file

\end{fulllineitems}

\index{set\_ref() (thermolib.thermodynamics.fep.FreeEnergySurface2D method)@\spxentry{set\_ref()}\spxextra{thermolib.thermodynamics.fep.FreeEnergySurface2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.fep.FreeEnergySurface2D.set_ref}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_ref}}}{\emph{\DUrole{n}{ref}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}min\textquotesingle{}}}}{}
\sphinxAtStartPar
Set the energy reference of the free energy surface.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ref}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} the choice for the energy reference. Currently only one possibility is implemented, i.e. \sphinxstyleemphasis{m} or \sphinxstyleemphasis{min} for the global minimum. Defaults to ‘min’.

\item[{Raises}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{IOError}} \textendash{} invalid value for keyword argument ref is given. See doc above for choices.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subsubsection{Histograms \textendash{} \sphinxstyleliteralintitle{\sphinxupquote{thermodynamics.histogram}}}
\label{\detokenize{rg:histograms-thermodynamics-histogram}}\index{Histogram1D (class in thermolib.thermodynamics.histogram)@\spxentry{Histogram1D}\spxextra{class in thermolib.thermodynamics.histogram}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.histogram.}}\sphinxbfcode{\sphinxupquote{Histogram1D}}}{\emph{\DUrole{n}{cvs}}, \emph{\DUrole{n}{ps}}, \emph{\DUrole{n}{plower}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{pupper}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{cv\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{cv\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV\textquotesingle{}}}}{}
\sphinxAtStartPar
Class to implement the estimation of a probability histogram in terms of a collective variable from a trajectory series corresponding to that collective variable.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cvs}} \textendash{} array corresponding the collective variable grid points

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ps}} \textendash{} array corresponding to the histogram probability values at the grid points

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plower}} \textendash{} lower bound of the error on the probability histogram values, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pupper}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} upper bound of the error on the probability histogram values, defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the unit in which cv will be plotted/printed, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the label of the cv that will be used on plots, defaults to ‘CV’

\end{itemize}

\end{description}\end{quote}
\index{from\_average() (thermolib.thermodynamics.histogram.Histogram1D class method)@\spxentry{from\_average()}\spxextra{thermolib.thermodynamics.histogram.Histogram1D class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D.from_average}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_average}}}{\emph{\DUrole{n}{histograms}}, \emph{\DUrole{n}{error\_estimate}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{nsigma}\DUrole{o}{=}\DUrole{default_value}{2}}}{}
\sphinxAtStartPar
Start from a set of histograms and compute and return the averaged histogram. If error\_estimate is set to ‘std’, an error on the histogram will be computed from the standard deviation within the set of histograms.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{histograms}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}{\hyperref[\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{Histogram1D}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} set of histrograms to be averaged

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{error\_estimate}} \textendash{} 
\sphinxAtStartPar
indicate if and how to perform error analysis. One of following options is available:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{std} \textendash{} compute error from the standard deviation within the set of histograms.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{None} \textendash{} do not estimate the error.

\end{itemize}


\end{itemize}

\end{description}\end{quote}

\sphinxAtStartPar
Defaults to None, i.e. no error estimate.
:type error\_estimate: str, optional
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nsigma}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} only relevant when error estimation is turned on (i.e. when keyword \sphinxcode{\sphinxupquote{error\_estimate}} is not None), this option defines how large the error interval should be in terms of the standard deviation sigma. A \sphinxcode{\sphinxupquote{nsigma=2}} implies a 2\sphinxhyphen{}sigma error bar (corresponding to 95\% confidence interval) will be returned. Defaults to 2

\item[{Returns}] \leavevmode
\sphinxAtStartPar
averages histogram

\item[{Return type}] \leavevmode
\sphinxAtStartPar
Histrogram1D

\end{description}\end{quote}

\end{fulllineitems}

\index{from\_fep() (thermolib.thermodynamics.histogram.Histogram1D class method)@\spxentry{from\_fep()}\spxextra{thermolib.thermodynamics.histogram.Histogram1D class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D.from_fep}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_fep}}}{\emph{\DUrole{n}{fep}}, \emph{\DUrole{n}{temp}}}{}
\sphinxAtStartPar
Use the given free energy profile to construct the corresponding probability histogram at the given temperature.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fep}} (\sphinxstyleliteralemphasis{\sphinxupquote{fep.BaseFreeEnergyProfile/fep.SimpleFreeEnergyProfile}}) \textendash{} free energy profile from which the probability histogram is computed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the temperature at which the histogram input data was simulated

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
probability histogram corresponding to the given free energy profile

\item[{Return type}] \leavevmode
\sphinxAtStartPar
{\hyperref[\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D}]{\sphinxcrossref{Histogram1D}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{from\_single\_trajectory() (thermolib.thermodynamics.histogram.Histogram1D class method)@\spxentry{from\_single\_trajectory()}\spxextra{thermolib.thermodynamics.histogram.Histogram1D class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D.from_single_trajectory}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_single\_trajectory}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{bins}}, \emph{\DUrole{n}{error\_estimate}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{nsigma}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{cv\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{cv\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV\textquotesingle{}}}}{}
\sphinxAtStartPar
Routine to estimate of a probability histogram in terms of a collective variable from a trajectory series corresponding to that collective variable.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} array corresponding to the trajectory series of the collective variable

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bins}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} array representing the edges of the bins for which a histogram will be constructed. This argument is parsed to \sphinxhref{https://numpy.org/doc/stable/reference/generated/numpy.histogram.html}{the numpy.histogram routine}. Hence, more information on its meaning and allowed values can be found there.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{error\_estimate}} \textendash{} 
\sphinxAtStartPar
indicate if and how to perform error analysis. One of following options is available:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{mle\_p} \textendash{} compute error through the asymptotic normality of the maximum likelihood estimator for the probability itself. WARNING: due to positivity constraint of the probability, this only works for low variance. Otherwise the standard error interval for the normal distribution (i.e. mle +\sphinxhyphen{} n*sigma) might give rise to negative lower error bars.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{mle\_f} \textendash{} compute error through the asymptotic normality of the maximum likelihood estimator for \sphinxhyphen{}log(p) (hence for the beta\sphinxhyphen{}scaled free energy). This estimation does not suffor from the same WARNING as for \sphinxcode{\sphinxupquote{mle\_p}}. Furthermore, in case of low variance, the error estimation using \sphinxcode{\sphinxupquote{mle\_f}} and \sphinxcode{\sphinxupquote{mle\_p}} are consistent (i.e. one can be computed from the other using f=\sphinxhyphen{}log(p)).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{None} \textendash{} do not estimate the error.

\end{itemize}


\end{itemize}

\end{description}\end{quote}

\sphinxAtStartPar
Defaults to None, i.e. no error estimate.
:type error\_estimate: str, optional
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nsigma}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} only relevant when error estimation is turned on (i.e. when keyword \sphinxcode{\sphinxupquote{error\_estimate}} is not None), this option defines how large the error interval should be in terms of the standard deviation sigma. A \sphinxcode{\sphinxupquote{nsigma=2}} implies a 2\sphinxhyphen{}sigma error bar (corresponding to 95\% confidence interval) will be returned. Defaults to 2

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the unit in which cv will be plotted/printed, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the label of the cv that will be used on plots, defaults to ‘CV’

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{from\_wham() (thermolib.thermodynamics.histogram.Histogram1D class method)@\spxentry{from\_wham()}\spxextra{thermolib.thermodynamics.histogram.Histogram1D class method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D.from_wham}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{classmethod }}\sphinxbfcode{\sphinxupquote{from\_wham}}}{\emph{\DUrole{n}{bins}}, \emph{\DUrole{n}{trajectories}}, \emph{\DUrole{n}{biasses}}, \emph{\DUrole{n}{temp}}, \emph{\DUrole{n}{error\_estimate}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{nsigma}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{bias\_subgrid\_num}\DUrole{o}{=}\DUrole{default_value}{20}}, \emph{\DUrole{n}{Nscf}\DUrole{o}{=}\DUrole{default_value}{1000}}, \emph{\DUrole{n}{convergence}\DUrole{o}{=}\DUrole{default_value}{1e\sphinxhyphen{}06}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{cv\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{cv\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV\textquotesingle{}}}}{}
\sphinxAtStartPar
Routine that implements the Weighted Histogram Analysis Method (WHAM) for reconstructing the overall probability histogram from a series of biased molecular simulations.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bins}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} number of bins for the CV grid or array representing the bin edges for th CV grid.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{trajectories}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}\sphinxstyleliteralemphasis{\sphinxupquote{/np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} list or array of numpy arrays containing the CV trajectory data for each simulation. Alternatively, a list of PLUMED file names containing the trajectory data can be specified as well. The arguments trajectories and biasses should be of the same length.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{biasses}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} list of callables, each representing a function to compute the bias at a given value of the collective variable. The arguments trajectories and biasses should be of the same length.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the temperature at which all simulations were performed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{error\_estimate}} \textendash{} 
\sphinxAtStartPar
indicate if and how to perform error analysis. One of following options is available:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{mle\_p} \textendash{} compute error through the asymptotic normality of the maximum likelihood estimator for the probability itself. WARNING: due to positivity constraint of the probability, this only works for high probability and low variance. Otherwise the standard error interval for the normal distribution (i.e. mle +\sphinxhyphen{} n*sigma) might give rise to negative lower error bars.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{mle\_f} \textendash{} compute error through the asymptotic normality of the maximum likelihood estimator for \sphinxhyphen{}log(p) (hence for the beta\sphinxhyphen{}scaled free energy). This estimation does not suffor from the same WARNING as for \sphinxcode{\sphinxupquote{mle\_p}}. Furthermore, in case of high probability and low variance, the error estimation using \sphinxcode{\sphinxupquote{mle\_f}} and \sphinxcode{\sphinxupquote{mle\_p}} are consistent (i.e. one can be computed from the other using f=\sphinxhyphen{}log(p)).

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{None} \textendash{} do not estimate the error.

\end{itemize}


\end{itemize}

\end{description}\end{quote}

\sphinxAtStartPar
Defaults to None, i.e. no error estimate.
:type error\_estimate: str, optional
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nsigma}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} only relevant when error estimation is turned on (i.e. when keyword \sphinxcode{\sphinxupquote{error\_estimate}} is not None), this option defines how large the error interval should be in terms of the standard deviation sigma. A \sphinxcode{\sphinxupquote{nsigma=2}} implies a 2\sphinxhyphen{}sigma error bar (corresponding to 95\% confidence interval) will be returned. Defaults to 2

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bias\_subgrid\_num}} (\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to 20}}) \textendash{} the number of grid points for the sub\sphinxhyphen{}grid used to compute the integrated boltzmann factor of the bias in each CV bin.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Nscf}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to 1000}}) \textendash{} the maximum number of steps in the self\sphinxhyphen{}consistent loop to solve the WHAM equations

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{convergence}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to 1e\sphinxhyphen{}6}}) \textendash{} convergence criterium for the WHAM self consistent solver. The SCF loop will stop whenever the integrated absolute difference between consecutive probability densities is less then the specified value.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} set to True to turn on more verbosity during the self consistent solution cycles of the WHAM equations, defaults to False.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the unit in which cv will be plotted/printed, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the label of the cv that will be used on plots, defaults to ‘CV’

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
probability histogram

\item[{Return type}] \leavevmode
\sphinxAtStartPar
{\hyperref[\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D}]{\sphinxcrossref{Histogram1D}}}

\end{description}\end{quote}

\end{fulllineitems}

\index{plot() (thermolib.thermodynamics.histogram.Histogram1D method)@\spxentry{plot()}\spxextra{thermolib.thermodynamics.histogram.Histogram1D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D.plot}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{plot}}}{\emph{\DUrole{n}{fn}}, \emph{\DUrole{n}{temp}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{flim}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Make a plot of the probability histogram and possible the corresponding free energy (if the argument \sphinxcode{\sphinxupquote{temp}} is specified).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} file name of the resulting plot

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the temperature for conversion of histogram to free energy profile. Specifying this number will add a free energy plot. Defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{flim}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} upper limit of the free energy axis in plots. Defaults to None

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{plot\_histograms() (thermolib.thermodynamics.histogram method)@\spxentry{plot\_histograms()}\spxextra{thermolib.thermodynamics.histogram method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.histogram.plot_histograms}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{histogram.}}\sphinxbfcode{\sphinxupquote{plot\_histograms}}}{\emph{\DUrole{n}{histograms}}, \emph{\DUrole{n}{temp}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{labels}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{flims}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{colors}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{linestyles}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{linewidths}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{set\_ref}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}min\textquotesingle{}}}}{}
\sphinxAtStartPar
Make a plot to compare multiple probability histograms and possible the corresponding free energy (if the argument \sphinxcode{\sphinxupquote{temp}} is specified).
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} file name to write the figure to, the extension determines the format (PNG or PDF).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{histograms}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}{\hyperref[\detokenize{rg:thermolib.thermodynamics.histogram.Histogram1D}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{Histogram1D}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} list of histrograms to plot

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float/list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}\sphinxstyleliteralemphasis{\sphinxupquote{/np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} if defined, the free energy profile corresponding to each histogram will be computed and plotted with its corresponding temperature. If a single float is given, all histograms are assumed to be at the same temperature, if a list or array of floats is given, each entry is assumed to be the temperature of the corresponding entry in the input list of histograms. Defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{labels}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} list of labels for the legend, one for each histogram. Defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{flims}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} {[}lower,upper{]} limit of the free energy axis in plots. Defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{colors}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} List of matplotlib color definitions for each entry in histograms. If an entry is None, a color will be chosen internally. Defaults to None, implying all colors are chosen internally.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{linestyles}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} List of matplotlib line style definitions for each entry in histograms. If an entry is None, the default line style of ‘\sphinxhyphen{}‘ will be chosen . Defaults to None, implying all line styles are set to the default of ‘\sphinxhyphen{}‘.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{linewidths}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} List of matplotlib line width definitions for each entry in histograms. If an entry is None, the default line width of 1 will be chosen. Defaults to None, implying all line widths are set to the default of 2.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{set\_ref}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} set the reference of each corresponding free energy profile, see documentation of the set\_ref routine of the free energy profile class for more information on the allowed values. Defaults to min, implying each profile is shifted vertically untill the minimum value equals zero.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{Collective variable \textendash{} \sphinxstyleliteralintitle{\sphinxupquote{thermodynamics.cv}}}
\label{\detokenize{rg:module-thermolib.thermodynamics.cv}}\label{\detokenize{rg:collective-variable-thermodynamics-cv}}\index{module@\spxentry{module}!thermolib.thermodynamics.cv@\spxentry{thermolib.thermodynamics.cv}}\index{thermolib.thermodynamics.cv@\spxentry{thermolib.thermodynamics.cv}!module@\spxentry{module}}\index{Average (class in thermolib.thermodynamics.cv)@\spxentry{Average}\spxextra{class in thermolib.thermodynamics.cv}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.cv.Average}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.cv.}}\sphinxbfcode{\sphinxupquote{Average}}}{\emph{\DUrole{n}{cv1}}, \emph{\DUrole{n}{cv2}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Class to implement a collective variable representing the average of two
other collective variables:
\begin{quote}

\sphinxAtStartPar
CV = 0.5*(CV1 + CV2)
\end{quote}

\end{fulllineitems}

\index{CoordinationNumber (class in thermolib.thermodynamics.cv)@\spxentry{CoordinationNumber}\spxextra{class in thermolib.thermodynamics.cv}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.cv.CoordinationNumber}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.cv.}}\sphinxbfcode{\sphinxupquote{CoordinationNumber}}}{\emph{\DUrole{n}{pairs}}, \emph{\DUrole{n}{r0}\DUrole{o}{=}\DUrole{default_value}{3.779452267842504}}, \emph{\DUrole{n}{nn}\DUrole{o}{=}\DUrole{default_value}{6}}, \emph{\DUrole{n}{nd}\DUrole{o}{=}\DUrole{default_value}{12}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{unit\_cell\_pars}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Class to implement a collective variable representing the coordination
number of a certain atom pair or a set of atom pairs. If n atom pairs
are defined, the coordination number should be a number between 0 and n.
\begin{quote}

\sphinxAtStartPar
CN = sum( (1\sphinxhyphen{}x\_ij\textasciicircum{}nn)/(1\sphinxhyphen{}x\_ij\textasciicircum{}nd), ij in pairs)
\end{quote}

\sphinxAtStartPar
with
\begin{quote}

\sphinxAtStartPar
x\_ij = r\_ij/r0
\end{quote}

\sphinxAtStartPar
in which r\_ij is the distance between the atoms of pair ij, r0 is a
reference distance set to 2 angstrom by default but can ge defined by
the user and nn and nd are integers that are set to 6,12 by default but
can also be defined by the user.

\end{fulllineitems}

\index{Difference (class in thermolib.thermodynamics.cv)@\spxentry{Difference}\spxextra{class in thermolib.thermodynamics.cv}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.cv.Difference}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.cv.}}\sphinxbfcode{\sphinxupquote{Difference}}}{\emph{\DUrole{n}{cv1}}, \emph{\DUrole{n}{cv2}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Class to implement a collective variable representing the difference
between two other collective variables:
\begin{quote}

\sphinxAtStartPar
CV = CV2 \sphinxhyphen{} CV1
\end{quote}

\end{fulllineitems}

\index{Distance (class in thermolib.thermodynamics.cv)@\spxentry{Distance}\spxextra{class in thermolib.thermodynamics.cv}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.cv.Distance}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.cv.}}\sphinxbfcode{\sphinxupquote{Distance}}}{\emph{\DUrole{n}{index1}}, \emph{\DUrole{n}{index2}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{unit\_cell\_pars}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Class to implement a collective variable representing the distance
between two atoms given by index1 and index2.
\index{compute() (thermolib.thermodynamics.cv.Distance method)@\spxentry{compute()}\spxextra{thermolib.thermodynamics.cv.Distance method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.cv.Distance.compute}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{compute}}}{\emph{\DUrole{n}{coords}}, \emph{\DUrole{n}{deriv}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Compute the value of the collective variable given the coordinates.
If deriv is set to True, also compute and return the analytical
derivative of Q towards the cartesian coordinates.

\end{fulllineitems}


\end{fulllineitems}

\index{DistanceCOP (class in thermolib.thermodynamics.cv)@\spxentry{DistanceCOP}\spxextra{class in thermolib.thermodynamics.cv}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.cv.DistanceCOP}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.cv.}}\sphinxbfcode{\sphinxupquote{DistanceCOP}}}{\emph{\DUrole{n}{index1}}, \emph{\DUrole{n}{index2a}}, \emph{\DUrole{n}{index2b}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{unit\_cell\_pars}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Class to implement a collective variable representing the distance
between an atom (index1) and the center of position (i.e. the geometric
center) of two other atoms (index2a and index2b).

\end{fulllineitems}

\index{Minimum (class in thermolib.thermodynamics.cv)@\spxentry{Minimum}\spxextra{class in thermolib.thermodynamics.cv}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.cv.Minimum}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.cv.}}\sphinxbfcode{\sphinxupquote{Minimum}}}{\emph{\DUrole{n}{cv1}}, \emph{\DUrole{n}{cv2}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Class to implement a collective variable representing the minimum of two
other collective variables:
\begin{quote}

\sphinxAtStartPar
CV = min(CV1,CV2)
\end{quote}

\end{fulllineitems}

\index{OrthogonalDistanceToPore (class in thermolib.thermodynamics.cv)@\spxentry{OrthogonalDistanceToPore}\spxextra{class in thermolib.thermodynamics.cv}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.cv.OrthogonalDistanceToPore}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.cv.}}\sphinxbfcode{\sphinxupquote{OrthogonalDistanceToPore}}}{\emph{\DUrole{n}{ring\_indices}}, \emph{\DUrole{n}{guest\_indices}}, \emph{\DUrole{n}{masses}}, \emph{\DUrole{n}{unit\_cell\_pars}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{name}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Class to implement a collective variable that represents the orthogonal
distance between the center of mass of a guest molecule defined by its
atom indices (guest\_indices) on the one hand, and a pore ring defined
by the atom indices of its constituting atoms (ring\_indices) on the
other hand.

\end{fulllineitems}



\subsubsection{Bias potentials \textendash{} \sphinxstyleliteralintitle{\sphinxupquote{thermodynamics.bias}}}
\label{\detokenize{rg:module-thermolib.thermodynamics.bias}}\label{\detokenize{rg:bias-potentials-thermodynamics-bias}}\index{module@\spxentry{module}!thermolib.thermodynamics.bias@\spxentry{thermolib.thermodynamics.bias}}\index{thermolib.thermodynamics.bias@\spxentry{thermolib.thermodynamics.bias}!module@\spxentry{module}}\index{BiasPotential1D (class in thermolib.thermodynamics.bias)@\spxentry{BiasPotential1D}\spxextra{class in thermolib.thermodynamics.bias}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.bias.BiasPotential1D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.bias.}}\sphinxbfcode{\sphinxupquote{BiasPotential1D}}}{\emph{\DUrole{n}{name}}, \emph{\DUrole{n}{inverse\_cv}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
A base class for 1\sphinxhyphen{}dimensional bias potentials. This abstract class serves as a parent for inheriting child classes which should implement the \_\_call\_\_ routine.

\end{fulllineitems}

\index{BiasPotential2D (class in thermolib.thermodynamics.bias)@\spxentry{BiasPotential2D}\spxextra{class in thermolib.thermodynamics.bias}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.bias.BiasPotential2D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.bias.}}\sphinxbfcode{\sphinxupquote{BiasPotential2D}}}{\emph{\DUrole{n}{name}}, \emph{\DUrole{n}{inverse\_cv1}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{inverse\_cv2}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
A base class for 2\sphinxhyphen{}dimensional bias potentials. This abstract class serves as a parent for inheriting child classes which should implement the \_\_call\_\_ routine.

\end{fulllineitems}

\index{MultipleBiasses1D (class in thermolib.thermodynamics.bias)@\spxentry{MultipleBiasses1D}\spxextra{class in thermolib.thermodynamics.bias}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.bias.MultipleBiasses1D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.bias.}}\sphinxbfcode{\sphinxupquote{MultipleBiasses1D}}}{\emph{\DUrole{n}{biasses}}, \emph{\DUrole{n}{coeffs}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
A class to add multiple bias potentials together, possibly weighted by given coefficients.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{biasses}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}{\hyperref[\detokenize{rg:thermolib.thermodynamics.bias.BiasPotential1D}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{BiasPotential1D}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} list of bias potentials

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{coeffs}} (\sphinxstyleliteralemphasis{\sphinxupquote{list/np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} array of weigth coefficients. If not given, defaults to an array of ones (i.e. no weighting).

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{Parabola1D (class in thermolib.thermodynamics.bias)@\spxentry{Parabola1D}\spxextra{class in thermolib.thermodynamics.bias}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.bias.Parabola1D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.bias.}}\sphinxbfcode{\sphinxupquote{Parabola1D}}}{\emph{\DUrole{n}{name}}, \emph{\DUrole{n}{q0}}, \emph{\DUrole{n}{kappa}}, \emph{\DUrole{n}{inverse\_cv}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
A 1\sphinxhyphen{}dimensional parabolic bias potential.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} a name for the bias potential

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{q0}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the value of the parabola equilibruim (i.e. its minimum)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{kappa}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the force constant of the parabola

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{inverse\_cv}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to False}}) \textendash{} If set to True, the CV\sphinxhyphen{}axis will be inverted prior to bias evaluation

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{Parabola2D (class in thermolib.thermodynamics.bias)@\spxentry{Parabola2D}\spxextra{class in thermolib.thermodynamics.bias}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.bias.Parabola2D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.bias.}}\sphinxbfcode{\sphinxupquote{Parabola2D}}}{\emph{\DUrole{n}{name}}, \emph{\DUrole{n}{q01}}, \emph{\DUrole{n}{q02}}, \emph{\DUrole{n}{kappa1}}, \emph{\DUrole{n}{kappa2}}, \emph{\DUrole{n}{inverse\_cv1}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{inverse\_cv2}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
A 2\sphinxhyphen{}dimensional parabolic bias potential.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} a name for the bias potential

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{q01}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the value of the first collective variable corresponding to the parabola minimum

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{q02}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} the value of the second collective variable corresponding to the parabola minimum

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{kappa1}} \textendash{} the force constant of the parabola in the direction of the first collective variable

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{kappa2}} \textendash{} the force constant of the parabola in the direction of the second collective variable

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{inverse\_cv1}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to False}}) \textendash{} If set to True, the CV1\sphinxhyphen{}axis will be inverted prior to bias evaluation

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{inverse\_cv2}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to False}}) \textendash{} If set to True, the CV2\sphinxhyphen{}axis will be inverted prior to bias evaluation

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{PlumedSplinePotential1D (class in thermolib.thermodynamics.bias)@\spxentry{PlumedSplinePotential1D}\spxextra{class in thermolib.thermodynamics.bias}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.bias.PlumedSplinePotential1D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.bias.}}\sphinxbfcode{\sphinxupquote{PlumedSplinePotential1D}}}{\emph{\DUrole{n}{name}}, \emph{\DUrole{n}{fn}}, \emph{\DUrole{n}{inverse\_cv}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{scale}\DUrole{o}{=}\DUrole{default_value}{1.0}}}{}
\sphinxAtStartPar
A bias potential read from a PLUMED file, which is spline\sphinxhyphen{}interpolated.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} name for the external bias potential

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} specifies the filename of an external potential written on a grid and acting on the collective variable, as used with the EXTERNAL keyword in PLUMED.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit used to express the external potential, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{scale}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} scaling factor for the external potential (useful to invert free energy surfaces), default to 1.0

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{Polynomial1D (class in thermolib.thermodynamics.bias)@\spxentry{Polynomial1D}\spxextra{class in thermolib.thermodynamics.bias}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.bias.Polynomial1D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.bias.}}\sphinxbfcode{\sphinxupquote{Polynomial1D}}}{\emph{\DUrole{n}{name}}, \emph{\DUrole{n}{coeffs}}, \emph{\DUrole{n}{inverse\_cv}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}}{}
\sphinxAtStartPar
Bias potential given by general polynomial of any degree.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} name of the bias

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{coeffs}} (\sphinxstyleliteralemphasis{\sphinxupquote{list/np.ndarray}}) \textendash{} list of expansion coefficients of the polynomial in increasing order starting with the coefficient of power 0. The degree of the polynomial is given by len(coeffs)\sphinxhyphen{}1

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\subsubsection{Conditional probability \textendash{} \sphinxstyleliteralintitle{\sphinxupquote{thermodynamics.condprob}}}
\label{\detokenize{rg:module-thermolib.thermodynamics.condprob}}\label{\detokenize{rg:conditional-probability-thermodynamics-condprob}}\index{module@\spxentry{module}!thermolib.thermodynamics.condprob@\spxentry{thermolib.thermodynamics.condprob}}\index{thermolib.thermodynamics.condprob@\spxentry{thermolib.thermodynamics.condprob}!module@\spxentry{module}}\index{ConditionalProbability1D1D (class in thermolib.thermodynamics.condprob)@\spxentry{ConditionalProbability1D1D}\spxextra{class in thermolib.thermodynamics.condprob}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D1D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.condprob.}}\sphinxbfcode{\sphinxupquote{ConditionalProbability1D1D}}}{\emph{\DUrole{n}{q1s}}, \emph{\DUrole{n}{cvs}}, \emph{\DUrole{n}{q1\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Q\textquotesingle{}}}, \emph{\DUrole{n}{cv\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV\textquotesingle{}}}}{}
\sphinxAtStartPar
Routine to store and compute conditional probabilities of the form \(p(q_1|cv)\) which allow to convert a free energy profile in terms of the collective variable \(cv\) to a free energy profile in terms of the collective variable \(q_1\).
\index{process\_trajectory\_cvs() (thermolib.thermodynamics.condprob.ConditionalProbability1D1D method)@\spxentry{process\_trajectory\_cvs()}\spxextra{thermolib.thermodynamics.condprob.ConditionalProbability1D1D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D1D.process_trajectory_cvs}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process\_trajectory\_cvs}}}{\emph{\DUrole{n}{fns}}, \emph{\DUrole{n}{col\_q1}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{col\_cv}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{finish}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Compute the conditional probability p(q1|cv) (and norm for final normalisation) by processing a series of CV trajectory files. Each CV trajectory file contains rows of the form
\begin{quote}

\sphinxAtStartPar
time q1 cv
\end{quote}

\sphinxAtStartPar
If the trajectory file contains this data in a different order, it can be accounted for using the col\_xx keyword arguments.

\end{fulllineitems}

\index{process\_trajectory\_xyz() (thermolib.thermodynamics.condprob.ConditionalProbability1D1D method)@\spxentry{process\_trajectory\_xyz()}\spxextra{thermolib.thermodynamics.condprob.ConditionalProbability1D1D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D1D.process_trajectory_xyz}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process\_trajectory\_xyz}}}{\emph{\DUrole{n}{fns}}, \emph{\DUrole{n}{Q1}}, \emph{\DUrole{n}{CV}}, \emph{\DUrole{n}{finish}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Compute the conditional probability p(q1|cv) (and norm for final normalisation) by processing a series of XYZ trajectory files. The final probability is estimated as the average over all given files. These files may also contain data from biased simulations.

\end{fulllineitems}

\index{transform() (thermolib.thermodynamics.condprob.ConditionalProbability1D1D method)@\spxentry{transform()}\spxextra{thermolib.thermodynamics.condprob.ConditionalProbability1D1D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D1D.transform}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{transform}}}{\emph{\DUrole{n}{fep}}, \emph{\DUrole{n}{cv\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{f\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{cv\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV\textquotesingle{}}}}{}
\sphinxAtStartPar
Transform the provided 1D FES to a different 1D FES using the current conditional probability according to the formula
\begin{equation*}
\begin{split}F(q) &= -kT \ln\left(\int p(q|v)\cdot e^{-\beta F(v)} dv\right)\end{split}
\end{equation*}\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fep}} (\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{child of}}\sphinxstyleliteralemphasis{\sphinxupquote{) }}{\hyperref[\detokenize{rg:thermolib.thermodynamics.fep.BaseFreeEnergyProfile}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{BaseFreeEnergyProfile}}}}}) \textendash{} the free energy profile F(v) which will be transformed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to atomic units}}) \textendash{} the unit to be used in plotting and printing of the new cv

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{f\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to kJ/mol}}) \textendash{} the unit of the the transformed free energy profile to be used in plotting and printing of energies

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{cv\_label}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{defaults to CV}}) \textendash{} the label of the new collective variable to be used in plot labels

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{ConditionalProbability1D2D (class in thermolib.thermodynamics.condprob)@\spxentry{ConditionalProbability1D2D}\spxextra{class in thermolib.thermodynamics.condprob}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D2D}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.thermodynamics.condprob.}}\sphinxbfcode{\sphinxupquote{ConditionalProbability1D2D}}}{\emph{\DUrole{n}{q1s}}, \emph{\DUrole{n}{q2s}}, \emph{\DUrole{n}{cvs}}, \emph{\DUrole{n}{q1\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Q1\textquotesingle{}}}, \emph{\DUrole{n}{q2\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Q2\textquotesingle{}}}, \emph{\DUrole{n}{cv\_label}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}CV\textquotesingle{}}}}{}
\sphinxAtStartPar
Class to store and compute conditional probabilities of the form \(p(q_1,q_2|cv)\) which can be used to transform a 1D free energy profile in terms of the collective variable \sphinxstyleemphasis{cv} towards a 2D free energy surface in terms of the collective variables \(q_{1}\) and \(q_{2}\).
\index{process\_trajectory\_cvs() (thermolib.thermodynamics.condprob.ConditionalProbability1D2D method)@\spxentry{process\_trajectory\_cvs()}\spxextra{thermolib.thermodynamics.condprob.ConditionalProbability1D2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D2D.process_trajectory_cvs}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process\_trajectory\_cvs}}}{\emph{\DUrole{n}{fns}}, \emph{\DUrole{n}{col\_q1}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{col\_q2}\DUrole{o}{=}\DUrole{default_value}{2}}, \emph{\DUrole{n}{col\_cv}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{finish}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Routine to update conditional probability \(p(q_1,q_2|v)\) (and norm for final normalisation) by processing a series of CV trajectory file. Each CV trajectory file contains rows of the form
\begin{quote}

\sphinxAtStartPar
time q1 q2 v
\end{quote}

\sphinxAtStartPar
If the trajectory file contains this data in a different order, it can be accounted for using the col\_xx keyword arguments. Similar constraints apply to these CV trajectory files as specified in the routine {\hyperref[\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D2D.process_trajectory_xyz}]{\sphinxcrossref{\sphinxcode{\sphinxupquote{process\_trajectory\_xyz()}}}}}.

\sphinxAtStartPar
Warning: after all trajectories have been processes, you need to manually call the finish routine!

\end{fulllineitems}

\index{process\_trajectory\_xyz() (thermolib.thermodynamics.condprob.ConditionalProbability1D2D method)@\spxentry{process\_trajectory\_xyz()}\spxextra{thermolib.thermodynamics.condprob.ConditionalProbability1D2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D2D.process_trajectory_xyz}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process\_trajectory\_xyz}}}{\emph{\DUrole{n}{fns}}, \emph{\DUrole{n}{Q1}}, \emph{\DUrole{n}{Q2}}, \emph{\DUrole{n}{CV}}, \emph{\DUrole{n}{finish}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\sphinxAtStartPar
Compute the conditional probability \(p(q_1,q_2|v)\) (and norm for final normalisation) by processing a series of XYZ trajectory files. The final probability is estimated as the average over all given files. These files may also contain data from biased simulations as long as the bias is constant over the simulation. For example, data from Umbrella Sampling is OK, while data from metadynamica itself is not. Data obtained from a regular MD with the final MTD profile as bias is OK.

\end{fulllineitems}

\index{transform() (thermolib.thermodynamics.condprob.ConditionalProbability1D2D method)@\spxentry{transform()}\spxextra{thermolib.thermodynamics.condprob.ConditionalProbability1D2D method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.thermodynamics.condprob.ConditionalProbability1D2D.transform}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{transform}}}{\emph{\DUrole{n}{fep}}, \emph{\DUrole{n}{cv1\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{cv2\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{f\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{label1}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{label2}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Transform the provided 1D FEP to a 2D FES using the current conditional probability according to the formula
\begin{equation*}
\begin{split}F(q_1,q_2) &= -kT\cdot\ln\left(\int p(q_1,q_2|v)\cdot e^{-\beta F(v)}dv\right)\end{split}
\end{equation*}
\end{fulllineitems}


\end{fulllineitems}



\subsection{Kinetic Modules}
\label{\detokenize{rg:kinetic-modules}}

\subsubsection{Rate constant from transition state theory \textendash{} \sphinxstyleliteralintitle{\sphinxupquote{kinetics.rate}}}
\label{\detokenize{rg:module-thermolib.kinetics.rate}}\label{\detokenize{rg:rate-constant-from-transition-state-theory-kinetics-rate}}\index{module@\spxentry{module}!thermolib.kinetics.rate@\spxentry{thermolib.kinetics.rate}}\index{thermolib.kinetics.rate@\spxentry{thermolib.kinetics.rate}!module@\spxentry{module}}\index{RateFactorEquilibrium (class in thermolib.kinetics.rate)@\spxentry{RateFactorEquilibrium}\spxextra{class in thermolib.kinetics.rate}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.kinetics.rate.RateFactorEquilibrium}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{thermolib.kinetics.rate.}}\sphinxbfcode{\sphinxupquote{RateFactorEquilibrium}}}{\emph{\DUrole{n}{CV}}, \emph{\DUrole{n}{CV\_TS\_lims}}, \emph{\DUrole{n}{temp}}, \emph{\DUrole{n}{CV\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}}{}
\sphinxAtStartPar
Class to compute the factor \(A\) required for the computation of the rate constant \(k\) of the process of crossing a transition state:
\begin{align*}\!\begin{aligned}
\begin{aligned}
    k &= A\cdot\frac{ e^{-\beta F(q_{TS})} }{ \int_{-\infty}^{q_{TS}}e^{-\beta F(q)}dq } \\\\
A &= \frac{1}{2}\left\langle|\dot{Q}|\right\rangle_{TS}
\end{aligned}\\
\end{aligned}\end{align*}
\sphinxAtStartPar
Herein, the subscript TS refers to the fact that the average has to be taken only at configurational states corresponding to the transition state (TS). Furthermore, the average contains an integral over configurational phase space as well as momenta. The integral over momenta can either be performed analytical or numerical by taking momentum samples according to a certain distribution.
\begin{itemize}
\item {} 
\sphinxAtStartPar
When performing the momentum integration analytical, the above expression simplifies to:
\begin{quote}
\begin{equation*}
\begin{split}A = \sqrt{\frac{kT}{2\pi}} \cdot \left\langle\left||\vec{\nabla}_x Q\right||\right\rangle_{TS}\end{split}
\end{equation*}
\sphinxAtStartPar
where the average is now only taken in configurational space for states corresponding to the transition state (hence still the subscript TS). Furtheremore, \(\vec{\nabla}_x Q\) represents the gradient of the collective variable \(Q\) towards the mass\sphinxhyphen{}weighted cartesian coordinates.
\end{quote}

\item {} 
\sphinxAtStartPar
When performing the momentum integral numerically, the expression for A can be rewritten as:
\begin{quote}
\begin{equation*}
\begin{split}A = \frac{1}{2}\int_{\vec{x}\in TS} \left[\int_{-\infty}^{+\infty} \left|\dot{Q}(\vec{x},\vec{P})\right| p_p(\vec{P}) d\vec{P}\right]p_x(\vec{x})d\vec{x}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\dot{Q}(\vec{x},\vec{P})\) indicates that the time derivative of \(Q\) depends on both configurational state indicated by its mass\sphinxhyphen{}weighted cartesian coordinates \(\vec{x}\) as well as the mass\sphinxhyphen{}weighted momenta \(\vec{P}\). Furthermore \(p_p(\vec{P})\) represents the momentum probability distribution which will need to be specified (eg. the Maxwell\sphinxhyphen{}Boltzmann distribution). The integral over \(\vec{x}\) is computed using the samples \(\vec{x}_i\) taken from the MD trajectory while the integration over \(\vec{P}\) is computed numerically by taking random samples \(\vec{P}_k\) from the given momentum distribution \(p_p\):
\begin{align*}\!\begin{aligned}
\begin{aligned}
    A &= \frac{1}{N_s}\sum_{i=1}^{N_s}A(\vec{x}_i) \\\\
A(x_i) &=  \frac{1}{2N_p}\sum_{k=1}^{N_p}\left|\dot{Q}\left(\vec{x}_i,\vec{P}_k\right)\right|
\end{aligned}\\
\end{aligned}\end{align*}\end{quote}

\end{itemize}

\sphinxAtStartPar
These computational methods are implemented in the \sphinxcode{\sphinxupquote{RateFactorEquilibrium.proces\_trajectory()}} routine.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{CV}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}) \textendash{} a function that computes the value (and gradient) of the collective variable

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{CV\_TS\_lims}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} the lower and upper boundaries for determining whether a certain frame of the trajectory corresponds with the transition state (TS). In other words, the condition CV(R)=CV\_TS is replaced by CV\_TS\_lims{[}0{]}\textless{}=CV(R)\textless{}=CV\_TS\_lims{[}1{]}

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{masses}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} the masses of the atoms (should be consistently indexed as the coords argument parsed to the compute\_contribution routine).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{temp}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}) \textendash{} temperature

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{CV\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} the unit for printing the collective variable

\end{itemize}

\end{description}\end{quote}
\index{process\_trajectory() (thermolib.kinetics.rate.RateFactorEquilibrium method)@\spxentry{process\_trajectory()}\spxextra{thermolib.kinetics.rate.RateFactorEquilibrium method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.kinetics.rate.RateFactorEquilibrium.process_trajectory}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process\_trajectory}}}{\emph{\DUrole{n}{fn\_xyz}}, \emph{\DUrole{n}{finish}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{fn\_samples}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{momenta}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}analytical\textquotesingle{}}}, \emph{\DUrole{n}{Nmomenta}\DUrole{o}{=}\DUrole{default_value}{500}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Process the given XYZ trajectory and store T and N values.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn\_xyz}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} filename of the trajectory from which the rate factor will be computed.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{finish}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=True}}) \textendash{} when set to True, the finish routine will be called after processing the trajectory, which will finalize storing the data. If multiple trajectory from different files need to be read, set finish to False for all but the last trajectory.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn\_samples}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=None}}) \textendash{} write the rate factor samples (i.e. the As array) to the given file. This feature is switched off by specifying None.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{momenta}} (\sphinxstyleliteralemphasis{\sphinxupquote{string}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=analytical}}) \textendash{} 
\sphinxAtStartPar
specify how to compute the momentum part of the phase space integral in computing the As samples (see description above). The following options are available:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{analytical} \textendash{} compute the momentum integral analytically, is hence the fastest method

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{MB} \textendash{} compute the momentum integral numerical by taking random samples for the velocity from the Maxwell\sphinxhyphen{}Boltzmann distribution.

\end{itemize}


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Nmomenta}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=500}}) \textendash{} the number of momentum samples taken from the given distribution in case of numerical momentum integration. This keyword is only relevant when momenta is not set to analytical.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default=False}}) \textendash{} increase verbosity by setting to True.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\subsection{General tools}
\label{\detokenize{rg:module-thermolib.tools}}\label{\detokenize{rg:general-tools}}\index{module@\spxentry{module}!thermolib.tools@\spxentry{thermolib.tools}}\index{thermolib.tools@\spxentry{thermolib.tools}!module@\spxentry{module}}\index{blav() (in module thermolib.tools)@\spxentry{blav()}\spxextra{in module thermolib.tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.tools.blav}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{thermolib.tools.}}\sphinxbfcode{\sphinxupquote{blav}}}{\emph{\DUrole{n}{data}}, \emph{\DUrole{n}{blocksizes}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{fitrange}\DUrole{o}{=}\DUrole{default_value}{{[}0, \sphinxhyphen{} 1{]}}}, \emph{\DUrole{n}{exponent}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{fn\_plot}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{plot\_ac}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{ac\_range}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{acft\_plot\_range}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\sphinxAtStartPar
Routine to implement block averaging. This allows to estimate the sample error on correlated data by fitting a model function towards to the naive (i.e. as if uncorrelated) sample error on the block averages as function of the blocksize. This model function is based on the following model for the integrated correlation time \(\tau\) between the block averages:
\begin{equation*}
\begin{split}\begin{aligned}
    \tau = 1 + \frac{t_0-1}{B^n}
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
As a result, the model for the naive error estimate on the block averages becomes
\begin{equation*}
\begin{split}\begin{aligned}
    error = TE\cdot\frac{B^n}{B^n+t_0-1}
\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
in which \(B\) represents the block size, \(TE\) the true error, \(t_0\) the correlation time for the original time series (\(B=1\)) and \(n\) the exponential rate with which the block average integrated correlation time decreases as function of block size.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} 1D array representing the data to be analyzed

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{blocksizes}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} array of block sizes, defaults to np.arange(1,len(data)+1,1)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fitrange}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} range of blocksizes to which fit will be performed, defaults to {[}0,\sphinxhyphen{}1{]}

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{exponent}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the exponent of the blocksize in the models for the auto correlation time and correlated sample error, defaults to 1

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn\_plot}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} file name to which to write the plot. No plot is made if set to None. Defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit in which to plot the data, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plot\_ac}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} indicate whether or not to compute and plot the auto correlation function as well (might take some time), defaults to False

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ac\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the range for which to plot the auto correlation function, only relevant if \sphinxcode{\sphinxupquote{plot\_ac}} is set to True, defaults to np.arange(0,501,1)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{acft\_plot\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} the range for which to plot the fourier transform of the auto correlation function, only relevant if \sphinxcode{\sphinxupquote{plot\_ac}} is set to True, defaults to entire freq range

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
mean, error, corrtime

\end{description}\end{quote}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{mean} (\sphinxstyleemphasis{float}) \textendash{} the sample mean

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{error} (\sphinxstyleemphasis{foat}) \textendash{} the error on the sample mean

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{corrtime} (\sphinxstyleemphasis{float}) \textendash{} the correlation time (in units of the timestep) of the original sample data

\end{itemize}

\end{fulllineitems}

\index{integrate() (in module thermolib.tools)@\spxentry{integrate()}\spxextra{in module thermolib.tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.tools.integrate}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{thermolib.tools.}}\sphinxbfcode{\sphinxupquote{integrate}}}{\emph{\DUrole{n}{xs}}, \emph{\DUrole{n}{ys}}}{}
\sphinxAtStartPar
A simple integration method using the trapezoid rule
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{xs}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} array containing function argument values on grid

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ys}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}) \textendash{} array containing function values on grid

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{integrate2d() (in module thermolib.tools)@\spxentry{integrate2d()}\spxextra{in module thermolib.tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.tools.integrate2d}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{thermolib.tools.}}\sphinxbfcode{\sphinxupquote{integrate2d}}}{\emph{\DUrole{n}{z}}, \emph{\DUrole{n}{x}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{y}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dx}\DUrole{o}{=}\DUrole{default_value}{1.0}}, \emph{\DUrole{n}{dy}\DUrole{o}{=}\DUrole{default_value}{1.0}}}{}
\sphinxAtStartPar
Integrates a regularly spaced 2D grid using the composite trapezium rule.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{z}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{flt}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} 2 dimensional array containing the function values

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{flt}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} 1D array containing the first function argument values, is used to determine grid spacing of first function argument. If not given, optional argument dx is used to define the grid spacing. Defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{y}} (\sphinxstyleliteralemphasis{\sphinxupquote{np.ndarray}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{flt}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} 1D array containing the second function argument values, is used to determine grid spacing of second function argument. If not given, optional argument dy is used to define the grid spacing. Defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dx}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} grid spacing for first function argument. If not given, argument is used to determine grid spacing. Defaults to 1.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dy}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} grid spacing for second function argument. If not given, argument is used to determine grid spacing. Defaults to 1.

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
integral value

\item[{Return type}] \leavevmode
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{read\_wham\_input() (in module thermolib.tools)@\spxentry{read\_wham\_input()}\spxextra{in module thermolib.tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.tools.read_wham_input}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{thermolib.tools.}}\sphinxbfcode{\sphinxupquote{read\_wham\_input}}}{\emph{\DUrole{n}{fn}}, \emph{\DUrole{n}{path\_template\_colvar\_fns}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\%s\textquotesingle{}}}, \emph{\DUrole{n}{colvar\_cv\_column\_index}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{kappa\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{q0\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{start}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{end}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{} 1}}, \emph{\DUrole{n}{stride}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{bias\_potential}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Parabola1D\textquotesingle{}}}, \emph{\DUrole{n}{additional\_bias}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Read the input for a WHAM reconstruction of the free energy profile from a set of Umbrella Sampling simulations. The file specified by fn should have the following format:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{T} \PYG{o}{=} \PYG{n}{XXXK}
\PYG{n}{NAME1} \PYG{n}{Q1} \PYG{n}{KAPPA1}
\PYG{n}{NAME2} \PYG{n}{Q2} \PYG{n}{KAPPA2}
\PYG{n}{NAME3} \PYG{n}{Q3} \PYG{n}{KAPPA3}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

\sphinxAtStartPar
when a line starts with a T, it is supposed to specify the temperature. If no temperature line is found, a temperature of None will be returned. All other lines define the bias potential for each simulation as a parabola centered around \sphinxcode{\sphinxupquote{Qi}} and with force constant \sphinxcode{\sphinxupquote{KAPPAi}} (the units used in this file can be specified the keyword arguments \sphinxcode{\sphinxupquote{kappa\_unit}} and \sphinxcode{\sphinxupquote{q0\_unit}}). For each bias with name \sphinxcode{\sphinxupquote{NAMEi}} defined in this file, there should be a colvar trajectory file accessible through the path given by the string ‘path\_template\_colvar\_fns \%(NAMEi)’. For example, if path\_template\_colvar\_fns is defined as ‘trajectories/\%s/COLVAR’ and the wham input file contains the following lines:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{T} \PYG{o}{=} \PYG{l+m+mi}{300}\PYG{n}{K}
\PYG{n}{Window1}\PYG{o}{/}\PYG{n}{r1} \PYG{l+m+mf}{1.40} \PYG{l+m+mf}{1000.0}
\PYG{n}{Window2}\PYG{o}{/}\PYG{n}{r2} \PYG{l+m+mf}{1.45} \PYG{l+m+mf}{1000.0}
\PYG{n}{Window3}\PYG{o}{/}\PYG{n}{r1} \PYG{l+m+mf}{1.50} \PYG{l+m+mf}{1000.0}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

\sphinxAtStartPar
Then the colvar trajectory file of the first potential can be found through the path (relative to the wham input file) ‘Window1/r1/COLVAR’ and so on. These colvar files contain the trajectory of the relevant collective variable during the biased simulation. Finally, these trajectory files should be formatted as outputted by PLUMED:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{time\PYGZus{}1} \PYG{n}{cv\PYGZus{}value\PYGZus{}1}
\PYG{n}{time\PYGZus{}2} \PYG{n}{cv\PYGZus{}value\PYGZus{}2}
\PYG{n}{time\PYGZus{}3} \PYG{n}{cv\PYGZus{}value\PYGZus{}3}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

\sphinxAtStartPar
where the cv values again have a unit that can be specified by the keyword argument \sphinxcode{\sphinxupquote{q0\_unit}}.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} file name of the wham input file

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path\_template\_colvar\_fns}} (\sphinxstyleliteralemphasis{\sphinxupquote{str. Defaults to \textquotesingle{}\%s\textquotesingle{}}}) \textendash{} Template for defining the path (relative to the directory containing the wham input file given by argument fn) to the colvar trajectory file corresponding to each bias. See documentation above for more details. This argument should be string containing a single ‘\%s’ substring.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{kappa\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit used to express kappa in the wham input file, defaults to ‘kjmol’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{q0\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit used to express q0 in the wham input file as well as the cv values in the trajectory files, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stride}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} defines the sub sampling applied to the trajectory data to deal with correlations. For example a stride of 10 means only taking 1 in 10 samples and throw away 90\% of the data. Defaults to 1 (i.e. no sub sampling).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{start}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} defines the start point from which to take samples into account. This can be usefull for eliminating equilibration times as well as for taking various subsamples trajectories from the original data each starting at different timesteps. Defaults to 0.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{end}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} defines the end point to which to take samples into account. This can be usefull when it is desired to cut the original trajectory into blocks. Defaults to \sphinxhyphen{}1.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bias\_potential}} \textendash{} 
\sphinxAtStartPar
mathematical form of the bias potential used, allowed values are
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{parabola/harmonic} \textendash{} harmonic bias of the form 0.5*kappa*(q\sphinxhyphen{}q0)**2

\end{itemize}


\end{itemize}

\end{description}\end{quote}

\sphinxAtStartPar
defaults to parabola
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{additional\_bias}} ({\hyperref[\detokenize{rg:thermolib.thermodynamics.bias.BiasPotential1D}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{BiasPotential1D}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} A single additional bias that is added for each simulation on top of the simulation\sphinxhyphen{}specific biases. Defaults to None

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} increases verbosity if set to True, defaults to False

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar

\sphinxAtStartPar
temp, biasses, trajectories:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{temp} (float) \textendash{} temperature at which the simulations were performed

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{biasses} (list of callables) \textendash{} list of bias potentials (defined as callable functions) for all Umbrella Sampling simulations

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{trajectories} (list of np.ndarrays) \textendash{} list of trajectory data arrays containing the CV trajectory for all Umbrella Sampling simulations

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{read\_wham\_input\_2D() (in module thermolib.tools)@\spxentry{read\_wham\_input\_2D()}\spxextra{in module thermolib.tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.tools.read_wham_input_2D}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{thermolib.tools.}}\sphinxbfcode{\sphinxupquote{read\_wham\_input\_2D}}}{\emph{\DUrole{n}{fn}}, \emph{\DUrole{n}{path\_template\_colvar\_fns}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\%s\textquotesingle{}}}, \emph{\DUrole{n}{kappa1\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{kappa2\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}kjmol\textquotesingle{}}}, \emph{\DUrole{n}{q01\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{q02\_unit}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}au\textquotesingle{}}}, \emph{\DUrole{n}{start}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{end}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{} 1}}, \emph{\DUrole{n}{stride}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{bias\_potential}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}Parabola2D\textquotesingle{}}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\sphinxAtStartPar
Read the input for a WHAM reconstruction of the 2D free energy surface from a set of Umbrella Sampling simulations. The file specified by fn should have the following format:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{T} \PYG{o}{=} \PYG{n}{XXXK}
\PYG{n}{NAME\PYGZus{}1} \PYG{n}{Q01\PYGZus{}1} \PYG{n}{Q02\PYGZus{}1} \PYG{n}{KAPPA1\PYGZus{}1} \PYG{n}{KAPPA1\PYGZus{}1}
\PYG{n}{NAME\PYGZus{}2} \PYG{n}{Q01\PYGZus{}2} \PYG{n}{Q02\PYGZus{}2} \PYG{n}{KAPPA1\PYGZus{}2} \PYG{n}{KAPPA1\PYGZus{}2}
\PYG{n}{NAME\PYGZus{}3} \PYG{n}{Q01\PYGZus{}3} \PYG{n}{Q02\PYGZus{}3} \PYG{n}{KAPPA1\PYGZus{}3} \PYG{n}{KAPPA1\PYGZus{}3}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

\sphinxAtStartPar
when a line starts with a T, it is supposed to specify the temperature. If no temperature line is found, a temperature of None will be returned. All other lines define the bias potential for each simulation as a parabola centered around (\sphinxcode{\sphinxupquote{Q01\_i}},\textasciigrave{}\textasciigrave{}Q02\_i\textasciigrave{}\textasciigrave{}) and with force constants (\sphinxcode{\sphinxupquote{KAPPA1\_i}},\textasciigrave{}\textasciigrave{}KAPPA2\_i\textasciigrave{}\textasciigrave{}) (the units used in this file can be specified the keyword arguments \sphinxcode{\sphinxupquote{kappa1\_unit}}, \sphinxcode{\sphinxupquote{kappa2\_unit}}, \sphinxcode{\sphinxupquote{q01\_unit}} and \sphinxcode{\sphinxupquote{q02\_unit}}). For each bias with name \sphinxcode{\sphinxupquote{NAME\_i}} defined in this file, there should be a colvar trajectory file accessible through the path given by the string ‘path\_template\_colvar\_fns \%(NAME\_i)’. For example, if path\_template\_colvar\_fns is defined as ‘trajectories/\%s/COLVAR’ and the wham input file contains the following lines:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{T} \PYG{o}{=} \PYG{l+m+mi}{300}\PYG{n}{K}
\PYG{n}{Window1}\PYG{o}{/}\PYG{n}{r1} \PYG{l+m+mf}{1.40} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2} \PYG{l+m+mf}{1000.0} \PYG{l+m+mf}{1000.0}
\PYG{n}{Window2}\PYG{o}{/}\PYG{n}{r2} \PYG{l+m+mf}{1.45} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2} \PYG{l+m+mf}{1000.0} \PYG{l+m+mf}{1000.0}
\PYG{n}{Window3}\PYG{o}{/}\PYG{n}{r1} \PYG{l+m+mf}{1.50} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.2} \PYG{l+m+mf}{1000.0} \PYG{l+m+mf}{1000.0}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

\sphinxAtStartPar
Then the colvar trajectory file of the first potential can be found through the path (relative to the wham input file) ‘Window1/r1/COLVAR’ and so on. These colvar files contain the trajectory of the relevant collective variable during the biased simulation. Finally, these trajectory files should be formatted as outputted by PLUMED:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{time\PYGZus{}1} \PYG{n}{cv1\PYGZus{}value\PYGZus{}1} \PYG{n}{cv2\PYGZus{}value\PYGZus{}1}
\PYG{n}{time\PYGZus{}2} \PYG{n}{cv1\PYGZus{}value\PYGZus{}2} \PYG{n}{cv2\PYGZus{}value\PYGZus{}2}
\PYG{n}{time\PYGZus{}3} \PYG{n}{cv1\PYGZus{}value\PYGZus{}3} \PYG{n}{cv2\PYGZus{}value\PYGZus{}3}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}

\sphinxAtStartPar
where the cv1 and cv2 values again have a unit that can be specified by the keyword arguments \sphinxcode{\sphinxupquote{q01\_unit}} and \sphinxcode{\sphinxupquote{q02\_unit}} respectively.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fn}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} file name of the wham input file

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path\_template\_colvar\_fns}} (\sphinxstyleliteralemphasis{\sphinxupquote{str. Defaults to \textquotesingle{}\%s\textquotesingle{}}}) \textendash{} Template for defining the path (relative to the directory containing the wham input file given by argument fn) to the colvar trajectory file corresponding to each bias. See documentation above for more details. This argument should be string containing a single ‘\%s’ substring.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{kappa1\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit used to express the CV1 force constant kappa1 in the wham input file, defaults to ‘kjmol’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{kappa2\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit used to express the CV2 force constant kappa1 in the wham input file, defaults to ‘kjmol’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{q01\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit used to express q01 in the wham input file as well as the cv values in the trajectory files, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{q02\_unit}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} unit used to express q02 in the wham input file as well as the cv values in the trajectory files, defaults to ‘au’

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stride}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} defines the sub sampling applied to the trajectory data to deal with correlations. For example a stride of 10 means only taking 1 in 10 samples and throw away 90\% of the data. Defaults to 1 (i.e. no sub sampling).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{start}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} defines the start point from which to take samples into account. This can be usefull for eliminating equilibration times as well as for taking various subsamples trajectories from the original data each starting at different timesteps. Defaults to 0.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{end}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} defines the end point to which to take samples into account. This can be usefull when it is desired to cut the original trajectory into blocks. Defaults to \sphinxhyphen{}1.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bias\_potential}} \textendash{} 
\sphinxAtStartPar
mathematical form of the bias potential used, allowed values are
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{parabola2D/harmonic2D} \textendash{} harmonic bias of the form 0.5*kappa1*(q1\sphinxhyphen{}q01)**2 + 0.5*kappa2*(q2\sphinxhyphen{}q02)**2

\end{itemize}


\end{itemize}

\end{description}\end{quote}

\sphinxAtStartPar
defaults to parabola2D
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) \textendash{} increases verbosity if set to True, defaults to False

\item[{Raises}] \leavevmode
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ValueError}} \textendash{} when a line in the wham input file cannot be interpreted

\item[{Returns}] \leavevmode
\sphinxAtStartPar

\sphinxAtStartPar
temp, biasses, trajectories:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{temp} (float) \textendash{} temperature at which the simulations were performed

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{biasses} (list of callables) \textendash{} list of bias potentials (defined as callable functions) for all Umbrella Sampling simulations

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{trajectories} (list of np.ndarrays) \textendash{} list of trajectory data arrays containing the CV trajectory for all Umbrella Sampling simulations

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{trajectory\_xyz\_to\_CV() (in module thermolib.tools)@\spxentry{trajectory\_xyz\_to\_CV()}\spxextra{in module thermolib.tools}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{rg:thermolib.tools.trajectory_xyz_to_CV}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{thermolib.tools.}}\sphinxbfcode{\sphinxupquote{trajectory\_xyz\_to\_CV}}}{\emph{\DUrole{n}{fns}}, \emph{\DUrole{n}{CV}}}{}
\sphinxAtStartPar
Compute the CV along an XYZ trajectory. The XYZ trajectory is assumed to be composed out of a (list of subsequent) XYZ files.
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fns}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} (list of) names of XYZ trajectory file(s) containing the xyz coordinates of the system

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{CV}} (\sphinxstyleliteralemphasis{\sphinxupquote{one from thermolib.thermodynamics.cv.\_\_all\_\_}}) \textendash{} collective variable defining how to compute the collective variable along the trajectory

\end{itemize}

\item[{Returns}] \leavevmode
\sphinxAtStartPar
array containing the CV value along the trajectory

\item[{Return type}] \leavevmode
\sphinxAtStartPar
np.ndarray(flt)

\end{description}\end{quote}

\end{fulllineitems}



\chapter{Theoretical background}
\label{\detokenize{index:theoretical-background}}
\sphinxAtStartPar
In this section we provide the theoretical background for all various transformations and relations used in ThermoLIB.


\section{Theoretical background}
\label{\detokenize{theory:theoretical-background}}\label{\detokenize{theory:seclab-theory}}\label{\detokenize{theory::doc}}
\sphinxAtStartPar
In this section we provide the theoretical background for all various transformations and relations used in ThermoLIB.


\subsection{General statistical physics}
\label{\detokenize{theory:general-statistical-physics}}

\subsubsection{Partition function and total free energy}
\label{\detokenize{theory:partition-function-and-total-free-energy}}
\sphinxAtStartPar
In this section, we outline the fundamental theoretical background from thermodynamics and statistical physics applied in the ThermoLIB package. The main assumption is that we can describe the dynamics of the system using classical mechanics by means of the Hamiltonian:
\begin{equation*}
\begin{split}\begin{aligned}
\mathcal{H}\left(\vec{r}^{N},\vec{p}^{N}\right) & =\sum_{i=1}^{N}\frac{\vec{p}_{i}^{2}}{2m_{i}}+V\left(\vec{r}^{N}\right)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, \(m_{i}\) represents the mass of particle \(i\) and \(V\left(\vec{r}^{N}\right)\) the potential energy of the \(N\) particles at positions denoted as \(\vec{r}^{N}=(\vec{r}_{1},\vec{r}_{2},\ldots,\vec{r}_{N})\). In order to translate this microscopic description of the molecular interactions towards macroscopically observable thermodynamic properties, we apply the theory of statistical physics and construct the partition function \(Z_{NVT}\). We will illustrate everything in the canonical ensemble (i.e. control over particle number \(N\), volume \(V\) and temperature \(T\)) but it should be straightforward to generalize to other ensembles (). The classical partition function in the canonical ensemble is given by:
\begin{equation*}
\begin{split}\begin{aligned}
Z(N,V,T) & =\frac{1}{h^{3N}}\iint e^{-\beta\mathcal{H}\left(\vec{r}^{N},\vec{p}^{N}\right)}d\vec{r}^{N}d\vec{p}^{N}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Note that we assume that each particle in the system is distinguishable, which is indeed the case for purely crystalline materials as the crystal position allows to distinguish between the various atoms. However, whenever interchangeability makes (some) particles indistinguishable, adequate correction factors are required. This is e.g. the case when guest molecules are adsorbed inside a nanoporous framework. If \(n\) molecules are adsorbed, a correction factor of \(\frac{1}{n!}\) needs to be included in the partition function. We proceed by using the fact that the kinetic and potential degrees of freedom are fully decoupled, implying that the partition function can be factorized. Furthermore, since the kinetic energy takes on a simple quadratic form, its contribution to the partition function can be integrated analytically. Hence we arrive at:
\begin{equation*}
\begin{split}\begin{aligned}
Z(N,V,T) & =\frac{1}{h^{3N}}\int e^{-\beta\sum_{i}\frac{\vec{p}_{i}^{2}}{2m_{i}}}d\vec{p}^{N}\int e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\\
 & =\frac{1}{h^{3N}}\left[\prod_{i=1}^{N}\int e^{-\beta\frac{\vec{p}_{i}^{2}}{2m_{i}}}d\vec{p}_{i}\right]\int e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\\
 & =\frac{1}{\prod_{i}\Lambda_{i}^{3}}\int e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where we used the standard Gaussian integral in the third line and introduced the thermal wavelength for a particle with mass \(m_{i}\):
\begin{equation*}
\begin{split}\begin{aligned}
\Lambda_{i} & =\sqrt{\frac{h^{2}\beta}{2\pi m_{i}}}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
We clearly see that the partition function can be factorized in a contribution due to the kinetic degrees of freedom and a contribution due to the potential energy:
\begin{equation*}
\begin{split}\begin{aligned}
Z(N,V,T) & =Z^{\text{kin}}(N,V,T)Q(N,V,T)\\
Z^{\text{kin}}(N,V,T) & =\frac{V_{0}^{N}}{\prod_{i}\Lambda_{i}^{3}}\\
Q(N,V,T) & =\frac{1}{V_{0}^{N}}\int e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, \(V_{0}\) is an arbitrary volume introduced to make the separate contributions to the partition function dimensionless and drops out when considering the total partition function or when computing differences of \(Z^{kin}\) and \(Q\). \(Q\) is sometimes referred to as the configurational contribution to the partition function. If one chooses \(V_{0}\) to be the accessible volume of each atom in absence of any forces (i.e. \(V(\vec{r}^{N})=0\)), then \(Z^{kin}\) represents the ideal gas partition function. Once the partition function is known, the corresponding free energy can be computed from which all thermodynamic observables can be computed:
\begin{equation*}
\begin{split}\begin{aligned}
F(N,V,T) & =-k_{B}T\ln Z(N,V,T)\\
 & =F^{kin}(N,V,T)+F^{conf}(N,V,T)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
with \(F^{kin}\) the kinetic contribution to the free energy:
\begin{equation*}
\begin{split}\begin{aligned}
F^{kin}(N,V,T) & =-k_{B}T\ln Z^{kin}(N,V,T)\\
 & =-Nk_{B}T\ln V_{0}+\frac{3}{2}k_{B}T\sum_{i=1}^{N}\ln\left(\frac{h^{2}\beta}{2\pi m_{i}}\right)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
and \(F^{conf}\) the configurational contribution:
\begin{equation*}
\begin{split}F^{conf}(N,V,T)=-k_{B}T\ln Q(N,V,T)\end{split}
\end{equation*}

\subsubsection{Collective variables and free energy profiles}
\label{\detokenize{theory:collective-variables-and-free-energy-profiles}}

\paragraph{1D free energy profile}
\label{\detokenize{theory:d-free-energy-profile}}
\sphinxAtStartPar
One of the basic features of ThermoLIB is the construction and manipulation of free energy profiles (FEP) as function of a well chosen collective variable to describe the thermodynamic stability of a certain process. The collective variable \(X(\vec{r}^{N})\) represents a degree of freedom as a function of the coordinates \(\vec{r}^{N}\) and describes the progress of the system during the process of interest. One can then define a macrostate \(x\) of the system as the collection of microstates \(\vec{r}^{N}\) for which the collective variable takes on a value for \(X(\vec{r}^{N})\) within the interval \([x,x+dx]\). The configurational partition function of this macrostate and the corresponding configurational free energy is given by:
\begin{equation*}
\begin{split}\begin{aligned}
Q(x;N,V,T) & =\frac{1}{V_{0}^{N}}\int\delta(X(\vec{r}^{N})-x)e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\\
F^{conf}(x;N,V,T) & =-k_{B}T\ln Q(x;N,V,T)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, \(\delta(x)\) represents the Dirac delta distribution. The original total partition function \(Q(N,V,T)\) can be found as the integral over \(x\) which reconstructs the integral over entire phase space:
\begin{equation*}
\begin{split}\begin{aligned}
\int_{-\infty}^{+\infty}Q(x;N,V,T)dx & =\int_{-\infty}^{+\infty}\left[\frac{1}{V_{0}^{N}}\int\delta(X(\vec{r}^{N})-x)e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\right]dx\\
 & =\frac{1}{V_{0}^{N}}\int\left[\int_{-\infty}^{+\infty}\delta(X(\vec{r}^{N})-x)dx\right]e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\\
 & =\frac{1}{V_{0}^{N}}\int e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\\
 & =Q(N,V,T)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
In the third line, we used the defining property of the Dirac delta distribution. As a result, we can express the probability of finding the system in a macrostate with value for \(X(\vec{r}^{N})\) in the interval \([x,x+dx]\) as follows:
\begin{equation*}
\begin{split}p(x;N,V,T)dx=\frac{Q(x;N,V,T)}{Q(N,V,T)}dx\end{split}
\end{equation*}
\sphinxAtStartPar
As we will only be interested in processes that can be described by collective variables depending only on the coordinates \(\vec{r}^{N}\)  and not on the momenta), we will also only be interested in the configurational contributions to partition functions and free energies (as the kinetic contribution will not change along this process). Hence, from now on we will drop the superscript \sphinxstyleemphasis{conf} and we will also drop the functional dependence on \(N\), \(V\) and \(T\) to not over encumber the notation:
\begin{equation}\label{equation:theory:eq:probdens_from_partfun}
\begin{split}\begin{aligned}
Q(x) & =\frac{1}{V_{0}^{N}}\int\delta(X(\vec{r}^{N})-x)e^{-\beta V\left(\vec{r}^{N}\right)}d\vec{r}^{N}\\
Q & =\int_{-\infty}^{+\infty}Q(x)dx\\
F(x) & =-k_{B}T\ln Q(x)\\
F & =-k_{B}T\ln Q\\
p(x) & =\frac{Q(x)}{Q}\end{aligned}\end{split}
\end{equation}

\paragraph{2D free energy surface}
\label{\detokenize{theory:d-free-energy-surface}}
\sphinxAtStartPar
In many cases, when a system is undergoing a process we require 2 collective variables , i.e. \(X\) and \(Y\), to adequately describe the progress of the process. The corresponding 2D partition function, probability density and free energy surface, which describe the system in the state defined by \(X(\vec{r}^{N})\in[x,x+dx]\) and \(Y(\vec{r}^{N})\in[y,y+dy]\), are given by:
\begin{equation*}
\begin{split}\begin{aligned}
Q(x,y) & =\frac{1}{V_{0}^{N}}\int\delta(X(\vec{r}^{N})-x)\delta(Y(\vec{r}^{N})-y)e^{-\beta V(\vec{r}^{N})}d\vec{r}^{N}\\
p(x,y) & =\frac{Q(x,y)}{Q}\\
F(x,y) & =-k_{B}T\ln Q(x,y)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
One can easily make the link towards the 1D free energy profile as follows:
\begin{equation*}
\begin{split}\begin{aligned}
Q(x) & =\int_{-\infty}^{+\infty}Q(x,y)dy\\
p(x) & =\int_{-\infty}^{+\infty}p(x,y)dy\\
F(x) & =-k_{B}T\ln\left(\int_{-\infty}^{+\infty}e^{-\beta F(x,y)}dy\right)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
In what follows, we will derive various transformation formulas used by ThermoLIB for transforming between various collective variables, general projections of higher dimensional free energy surfaces (FES) to lower dimensional FES or \sphinxstyleemphasis{deprojecting} lower dimensional FES to higher
dimension FES.


\subsection{Transformations and projections of the FES}
\label{\detokenize{theory:transformations-and-projections-of-the-fes}}

\subsubsection{Transforming the FEP from one CV to another}
\label{\detokenize{theory:transforming-the-fep-from-one-cv-to-another}}
\sphinxAtStartPar
Consider a system undergoing a process that can be described by either one of two collective variables \(X(\vec{r}^{N})\) or \(Y(\vec{r}^{N})\). In other words, the progress of the system along the considered process can be adequately quantified by the value of either \(X\) or \(Y\). For such a process, one can construct a free energy profile as a function of either \(x\) (resulting in \(F_{x}(x)\)) or \(y\) (resulting in \(F_{y}(y)\)). The resulting two free energy profiles do not necessarily represent the same physical property. More specifically, if there exists a bijection between \(X\) and \(Y\) linking the value of \(x\) uniquely to that of \(y\) through the transformation formula \(y=h(x)\) (which is not always the case as we will discuss further on), then in general:
\begin{equation*}
\begin{split}F_{x}(x)\ne F_{y}(h(x))\end{split}
\end{equation*}
\sphinxAtStartPar
This is due to the fact that \(F_{x}(x)\) represents the free energy of the macrostate corresponding to all microstates for which \(X(\vec{r}^{N})=x\), while \(F_{y}(y)\) represents the free energy of the macrostate corresponding to all microstates for which \(Y(\vec{r}^{N})=y\). These two collections in general do not contain the same set of microstates, i.e. they do not represent the same subspace of phase space. Therefore, the free energy is not necessarily the same. As we will see later, only in the case where \(X\) and \(Y\) are connected by a linear transformation, are the free energies identical (up to a additive constant). Furthermore, it is not always the case one can identify a unique bijection between \(X\) and \(Y\). However, one can then usually still determine a probabilistic correlation  etween \(X\) and \(Y\) in the form of a conditional probability. We will go into more details for both situations in the following paragraphs.


\paragraph{Deterministic relation}
\label{\detokenize{theory:deterministic-relation}}
\sphinxAtStartPar
Assume one can define a unique relation \(y=h(x)\) between the value of two collective variables \(X\) and \(Y\). To derive the transformation formula for the free energy, i.e. the formula allowing to compute \(F_{x}(x)\) from \(F_{y}(y)\), we start by expressing that the probability of finding the system in \(X(\vec{r}^{N})\in[x,x+dx]\) is equal to the probability of finding the system in \(Y(\vec{r}^{N})\in[y,y+dy]\) with \(y=h(x)\):
\begin{equation*}
\begin{split}\begin{aligned}
p_{x}(x)dx & =p_{y}(y)dy\\
\frac{Q_{x}(x)}{Q}dx & =\frac{Q_{y}(y)}{Q}dy\\
Q_{x}(x) & =Q_{y}(y)\left|\frac{dy}{dx}\right|\\
Q_{x}(x) & =Q_{y}(h(x))\left|h'(x)\right|\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The absolute value in the third line is introduced because both partition functions \(Q_{x}(x)\) and \(Q_{y}(y)\) are fundamentally positive quantities. As a result, the corresponding free energy profiles transform as follows:
\begin{equation*}
\begin{split}\begin{aligned}
F_{x}(x) & =-k_{B}T\ln Q_{x}(x)\\
 & =-k_{B}T\ln\left(Q_{y}(h(x))h'(x)\right)\\
 & =-k_{B}T\ln Q_{y}(h(x))-k_{B}T\ln h'(x)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
As such, we arrive at the transformation formula between \(F_{x}(x)\) and \(F_{y}(y)\):
\begin{equation}\label{equation:theory:eq:fener_transfo_deterbij}
\begin{split}F_{x}(x)=F_{y}(h(x))-k_{B}T\ln\left|h'(x)\right|\end{split}
\end{equation}
\sphinxAtStartPar
Therefore, only for a linear transformation for which \(h'(x)=cte\), will the last term represent a meaningless additive constant and will the two free energy profiles coincide. However, when the transformation is not linear, an extra term \(-k_{B}T\ln\left|h'(x)\right|\) figures in the transformation formula. This term is related to the difference in width of the intervals \([x,x+dx]\) and \([y,y+dy]\) defining the macrostates corresponding to a given value of \(X\) and \(Y\). This can be generalized to multidimensional free energy surfaces (FES). Consider for example a 2D free energy surface \(F_{x}(x_{1},x_{2})\) subject to the following transformation:
\begin{equation*}
\begin{split}\begin{aligned}
y_{1} & =h_{1}(x_{1},x_{2})\\
y_{2} & =h_{2}(x_{1},x_{2})\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The transformation formula for the FES then becomes:
\begin{equation*}
\begin{split}F_{x}(x_{1},x_{2})=F_{y}(h_{1}(x_{1},x_{2}),h_{2}(x_{1},x_{2}))-k_{B}T\ln J(x_{1},x_{2})\end{split}
\end{equation*}
\sphinxAtStartPar
with \(J\) the Jacobian of the transformation:
\begin{equation*}
\begin{split}J(x_{1},x_{2})=\left|\frac{\partial[y_{1},y_{2}]}{\partial[x_{1},x_{2}]}\right|=\begin{vmatrix}\frac{\partial h_{1}}{\partial x_{1}} & \frac{\partial h_{1}}{\partial x_{2}}\\
\frac{\partial h_{2}}{\partial x_{1}} & \frac{\partial h_{2}}{\partial x_{2}}
\end{vmatrix}\end{split}
\end{equation*}

\paragraph{Probabilistic correlation}
\label{\detokenize{theory:probabilistic-correlation}}
\sphinxAtStartPar
A different situation arises when we cannot define a unique relation between a state of \(X(\vec{r}^{N})=x\) and a state of \(Y(\vec{r}^{N})=y\). However, one can usually still define a probabilistic correlation through the conditional probability \(p_{c}(x|y)\) expressing the probability of the system for being observed with a value \(X(\vec{r}^{N})=x\) given that is was prepared in a state for which \(Y(\vec{r}^{N})=y\). To derive the transformation formula between \(F_{x}(x)\) and \(F_{y}(y)\), we start from the following result of probability theory:
\begin{equation*}
\begin{split}\begin{aligned}
p_{x}(x) & =\int_{-\infty}^{+\infty}p_{xy}(x,y)dy\\
 & =\int_{-\infty}^{+\infty}p_{x|y}(x|y)p_{y}(y)dy\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
By using the relation between probability density and the partition function as well as the relation between free energy and partition function (Eq. \eqref{equation:theory-statphys:eq:probdens_from_partfun}), we arrive at:
\begin{equation}\label{equation:theory:eq:fener_transfo_probcor}
\begin{split}\begin{aligned}
e^{-\beta F_{x}(x)}=\int_{-\infty}^{+\infty}p_{x|y}(x|y)e^{-\beta F_{y}(y)}dy\\
F_{x}(x)=-k_{B}T\ln\left(\int_{-\infty}^{+\infty}p_{x|y}(x|y)e^{-\beta F_{y}(y)}dy\right)\end{aligned}\end{split}
\end{equation}
\sphinxAtStartPar
Note that this equation actually represents a generalization of the previous situation for a deterministic relation. Indeed, when the relation between \(X\) and \(Y\) can be expressed by a deterministic relation \(y=h(x)\), we can express the conditional probability as:
\begin{equation*}
\begin{split}p_{x|y}(x|y)=\delta(x-h^{-1}(y))=\frac{1}{\left|\frac{d}{dy}h^{-1}(h(x))\right|}\delta(y-h(x))=\left|h'(x)\right|\delta(y-h(x))\end{split}
\end{equation*}
\sphinxAtStartPar
As a result, the transformation formula \eqref{equation:theory-statphys:eq:probdens_from_partfun} becomes:
\begin{equation*}
\begin{split}\begin{aligned}
e^{-\beta F_{x}(x)} & =\left|h'(x)\right|\int_{-\infty}^{+\infty}\delta(y-h(x))e^{-\beta F_{y}(y)}dy\\
 & =\left|h'(x)\right|e^{-\beta F_{y}(h(x))}\\
F_{x}(x) & =F_{y}(h(x))-k_{B}T\ln\left|h'(x)\right|\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
which is indeed identical to the transformation formula \eqref{equation:theory-transformations:eq:fener_transfo_deterbij} for the case of a deterministic bijection.


\subsubsection{Projecting free energy surfaces}
\label{\detokenize{theory:projecting-free-energy-surfaces}}
\sphinxAtStartPar
In this section, we investigate how one could project a higher dimensional FES towards a lower dimensional FES. More specifically, we consider the situation where we start from a 2D FES \(F_{xy}(x,y)\) in terms of two collective variables \(X\) and \(Y\) and want to compute the free energy of macrostates defined by a collective variable \(Q\). Again, we can consider two situations: deterministic relation between \(X,Y\) and \(Q\) encoded by the expression \(Q(x,y)\) or a probabilistic correlation encoded by the conditional probability \(p_{q|xy}(q|x,y)\). However, just as it was the case for the transformations of the previous section, it will again turn out that the deterministic relation can be derived from the case of a probabilistic correlation. Therefore, we first consider the latter by starting from probability theory:
\begin{equation*}
\begin{split}\begin{aligned}
p_{q}(q) & =\int_{-\infty}^{+\infty}p_{q|xy}(q|x,y)p_{xy}(x,y)dxdye^{-\beta F_{q}(q)}\\
e^{-\beta F_{q}(q)} & =\int_{-\infty}^{+\infty}p_{q|xy}(q|x,y)e^{-\beta F_{xy}(x,y)}dxdyF_{q}(q)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Which gives the general projection formula as:
\begin{equation*}
\begin{split}F_{q}(q)=-k_{B}T\ln\left(\int_{-\infty}^{+\infty}p_{q|xy}(q|x,y)e^{-\beta F_{xy}(x,y)}dxdy\right)\end{split}
\end{equation*}
\sphinxAtStartPar
The situation for a deterministic relation encoded by the expression \(Q(x,y)\) can be found by setting the conditional probability appropriately:
\begin{equation*}
\begin{split}p_{q|xy}(q|x,y)=\delta\left(q-Q(x,y)\right)\end{split}
\end{equation*}\begin{equation*}
\begin{split}F_{q}(q)=-k_{B}T\ln\left(\int_{-\infty}^{+\infty}\delta\left(q-Q(x,y)\right)e^{-\beta F_{xy}(x,y)}dxdy\right)\end{split}
\end{equation*}
\sphinxAtStartPar
Furthermore, this formula can be simplified for some special, but common, cases:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\begin{DUlineblock}{0em}
\item[] The difference between 2 collective variable \(Q(x,y)=y-x\):
\item[] 
\end{DUlineblock}
\begin{quote}
\begin{equation*}
\begin{split}\begin{aligned}
F_{q}(q) & =-k_{B}T\ln\left(\int_{-\infty}^{+\infty}\delta(y-x-q)e^{-\beta F_{xy}(x,y)}dxdy\right)\nonumber \\
 & =-k_{B}T\ln\left(\int_{-\infty}^{+\infty}e^{-\beta F_{xy}(x,x+q)}dx\right)\end{aligned}\end{split}
\end{equation*}\end{quote}

\item {} 
\begin{DUlineblock}{0em}
\item[] The average of 2 collective variables \(Q(x,y)=\frac{x+y}{2}\):
\item[] 
\end{DUlineblock}
\begin{quote}
\begin{equation*}
\begin{split}\begin{aligned}
F_{q}(q) & =-k_{B}T\ln\left(\int_{-\infty}^{+\infty}\delta(\frac{x+y}{2}-q)e^{-\beta F_{xy}(x,y)}dxdy\right)\nonumber \\
 & =-k_{B}T\ln\left(2\int_{-\infty}^{+\infty}\delta(x+y-2q)e^{-\beta F_{xy}(x,y)}dxdy\right)\nonumber \\
 & =-k_{B}T\ln\left(2\int_{-\infty}^{+\infty}e^{-\beta F_{xy}(x,2q-x)}dx\right)\end{aligned}\end{split}
\end{equation*}\end{quote}

\end{enumerate}


\subsubsection{Deprojecting free energy surfaces}
\label{\detokenize{theory:deprojecting-free-energy-surfaces}}
\sphinxAtStartPar
Finally, one can also reconstruct a higher dimensional FES starting from a lower dimensional FES, a transformation we will herein denote as \sphinxstyleemphasis{deprojection}. As an example, consider a 1D FEP \(F_{q}(q)\) in terms of the collective variable \(q\) and assume we are interested in reconstructing the 2D FES \(F_{xy}(x,y)\) in terms of the collective variables \(x\) and \(y\). Remark that the 2D FES generally encodes more information than the 1D FEP due to the higher number of degrees of freedom. Hence, the reconstruction of this 2D FES requires additional information. This additional information is encoded in the conditional probability \(p_{xy|q}(x,y|q)\) expressing the probability of observing the system to have \(X(\vec{r}^{N})\in[x,x+dx]\) and \(Y(\vec{r}^{N})\in[y,y+dy]\) given that the system is in a macrostate given by \(Q(\vec{r}^{N})\in[q,q+dq]\). Using probability theory we find:
\begin{equation*}
\begin{split}\begin{aligned}
p_{xy}(x,y) & =\int_{-\infty}^{+\infty}p_{xyq}(x,y,q)dq\\
 & =\int_{-\infty}^{+\infty}p_{xy|q}(x,y|q)p_{q}(q)dq\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Which we can translate to the deprojection formula for the free energy surface:
\begin{equation*}
\begin{split}F_{xy}(x,y)=-k_{B}T\ln\left(\int_{-\infty}^{+\infty}p_{xy|q}(x,y|q)e^{-\beta F_{q}(q)}dq\right)\end{split}
\end{equation*}

\subsection{Conditional probabilities from (biased) simulations}
\label{\detokenize{theory:conditional-probabilities-from-biased-simulations}}
\sphinxAtStartPar
In all of the transformation, projection and deprojection formulas considered in the previous sections, one either knows the relation between the various collective variables \sphinxstyleemphasis{a priori} (deterministic relation) or expressed such relation through a conditional probability. The latter conditional probability will have to be derived from molecular simulations. In that case, we want to extract the conditional probability from the molecular simulations that were already performed to construct the free energy prior to transformation, projection or deprojection. If additional simulations would be required, one could argue that we could just as well set up new simulations to directly extract the new free energy. In that case, one could question the added value of the above derived transformation formulas (and rightly so). However, in many cases the original simulations involved enhanced sampling simulations that introduce bias potentials (such as umbrella sampling). Such biasing potentials were not taking into account in the previous derivations and hence we should wonder whether the conditional probabilities can be extracted from these biases simulations. Luckily, this indeed turns out to be the case whenever the biasing potential remains constant during the simulations (as is the case in umbrella sampling). To show this, we only consider the conditional probability \(p_{x|y}(x|y)\) figuring in Eq. \eqref{equation:theory-transformations:eq:fener_transfo_probcor}, but the proof can easily be extended towards the other conditional probabilities. Crucial to the proof is the realization that the applied bias in the original simulations was expressed in terms of the original collective variables. In the case of \(p_{x|y}(x|y)\) this means a bias \(V^{(b)}(y)\) only in terms of \(y\). We can then rewrite the conditional probability as follows:
\begin{equation*}
\begin{split}\begin{aligned}
p_{x|y}(x|y) & =\frac{p_{xy}(x,y)}{p_{y}(y)}=\frac{e^{-\beta F_{xy}(x,y)}}{e^{-\beta F_{y}(y)}}\\
 & =\frac{e^{-\beta F_{xy}(x,y)}e^{-\beta V^{(b)}(y)}}{e^{-\beta F_{y}(y)}e^{-\beta V^{(b)}(y)}}\\
 & =\frac{e^{-\beta\left[F_{xy}(x,y)+V^{(b)}(y)\right]}}{e^{-\beta\left[F_{y}(y)+V^{(b)}(y)\right]}}=\frac{p_{xy}^{(b)}(x,y)}{p_{y}^{(b)}(y)}\\
 & =p_{x|y}^{(b)}(x|y)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(p_{x|y}^{(b)}(x|y)\) represents the conditional probability
obtained from the biased simulation.


\subsection{Kinetic reaction rates from transition state theory}
\label{\detokenize{theory:kinetic-reaction-rates-from-transition-state-theory}}
\sphinxAtStartPar
Consider a system undergoing a process which brings it from one
(meta)stable state (denoted as the reactant state) to another
(meta)stable state (denoted as the product state). We also assume that
the progress along the process can be adequately described by the
collective variable \(Q(\vec{r}^{N})\) for which we have computed
the free energy profile \(F(q)\). Furthermore, we denote
\(q^{\dagger}\) as the value of \(Q\) in the transition state as
defined in Eyrings transition state theory and assume
\(Q<q^{\dagger}\) corresponds to the reactant state, while
\(Q>q^{\dagger}\) corresponds to the product state. The reaction
rate is a kinetic property as it represents the rate with which the
system undergoes the process. Therefore, it cannot be derived merely
from thermodynamic considerations. Eyrings transition state theory {[}
allows us to (approximately) compute the reaction rate from output of
molecular simulations in terms of the transition state as the ratio of
two ensemble averages:
\begin{equation*}
\begin{split}k^{TST}=\frac{\langle\dot{Q}\left(\vec{r}^{N}\right)\theta\left(\dot{Q}\left(\vec{r}^{N}\right)\right)\delta\left(Q\left(\vec{r}^{N}\right)-q^{\dagger}\right)\rangle}{\langle\theta\left(q^{\dagger}-Q(\vec{r}^{N})\right)\rangle}\end{split}
\end{equation*}
\sphinxAtStartPar
For a derivation of this formula, we refer to {[}. The meaning of the
various terms in this formula is as follows:

\sphinxAtStartPar
\(\dot{Q}\left(\vec{r}^{N}\right)\)                          the rate of variation (time derivative) of \(Q(\vec{r}^{N})\)
\(\theta\left(\dot{Q}\left(\vec{r}^{N}\right)\right)\)       only include phase\sphinxhyphen{}space samples for which natural time evolution would direct the system towards positive \(Q\), i.e. towards the product state.
\(\delta\left(Q\left(\vec{r}^{N}\right)-q^{\dagger}\right)\) only include phase\sphinxhyphen{}space samples in the transition state (\(Q=q^{\dagger}\))
\(\theta\left(q^{\dagger}-Q(\vec{r}^{N})\right)\)            normalize by dividing by a factor relative to the probability of finding the system in the reactant state.
================================================================
=====================================================================================================================================================

\sphinxAtStartPar
Since the momentum distribution is Gaussian, the integral over momentum
space can be done analytically, which results in ():
\begin{equation*}
\begin{split}k^{TST}=\sqrt{\frac{1}{2\pi\beta}}\frac{\int\delta\left(Q(\vec{x}^{N})-q^{\dagger}\right)\left|\vec{\nabla}_{x}Q(\vec{x}^{N})\right|e^{-\beta V(\vec{x}^{N})}d\vec{x}^{N}}{\int_{R}e^{-\beta V(\vec{x}^{N})}d\vec{x}^{N}}\end{split}
\end{equation*}
\sphinxAtStartPar
in which \(\vec{x}_{i}=\sqrt{m_{i}}\cdot\vec{r}_{i}\) represents
mass\sphinxhyphen{}weighted coordinates. The integral in the denominator only runs
over that part of phase space corresponding to the reactant state, i.e.
\(Q<q^{\dagger}\). Using the free energy profile \(F(q)\) we can
rewrite the expression even further:
\begin{equation*}
\begin{split}\begin{aligned}
k^{TST} & =\sqrt{\frac{1}{2\pi\beta}}\cdot\frac{\int\left|\vec{\nabla}_{x}Q(\vec{x}^{N})\right|\delta\left(Q(\vec{x}^{N})-q^{\dagger}\right)e^{-\beta V(\vec{x}^{N})}d\vec{x}^{N}}{\int\delta\left(Q(\vec{x}^{N})-q^{\dagger}\right)e^{-\beta V(\vec{x}^{N})}d\vec{x}^{N}}\cdot\frac{\int\delta\left(Q(\vec{x}^{N})-q^{\dagger}\right)e^{-\beta V(\vec{x}^{N})}d\vec{x}^{N}}{\int_{-\infty}^{q^{\dagger}}\left[\int\delta\left(Q(\vec{x}^{N})-q\right)e^{-\beta V(\vec{x}^{N})}d\vec{x}^{N}\right]dq}\\
 & =\sqrt{\frac{1}{2\pi\beta}}\cdot\left\langle \left|\vec{\nabla}_{x}Q\right|\right\rangle _{q^{\dagger}}\cdot\frac{e^{-\beta F(q^{\dagger})}}{\int_{-\infty}^{q^{\dagger}}e^{-\beta F(q)}dq}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Hence, transition state theory allows us to express the rate constant in
terms of the free energy profile and an additional prefactor \(A\)
which represents a (to the transition state) constrained ensemble
average of the (mass\sphinxhyphen{}weighted) gradient of the collective variable.
\begin{equation*}
\begin{split}\begin{aligned}
k^{TST} & =A\cdot\frac{e^{-\beta F(q^{\dagger})}}{\int_{-\infty}^{q^{\dagger}}e^{-\beta F(q)}dq}\\
A & =\sqrt{\frac{1}{2\pi\beta}}\cdot\left\langle \left|\vec{\nabla}_{x}Q\right|\right\rangle _{q^{\dagger}}\end{aligned}\end{split}
\end{equation*}

\subsection{Error on the sample average{[}sec:error\_sample\_average{]}}
\label{\detokenize{theory:error-on-the-sample-average-sec-error-sample-average}}
\sphinxAtStartPar
Whenever we want to calculate the population mean of a random variable,
we can use the sample average as an adequate estimate:
\begin{equation*}
\begin{split}\bar{X}=\frac{1}{N}\sum_{i=1}^{N}X_{i}\end{split}
\end{equation*}
\sphinxAtStartPar
Such an estimate is a consistent estimate in the sense that due to the
law of large numbers, its value converges to the true population average
for samples sizes approaching infinity \sphinxstepexplicit %
\begin{footnote}[1]\phantomsection\label{\thesphinxscope.1}%
\sphinxAtStartFootnote
The limit used in the expression of the law of large numbers is not a
conventional limit. Instead it should be interpreted as ’converges
almost surely’, which is a well\sphinxhyphen{}defined concept in probability
theory.
%
\end{footnote}:
\begin{equation*}
\begin{split}\bar{X}\rightarrow E[X]\text{ as }N\rightarrow+\infty\end{split}
\end{equation*}
\sphinxAtStartPar
Furthermore, as the sample average itself represents a random variable
(since it is a function of random variables \(X_{i}\)), one can also
express the mean and variance of this sample average. In this respect,
we know that the sample average represents an unbiased estimator of the
population mean, which means that the mean of the sample average is
equal to the population mean itself:
\begin{equation*}
\begin{split}E[\bar{X}]=E[X]\end{split}
\end{equation*}
\sphinxAtStartPar
With respect to the variance of the sample average, this is the topic of
the remainder of this section. We first make a distinction between
computing the variance for uncorrelated samples (Section
{\hyperref[\detokenize{theory:subsec:Uncorrelated-samples}]{\emph{{[}subsec:Uncorrelated\sphinxhyphen{}samples{]}}}}) and
correlated samples (Section
{\hyperref[\detokenize{theory:subsec:Correlated-samples}]{\emph{{[}subsec:Correlated\sphinxhyphen{}samples{]}}}}). Finally,
we discuss a well\sphinxhyphen{}known and practical method of dealing with these
correlations, the so\sphinxhyphen{}called block\sphinxhyphen{}averaging method (Section
{\hyperref[\detokenize{theory:subsec:Block-averaging}]{\emph{{[}subsec:Block\sphinxhyphen{}averaging{]}}}}).


\subsubsection{Error bar for uncorrelated samples{[}subsec:Uncorrelated\sphinxhyphen{}samples{]}}
\label{\detokenize{theory:error-bar-for-uncorrelated-samples-subsec-uncorrelated-samples}}
\sphinxAtStartPar
In almost all cases, we are (or should be) also interested in an error
bar on the estimate of the population mean. Such error bar is given by
the variance of the sample average. However, we need to make a
distinction between uncorrelated and correlated samples. If all samples
are uncorrelated from all others, then we have maximum amount of
information in the \(N\)\sphinxhyphen{}sample and the error bar will be at its
lowest. Mathematically, this is expressed as follows:
\begin{equation*}
\begin{split}\begin{aligned}
\text{Var}[\bar{X}] & =\text{Var}[\frac{1}{N}\sum_{i=1}^{N}X_{i}]=\frac{1}{N^{2}}\text{Var}[\sum_{i=1}^{N}X_{i}]\\
 & =\text{\ensuremath{\frac{1}{N{{}^2}}\sum_{i=1}^{N}\text{Var}[X_{i}]}}\\
 & =\frac{1}{N^{2}}\sum_{i=1}^{N}\sigma^{2}=\frac{1}{N^{2}}N\sigma^{2}\\
 & =\frac{\sigma{{}^2}}{N}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, the second line is only valid due to the fact that we assume the
samples are uncorrelated. In the third line, we used the fact that all
samples \(X_{i}\) are identically distributed with variance
\(\sigma^{2}\) of the original population. As a result we see that
the larger the sample size, the smaller the variance. Since the error
bar is proportional to the square root of the variance (i.e. the
standard deviation), we find the well\sphinxhyphen{}known result that the error on the
sample average of uncorrelated samples decreases with increasing sample
size \(N\) as \(\frac{1}{\sqrt{N}}\).


\subsubsection{Error bar for correlated samples{[}subsec:Correlated\sphinxhyphen{}samples{]}}
\label{\detokenize{theory:error-bar-for-correlated-samples-subsec-correlated-samples}}
\sphinxAtStartPar
However, whenever two samples are correlated they do not provide
independent information and hence using the sample average as given
above will overestimate the amount of information in our sample. This in
turn will turn out to underestimate the error bar and hence we need to
correct for this. To illustrate this mathematically, we rewrite the
variance on the sample average:
\begin{equation*}
\begin{split}\begin{aligned}
\text{\text{Var}[\ensuremath{\bar{X}}]} & =E\left[\left(\bar{X}-E[\bar{X}]\right)^{2}\right]=E\left[\left(\frac{1}{N}\sum_{i=1}^{N}X_{i}-\mu\right)^{2}\right]\\
 & =E\left[\left(\frac{1}{N}\sum_{i=1}^{N}X_{i}\right)^{2}-2\mu\frac{1}{N}\sum_{i=1}^{N}X_{i}+\mu^{2}\right]\\
 & =E\left[\left(\frac{1}{N}\sum_{i=1}^{N}X_{i}\right)^{2}\right]-\mu^{2}=\frac{1}{N^{2}}E\left[\sum_{i,j=1}^{N}X_{i}X_{j}\right]-\mu^{2}\\
 & =\frac{1}{N^{2}}\sum_{i,j=1}^{N}E[X_{i}X_{j}]-\mu^{2}\\
 & =\frac{1}{N^{2}}\left(\underbrace{\sum_{i=1}^{N}E[X_{i}^{2}]}_{i=j}+\underbrace{2\sum_{i<j=1}^{N}E[X_{i}X_{j}]}_{i\ne j}\right)-\mu^{2}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The first term in the last line is related to the variance
\(\sigma^{2}\) of the population:
\begin{equation*}
\begin{split}\sum_{i=1}^{N}E[X_{i}^{2}]=N(\sigma^{2}+\mu^{2})\end{split}
\end{equation*}
\sphinxAtStartPar
Which results in:
\begin{equation*}
\begin{split}\text{\text{Var}[\ensuremath{\bar{X}}]}=\frac{\sigma^{2}}{N}+\frac{2}{N^{2}}\sum_{i<j=1}^{N}E[X_{i}X_{j}]-\frac{N-1}{N}\mu^{2}\label{eq:variance_correlated_intermed1}\end{split}
\end{equation*}
\sphinxAtStartPar
The second term can be rewritten in terms of the autocorrelation
function as we will now show. We start by using the time translation
invariance of the sample data. For \(i<j\) this can be expressed as
follows:
\begin{equation*}
\begin{split}E[X_{i}X_{j}]=E[X_{1}X_{j-i+1}]=E[X_{1}X_{t+1}]\end{split}
\end{equation*}
\sphinxAtStartPar
for \(t=j-i\) with values in \([0,N-1]\). Using this relabeling,
the second term in Eq.
{\hyperref[\detokenize{theory:eq:variance_correlated_intermed1}]{\emph{{[}eq:variance\_correlated\_intermed1{]}}}}
can be rewritten as follows:
\begin{equation*}
\begin{split}\begin{aligned}
\sum_{i<j=1}^{N}E[X_{i}X_{j}] & =\sum_{i=1}^{N-1}\sum_{j=i+1}^{N}E[X_{i}X_{j}]\\
 & =\sum_{i=1}^{N-1}\sum_{t=1}^{N-i}E[X_{1}X_{1+t}]\\
 & =\sum_{t=1}^{N-1}E[X_{1}X_{1+t}]+\sum_{t=1}^{N-2}E[X_{1}X_{1+t}]+\cdots+\sum_{t=1}^{2}E[X_{1}X_{1+t}]+\sum_{t=1}^{1}E[X_{1}X_{1+t}]\\
 & =(N-1)E[X_{1}X_{2}]+\cdots+(N-t)E[X_{1}X_{1+t}]+E[X_{1}X_{N}]\\
 & =\sum_{t=1}^{N-1}(N-t)E[X_{1}X_{1+t}]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Furthermore, we also rewrite the third term in Eq.
{\hyperref[\detokenize{theory:eq:variance_correlated_intermed1}]{\emph{{[}eq:variance\_correlated\_intermed1{]}}}}:
\begin{equation*}
\begin{split}\frac{N-1}{N}\mu^{2}=\frac{2}{N^{2}}\cdot\frac{N(N-1)}{2}\mu^{2}=\frac{2}{N^{2}}\sum_{t=1}^{N-1}(N-t)\mu^{2}\end{split}
\end{equation*}
\sphinxAtStartPar
As such we can further rewrite Eq.
{\hyperref[\detokenize{theory:eq:variance_correlated_intermed1}]{\emph{{[}eq:variance\_correlated\_intermed1{]}}}}:
\begin{equation*}
\begin{split}\begin{aligned}
\text{\text{Var}[\ensuremath{\bar{X}}]} & =\frac{\sigma^{2}}{N}+\frac{2}{N^{2}}\sum_{t=1}^{N-1}(N-t)E[X_{1}X_{1+t}]-\frac{2}{N^{2}}\sum_{t=1}^{N-1}(N-t)\mu^{2}\\
 & =\frac{\sigma^{2}}{N}+\frac{2}{N^{2}}\sum_{t=1}^{N-1}(N-t)\left(E[X_{1}X_{1+t}]-\mu^{2}\right)\\
 & =\frac{\sigma^{2}}{N}+\frac{2\sigma^{2}}{N^{2}}\sum_{t=1}^{N-1}(N-t)\frac{E\left[(X_{1}-\mu)(X_{1+t}-\mu)\right]}{\sigma^{2}}\\
 & =\frac{\sigma^{2}}{N}\left[1+2\sum_{t=1}^{N-1}\left(1-\frac{t}{N}\right)c(t)\right]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where we introduced the autocorrelation function:
\begin{equation*}
\begin{split}c(t)=\frac{E\left[(X_{1}-\mu)(X_{1+t}-\mu)\right]}{\sigma^{2}}\label{eq:autocorrelationfunction}\end{split}
\end{equation*}
\sphinxAtStartPar
Finally, we define the integrated correlation time \(\tau_{int}\)
which allows to express the variance on the sample average more easily:
\begin{equation*}
\begin{split}\begin{aligned}
\text{\text{Var}[\ensuremath{\bar{X}}]} & =\frac{\sigma^{2}}{N}\tau_{int}\label{eq:variance_correlated_final}\\
\tau_{int} & =1+2\sum_{t=1}^{N-1}\left(1-\frac{t}{N}\right)c(t)\label{eq:variance_correlated_tau}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
As such, we can interpret the integrated correlation time
\(\tau_{int}\) as the number of subsequent samples in the original
sample set that are correlated and hence should be treated as only 1
sample. As a result the number of independent samples is given by
\(\frac{N}{\tau_{int}}\) instead of \(N\) when computing the
variance on the sample average. In many cases, one can assume that the
autocorrelation function can be expressed as a simple exponential:
\begin{equation*}
\begin{split}c(t)=e^{-\frac{t}{\tau_{exp}}}\end{split}
\end{equation*}
\sphinxAtStartPar
The integrated correlation time for \(N\)\sphinxhyphen{}sample with
\(N\rightarrow+\infty\) (hence approaching total population) can
easily be computed:
\begin{equation*}
\begin{split}\begin{aligned}
\tau_{int} & =1+2\sum_{t=1}^{N}\left(1-\frac{t}{N}\right)e^{-\frac{t}{\tau_{exp}}}\\
 & =1+2\sum_{t=1}^{+\infty}e^{-\frac{t}{\tau_{exp}}}\\
 & =1+2\left(\sum_{t=0}^{+\infty}e^{-\frac{t}{\tau_{exp}}}-1\right)\\
 & =1+2\left(\frac{1}{e^{-1/\tau_{exp}}-1}-1\right)\\
 & =1+2\frac{e^{-1/\tau_{exp}}}{e^{-1/\tau_{exp}}-1}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
In the second line, we used the facts that (1) the function
\(1-\frac{t}{N}\approx1\) for \(t<N(\rightarrow+\infty)\) and
(2) the function \(c(t)=e^{-\frac{t}{\tau_{exp}}}\approx0\) for
\(t\rightarrow+\infty\). In the fourth line, we also assumed
\(\tau_{exp}>0\). Furthermore, for large values of the ’exponential
correlation time’ \(\tau_{exp}\) we can approximate the function
\begin{equation*}
\begin{split}\frac{e^{-1/\tau_{exp}}}{e^{-1/\tau_{exp}}-1}\approx\tau_{exp}-\frac{1}{2}\end{split}
\end{equation*}
\sphinxAtStartPar
In practice, the approximation is valid rather quickly (for
\(\tau_{exp}>8.3\) the error on the approximation is smaller than
\(0.01\)). The approximation gives rise to the following integrated
correlation time
\begin{equation*}
\begin{split}\tau_{int}\approx2\tau_{exp}\text{ for }\tau_{exp}\gg1\end{split}
\end{equation*}
\sphinxAtStartPar
revealing the relation between the integrated correlation time (i.e. the
number of subsequent samples that are correlated and hence need to be
treated as one sample) and the exponential correlation time (i.e. the
rate with which correlations in the samples die out).


\subsubsection{Block averaging{[}subsec:Block\sphinxhyphen{}averaging{]}}
\label{\detokenize{theory:block-averaging-subsec-block-averaging}}
\sphinxAtStartPar
As was discussed in the previous section, to estimate the variance on
the sample average, we need to account for sample correlations. Assume
we start from a correlated \(N\)\sphinxhyphen{}sample taken from a population with
mean \(\mu\) and variance \(\sigma^{2}\), then we know from
previous subsections that the sample average has mean and variance given
by:
\begin{equation*}
\begin{split}\begin{aligned}
\bar{X} & =\frac{1}{N}\sum_{i=1}^{N}X_{i}\label{eq:blav_sampleaverage}\\
E[\bar{X}] & =\mu\label{eq:blav_sampleaverage_mean}\\
\text{Var}[\bar{X}] & =\frac{\sigma^{2}}{N}\tau_{int}\label{eq:blav_sampleaverage_variance}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
To estimate the variance, one could compute the integrated correlation
time \(\tau_{int}\). Although this can be achieved by defining an
estimator for the autocorrelation function, we will here discuss an
alternative method to deal with the sample correlations, the so called
block\sphinxhyphen{}averaging method. We first divide the entire sample in blocks of
size \(B\) (resulting in a number of blocks equal to
\(N_{B}=\frac{N}{B}\)) and compute the average of each block, which
we denote as the block averages \(X_{b}\):
\begin{equation*}
\begin{split}\left\{ X_{i}\right\} _{i=1}^{N}\rightarrow\left\{ X_{b}\right\} _{b=1}^{N_{B}}\text{ with }X_{b}=\frac{1}{B}\sum_{i=1}^{B}X_{(b-1)B+i}\end{split}
\end{equation*}
\sphinxAtStartPar
The average of the block averages (\(\bar{X}_{B}\)) is identical to
the orginal full sample average (\(\bar{X}\)):
\begin{equation*}
\begin{split}\bar{X}_{B}=\frac{1}{N_{B}}\sum_{b=1}^{N_{B}}X_{b}=\frac{1}{N_{B}}\sum_{b=1}^{N_{B}}\frac{1}{B}\sum_{i=1}^{B}X_{(b-1)B+i}=\frac{1}{N_{B}B}\sum_{n=1}^{N}X_{n}=\bar{X}\end{split}
\end{equation*}
\sphinxAtStartPar
Hence, the average of the block averages is a good (consistent and
unbiased) estimator for the population mean. However, the variance of
the block averages is given by:
\begin{equation*}
\begin{split}\text{Var}[\bar{X}_{B}]=\underbrace{\frac{\sigma_{B}^{2}}{N_{B}}}_{\text{Var}[\bar{X}_{B}]_{naive}}\cdot\tau_{int,B}\label{eq:blav_var_avofblavs}\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, we indicated what would be the naive estimate of the variance
when the correlations between block averages would not be accounted for.
The factor \(\tau_{int,B}\) corrects for these correlations between
subsequent block averages. In case we choose \(B=1\) (corresponding
to the original sample series without block averaging), we find
\(\tau_{int,B}(B=1)=\tau_{int}\) corresponding to the integrated
correlation time in the original sample seris. Furthermore,
\(\sigma_{B}^{2}=\text{Var}[X_{b}]\) represents the variance of the
block averages \(X_{b}\) (i.e. not the variance of the average of
the block averages but of the block averages themselves), for which we
have an unbiased estimator:
\begin{equation*}
\begin{split}S_{B}^{2}=\frac{1}{N_{B}-1}\sum_{b=1}^{N_{B}}\left(X_{b}-\bar{X}_{B}\right)^{2}\end{split}
\end{equation*}
\sphinxAtStartPar
If the original sample would be free of correlations, the block average
integrated correlation time \(\tau_{int,B}\) would be \(1\)
independent off the block size \(B\) and the variance on the block
averages would be given by:
\begin{equation*}
\begin{split}\sigma_{B}^{2}=\frac{\sigma^{2}}{B}\end{split}
\end{equation*}
\sphinxAtStartPar
As a result, the variance on the average of block averages given by Eq.
{\hyperref[\detokenize{theory:eq:blav_var_avofblavs}]{\emph{{[}eq:blav\_var\_avofblavs{]}}}} would reduce to
\begin{equation*}
\begin{split}\text{Var}[\bar{X}_{B}]=\frac{\sigma_{B}^{2}}{N_{B}}\tau_{int,B}\xrightarrow{uncorrelated}\text{Var}[\bar{X}_{B}]_{naive}=\frac{\sigma_{B}^{2}}{N_{B}}=\frac{\sigma^{2}}{BN_{B}}=\frac{\sigma^{2}}{N}\end{split}
\end{equation*}
\sphinxAtStartPar
which is indeed consistent with Eq.
{\hyperref[\detokenize{theory:eq:blav_sampleaverage_variance}]{\emph{{[}eq:blav\_sampleaverage\_variance{]}}}}
for \(\tau_{int}=1\) for uncorrelated samples. This implies that in
case sample correlations are absent, the naive error estimate
\(\text{Var}[\bar{X}_{B}]_{naive}\) is independent of the block size
and equals the true error on the sample average. This is, however, no
longer the case when correlations are present in the original samples.
In this case, we still consider the naive estimate of the variance
\(\text{Var}[\bar{X}_{B}]_{naive}\), which now depends on the block
size \(B\):
\begin{equation*}
\begin{split}\text{Var}[\bar{X}_{B}]_{naive}=\frac{\sigma_{B}^{2}}{N_{B}}=\frac{\text{Var}[\bar{X}_{B}]}{\tau_{int,B}}=\frac{\text{Var}[\bar{X}]}{\tau_{int,B}(B)}=\frac{\text{True error}}{\tau_{int,B}(B)}\end{split}
\end{equation*}
\sphinxAtStartPar
where we used the fact that (1) \(\bar{X}_{B}=\bar{X}\) and hence so
is its variance which is the true error we are interested in and (2) the
integrated correlation time between block averages \(\tau_{int,B}\)
depends on the block size \(B\). Furthermore, as the block size
increases, the ’time\sphinxhyphen{}difference’ between subsequent block averages
increases and hence the correlation between them will decrease as well.
Hence, as the block size increases, \(\tau_{int,B}\) will decrease
and the naive estimate \(\text{Var}[\bar{X}_{B}]_{naive}\) will
increase. Once the block size becomes larger than the integrated
correlation time \(\tau_{int}\), \(\tau_{int,B}\) will have
converged to \(1\) and the naive error estimate
\(\text{Var}[\bar{X}_{B}]_{naive}\) will have converged to the true
error. In order to apply the block averaging method to estimate the true
(correlated) error, we execute the following steps and for each block
size execute the following steps:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Define a range of block sizes (\(B=1\rightarrow B_{max}\))

\item {} 
\sphinxAtStartPar
For each block size \(B\) do:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumii}{enumiii}{}{.}%
\item {} 
\sphinxAtStartPar
compute the block averages
\(\left\{ X_{b}\right\} _{b=1}^{N_{B}}\)
\begin{equation*}
\begin{split}X_{b}=\frac{1}{B}\sum_{i=1}^{B}X_{(b-1)B+i}\end{split}
\end{equation*}
\item {} 
\sphinxAtStartPar
Estimate the variance of the block averages:
\begin{equation*}
\begin{split}S_{B}^{2}=\frac{1}{N_{B}-1}\sum_{b=1}^{N_{B}}\left(X_{b}-\bar{X}_{B}\right)^{2}\end{split}
\end{equation*}
\item {} 
\sphinxAtStartPar
Compute the naive estimate of the variance on the sample average:
\begin{equation*}
\begin{split}\text{Var}[\bar{X}_{B}]_{naive}=\frac{S_{B}^{2}}{N_{B}}\end{split}
\end{equation*}
\end{enumerate}

\item {} 
\sphinxAtStartPar
Propose a model function for \(\tau_{int,B}(B)\). This function
should satisfy following two conditions:
\begin{equation*}
\begin{split}\begin{aligned}
\tau_{int,B}(B=1) & =\tau_{int}\\
\lim_{B\rightarrow+\infty}\tau_{int,B}(B) & =1\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
A possible candidate is:
\begin{equation*}
\begin{split}\tau_{int,B}(B)=1+\frac{\tau_{int}-1}{B}\end{split}
\end{equation*}
\item {} 
\sphinxAtStartPar
Use the model function to fit the naive error estimation as function
of the blocksize:
\begin{equation*}
\begin{split}\text{Var}[\bar{X}_{B}]_{naive}=f(B)=\frac{TE}{\tau_{int,B}(B)}\end{split}
\end{equation*}
\sphinxAtStartPar
in which \(TE\) represents the true error we are interested in.
Using the previously mentioned example for model function of
\(\tau_{int,B}(B)\) we find:
\begin{equation*}
\begin{split}f(B)=\frac{TE\cdot B}{B+\tau_{int}-1}\end{split}
\end{equation*}
\sphinxAtStartPar
The resulting parameters of the fit, \(TE\) and
\(\tau_{int}\), gives the required estimate for the true error on
the sample average and the integrated correlation time respectively.

\end{enumerate}


\subsection{Error on the estimation of the probability density}
\label{\detokenize{theory:error-on-the-estimation-of-the-probability-density}}
\sphinxAtStartPar
In this section we outline the mathematical details on how to derive a
probability density (as well as the corresponding free energy profile)
as function of a collective variable from a histogram including an
estimation of the corresponding error bar. The discussion is divided
into two parts, the first part deals with the construction of a
probability density from a single (possibly biased) equilibrium
simulation while the second part deals with the wheighted histogram
analysis method for reconstructing probability densities from multiple
(possibly biased) equilibrium simulations as applied in the umbrella
sampling technique.


\subsubsection{Estimation from a single equilibrium simulation}
\label{\detokenize{theory:estimation-from-a-single-equilibrium-simulation}}

\paragraph{Probability model{[}subsec:Probability\sphinxhyphen{}model{]}}
\label{\detokenize{theory:probability-model-subsec-probability-model}}
\sphinxAtStartPar
Assume we performed a molecular dynamics simulation and computed the
value of the collective variable \(Q(\vec{r}^{N})\) at each step
resulting in the sample series \(q_{i}\). From this series, one can
easily construct a histogram \(H_{k}\) representing the number of
\(q\)\sphinxhyphen{}values in the series that are within the bin
\([q_{k}-\frac{\Delta}{2},q_{k}+\frac{\Delta}{2}]\) for a given bin
width \(\Delta\). After proper normalization, this histogram can
serve as a model for the probability density. However, in order to
estimate the error on each value in the resulting probability
distribution, we apply the theory of maximum likelihood estimators and
with corresponding error estimate from the Fisher information. Herein,
we start from a model for the probability density of finding a value
\(q\). Such model will depend on certain model parameters which we
will condense in the parameter vector \(\vec{a}\) and we will
therefore denote it as \(p(q|\vec{a})\) indicating the probability
is conditional on a certain value of the parameter vector
\(\vec{a}\). For example, a model for the probability density
corresponding to a histogram can be expressed as
\begin{equation*}
\begin{split}p(q|\vec{a})=\sum_{k=1}^{K}a_{k}\phi_{k}(q)\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, \(\phi_{k}\) represents a function corresponding to the bin
centered around value \(Q_{k}\):
\begin{equation*}
\begin{split}\phi_{k}(q)=\begin{cases}
\frac{1}{\Delta} & q\in[Q_{k}-\frac{\Delta}{2},Q_{k}+\frac{\Delta}{2}]\\
0 & elsewhere
\end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
with \(\Delta\) an a priori chosen bin width and \(Q_{k}\) the a
priori chosen bin centers. Note that each bin function \(\phi_{k}\)
is normalized to \(1\), which implies that normalization of the
probability density requires:
\begin{equation*}
\begin{split}\sum_{k=1}^{K}a_{k}=1\end{split}
\end{equation*}

\paragraph{Likelihood and maximum likelihood estimator{[}subsec:Likelihood\sphinxhyphen{}and\sphinxhyphen{}MLE{]}}
\label{\detokenize{theory:likelihood-and-maximum-likelihood-estimator-subsec-likelihood-and-mle}}
\sphinxAtStartPar
In order to be able to use such a model for further analysis such as the
construction of the free energy profile, we need an accurate estimate
for the model parameters \(\vec{a}\), which we want to derive from
the simulation data given by the samples \(q_{i}\). These parameters
can be estimated using the likelihood function. We define the likelihood
\(\mathcal{L}(\vec{a})\) as the probability of \(\vec{a}\) being
the true parameters given that we observed samples
\(\vec{q}=(q_{1},\ldots,q_{N})\) that were taken from the true
probability distribution \sphinxstepexplicit %
\begin{footnote}[2]\phantomsection\label{\thesphinxscope.2}%
\sphinxAtStartFootnote
We assume uncorrelated samples. See section
{\hyperref[\detokenize{theory:sec:error_sample_average}]{\emph{{[}sec:error\_sample\_average{]}}}} for more
information on error estimation of sample averages with sample
correlations.
%
\end{footnote}. Using Bayes theorem for conditional
probabilities we find:
\begin{equation*}
\begin{split}\mathcal{L}(\vec{a})=p(\vec{a}|\text{\ensuremath{\vec{q}}})=\frac{p(\vec{a},\vec{q})}{p(\vec{q})}=\frac{p(\vec{q}|\vec{a})p(\vec{a})}{p(\vec{q})}\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, we can express \(p(\vec{q}|\vec{a})\) in terms of the
previously defined probabilty function \(p(q|\vec{a})\) (assuming
uncorrelated samples):
\begin{equation*}
\begin{split}p(\vec{q}|\vec{a})=\prod_{n=1}^{N}p(q_{n}|\vec{a})\end{split}
\end{equation*}
\sphinxAtStartPar
Furthermore, the probability \(p(\vec{a})\) represents a prior
knowledge about the parameters, which we assume we don’t have, i.e.
\(p(\vec{a})=cte\). Finally, since \(p(\vec{q})\) does not
depend on the parameters, it is only relevant for proper normalization.
However, such normalisation will not be important for our purposes,
hence we write:
\begin{equation*}
\begin{split}\mathcal{L}(\vec{a})=p(\vec{q}|\vec{a})=\prod_{n=1}^{N}p(q_{n}|\vec{a})\end{split}
\end{equation*}
\sphinxAtStartPar
We also define the log\sphinxhyphen{}likelihood and the related function
\(l_{N}\):
\begin{equation*}
\begin{split}\begin{aligned}
\log\mathcal{L} & =\sum_{n=1}^{N}\log\left(p(q_{n}|\vec{a})\right)\nonumber \\
l_{N}(\vec{a}) & =\frac{1}{N}\sum_{n=1}^{N}\log\left(p(q_{n}|\vec{a})\right)\label{eq:loglikelihood-sampleaverage}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The function \(l_{N}\) can be interpreted as an N\sphinxhyphen{}sample estimate of
the mean of the random variable \(\log\left(p(q|\vec{a})\right)\),
therefore we also define the true mean \(l\):
\begin{equation*}
\begin{split}l(\vec{a})=E_{\vec{a}_{0}}\left[\log\left(p(q|\vec{a})\right)\right]=\int_{-\infty}^{+\infty}\log\left[p(q|\vec{a})\right]p(q|\vec{a}_{0})dq\label{eq:loglikelihood-populationaverage}\end{split}
\end{equation*}
\sphinxAtStartPar
where the notation \(E_{\vec{a}_{0}}[\cdot]\) denotes the average
computed using the probability density \(p(q|\vec{a}_{0})\) with the
true parameters \(\vec{a}_{0}\). We are now ready to define the
so\sphinxhyphen{}called maximum likelihood estimator (MLE) \(\hat{\vec{a}}\) as an
estimator for the parameters which maximizes the likelihood
\(\mathcal{L}(\vec{a})\) (and as a result
\(\mathcal{\log L}(\vec{a})\) and \(l_{N}(\vec{a})\) as well):
\begin{equation*}
\begin{split}\frac{\partial l_{N}}{\partial\vec{a}}(\hat{\vec{a}})=0\end{split}
\end{equation*}

\paragraph{Consistency of the MLE}
\label{\detokenize{theory:consistency-of-the-mle}}
\sphinxAtStartPar
We continue by formulating and prooving the following theorem:

\sphinxAtStartPar
The true parameters \(\vec{a}_{0}\) maximize the funtion
\(l(\vec{a})\)
\begin{equation*}
\begin{split}l(\vec{a})\le l(\vec{a}_{0})\ \ \forall\vec{a}\text{ and }l(\vec{a})=l(\vec{a}_{0})\text{ only if }\vec{a}=\vec{a}_{0}\end{split}
\end{equation*}
\sphinxAtStartPar
To prove this, we rewrite the difference
\(l(\vec{a})-l(\vec{a}_{0})\)
\begin{equation*}
\begin{split}\begin{aligned}
l(\vec{a})-l(\vec{a}_{0}) & =\int_{-\infty}^{+\infty}\log\left[p(q|\vec{a})\right]p(q|\vec{a}_{0})dq-\int_{-\infty}^{+\infty}\log\left[p(q|\vec{a}_{0})\right]p(q|\vec{a}_{0})dq\\
 & =\int_{-\infty}^{+\infty}\log\left[\frac{p(q|\vec{a})}{p(q|\vec{a}_{0})}\right]p(q|\vec{a}_{0})dq\\
 & \le\int_{-\infty}^{+\infty}\left[\frac{p(q|\vec{a})}{p(q|\vec{a}_{0})}-1\right]p(q|\vec{a}_{0})dq\\
 & =\int_{-\infty}^{+\infty}\left[p(q|\vec{a})-p(q|\vec{a}_{0})\right]dq=0\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
In the third line we used the inequality \(\log x\le x-1\) valid
\(\forall x>0\). Furthermore, since the probability density
\(p(q|\vec{a}_{0})\) is postive everywhere, the equality can only
hold if \(\log\left[\frac{p(q|\vec{a})}{p(q|\vec{a}_{0})}\right]\)
is zero everywhere, which implies that
\(p(q|\vec{a})=p(q|\vec{a}_{0})\) everywhere and hence
\(\vec{a}=\vec{a}_{0}\).
\begin{equation*}
\begin{split}Q.E.D.\end{split}
\end{equation*}
\sphinxAtStartPar
As such, we know now that the true parameters \(\vec{a}_{0}\)
maximize the function \(l(\vec{a})\) while the maximum likelihood
estimator \(\hat{\vec{a}}\) maximizes the corresponding estimator
function \(l_{N}(\vec{a})\). Since \(l(\vec{a})\) represents the
mean of a random variable, while \(l_{N}(\vec{a})\) represents the
sample average of this random variable, we can apply the law of large
numbers (LLN). Hence, the estimator function \(l_{N}(\vec{a})\) will
approach the true mean \(l(\vec{a})\) in the limit for sample sizes
approaching infinity. As a result we can conclude the same thing about
the maxima of these functions, i.e. the MLE will approach the true
parameters in the same limit:
\begin{equation*}
\begin{split}\begin{aligned}
l_{N}(\vec{a})\rightarrow l(\vec{a}) & \text{ as }N\rightarrow+\infty\\
\hat{\vec{a}}\rightarrow\vec{a}_{0} & \text{ as }N\rightarrow+\infty\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The result of the last line is referred to as \sphinxstyleemphasis{consistency} of the MLE,
which is not the same as being unbiased, but is important for its
interpretation as an adequate estimator of the true parameters.


\paragraph{Fisher information}
\label{\detokenize{theory:fisher-information}}
\sphinxAtStartPar
In order to derive an estimate for the error on the MLE, we first need
to introduce the Fisher information.

\sphinxAtStartPar
The Fisher information is defined as the following matrix:
\begin{equation*}
\begin{split}\bar{\bar{I}}(\vec{a}_{0})=E_{\vec{a}_{0}}\left[\left(\frac{\partial}{\partial\vec{a}}\log p(q|\vec{a}_{0})\right)\left(\frac{\partial}{\partial\vec{a}}\log p(q|\vec{a}_{0})\right)^{T}\right]\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{with matrix elements:}
\begin{equation*}
\begin{split}I_{kl}(\vec{a}_{0})=E_{\vec{a}_{0}}\left[\left(\frac{\partial}{\partial a_{k}}\log p(q|\vec{a}_{0})\right)\left(\frac{\partial}{\partial a_{l}}\log p(q|\vec{a}_{0})\right)\right]\end{split}
\end{equation*}
\sphinxAtStartPar
Herein, the notation
\(\frac{\partial}{\partial a_{k}}\log p(q|\vec{a}_{0})\) indicates
we first take the derivatieve of \(\log p(q|\vec{a})\) with respect
to \(a_{k}\) and then evaluate at \(\vec{a}=\vec{a}_{0}\). We
proceed by formulating and proving an important theorem about the Fisher
information.

\sphinxAtStartPar
The Fisher information can be computed from the expectation value of the
second order derivative of \(\log p(q|\vec{a})\) as follows:
\begin{equation*}
\begin{split}\begin{aligned}
\bar{\bar{I}}(\vec{a}_{0}) & =-E_{\vec{a}_{0}}\left[\frac{\partial^{2}}{\partial\vec{a}^{2}}\log p(q|\vec{a}_{0})\right]\\
I_{kl}(\vec{a}_{0}) & =-E_{\vec{a}_{0}}\left[\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\log p(q|\vec{a}_{0})\right]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
We start by rewriting the second order derivative
\begin{equation*}
\begin{split}\begin{aligned}
\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\left[\log p(q|\vec{a})\right] & =\frac{\partial}{\partial a_{l}}\left[\frac{1}{p(q|\text{\ensuremath{\vec{a}}})}\frac{\partial p(q|\vec{a})}{\partial a_{k}}\right]=\frac{1}{p(q|\text{\ensuremath{\vec{a}}})}\frac{\partial^{2}p(q|\vec{a})}{\partial a_{k}\partial a_{l}}-\frac{1}{(p(q|\vec{a}))^{2}}\frac{\partial p(q|\vec{a})}{\partial a_{k}}\frac{\partial p(q|\vec{a})}{\partial a_{l}}\\
 & =\frac{1}{p(q|\text{\ensuremath{\vec{a}}})}\frac{\partial^{2}p(q|\vec{a})}{\partial a_{k}\partial a_{l}}-\frac{\partial\log p(q|\vec{a})}{\partial a_{k}}\frac{\partial\log p(q|\vec{a})}{\partial a_{l}}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Next, we can compute the expected value
\begin{equation*}
\begin{split}\begin{aligned}
E_{\vec{a}_{0}}\left[\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\log p(q|\vec{a}_{0})\right] & =\int_{-\infty}^{+\infty}\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\left[\log p(q|\vec{a}_{0})\right]p(q|\vec{a}_{0})dq\\
 & =\int_{-\infty}^{+\infty}\left[\frac{1}{p(q|\vec{a}_{0})}\frac{\partial^{2}p(q|\vec{a}_{0})}{\partial a_{k}\partial a_{l}}-\frac{\partial\log p(q|\vec{a}_{0})}{\partial a_{k}}\frac{\partial\log p(q|\vec{a}_{0})}{\partial a_{l}}\right]p(q|\vec{a}_{0})dq\\
 & =\int_{-\infty}^{+\infty}\frac{1}{p(q|\vec{a}_{0})}\frac{\partial^{2}p(q|\vec{a}_{0})}{\partial a_{k}\partial a_{l}}p(q|\vec{a}_{0})dq-\int_{-\infty}^{+\infty}\frac{\partial\log p(q|\vec{a}_{0})}{\partial a_{k}}\frac{\partial\log p(q|\vec{a}_{0})}{\partial a_{l}}p(q|\vec{a}_{0})dq\\
 & =\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\left[\underbrace{\int_{-\infty}^{+\infty}p(q|\vec{a}_{0})dq}_{=1}\right]-E_{\vec{a}_{0}}\left[\left(\frac{\partial}{\partial a_{k}}\log p(q|\vec{a}_{0})\right)\left(\frac{\partial}{\partial a_{l}}\log p(q|\vec{a}_{0})\right)\right]\\
 & =-I_{kl}(\vec{a}_{0})\end{aligned}\end{split}
\end{equation*}\begin{equation*}
\begin{split}Q.E.D\end{split}
\end{equation*}
\sphinxAtStartPar
As a result, we now know the following about the function
\(l(\vec{a})\):
\begin{equation*}
\begin{split}\begin{aligned}
l(\vec{a}) & =E_{\vec{a}_{0}}\left[\log\left(p(q|\vec{a})\right)\right]\\
\frac{\partial l}{\partial\vec{a}}(\vec{a}_{0}) & =E_{\vec{a}_{0}}\left[\frac{\partial}{\partial\vec{a}}\log\left(p(q|\vec{a}_{0})\right)\right]=0\text{ (as }\vec{a}_{0}\text{ represents the maximum of }l\text{)}\\
\frac{\partial^{2}l}{\partial\vec{a}\partial\vec{a}}(\vec{a}_{0}) & =E_{\vec{a}_{0}}\left[\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\log p(q|\vec{a}_{0})\right]=-\bar{\bar{I}}(\vec{a}_{0})\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
These relations represent properties of the population mean of
\(\log\left(p(q|\vec{a})\right)\) which we will now use to say
something about the properties of the sample average \(l_{N}\) and
the distribution of its maximum, i.e. the MLE.


\paragraph{Asymptotic normality of the MLE{[}subsec:Asymptotic\sphinxhyphen{}normality{]}}
\label{\detokenize{theory:asymptotic-normality-of-the-mle-subsec-asymptotic-normality}}
\sphinxAtStartPar
Asymptotic normality expresses that when the sample size \(N\)
approaches infinity, the distribution of the MLE will approach a
multivariate normal distribution with a mean given by the true
parameters \(\vec{a}_{0}\) and a covariance matrix related to the
inverseof the Fisher information. Mathematically, this is expressed in
the following theorem.

\sphinxAtStartPar
The MLE converges in probability towards a normal distribution centered
around the true parameters with (co)variance related to the Fisher
information
\begin{equation*}
\begin{split}\sqrt{N}\left(\hat{\vec{a}}-\vec{a}_{0}\right)\xrightarrow{distribution}\mathcal{N}(\vec{0},\left[\bar{\bar{I}}(\vec{a}_{0})\right]^{-1})\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstyleemphasis{or equivalently}
\begin{equation*}
\begin{split}\hat{\vec{a}}\xrightarrow{distribution}\mathcal{N}\left(\vec{a}_{0},\frac{\left[\bar{\bar{I}}(\vec{a}_{0})\right]^{-1}}{N}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
where the second argument of the normal distribution denotes the
covariance matrix (which is why \(\sqrt{N}\) gets squared).

\sphinxAtStartPar
The proof starts with an application of the mean value theorem. We
consider the function
\begin{equation*}
\begin{split}f_{k}(t)=\frac{\partial}{\partial a_{k}}l_{N}(\hat{\vec{a}}\cdot t+\vec{a}_{0}\cdot(1-t))\end{split}
\end{equation*}
\sphinxAtStartPar
and apply the mean value theorem to it:
\begin{equation*}
\begin{split}\exists c_{k}\in\left[0,1\right]:f'_{k}(c_{k})=\frac{f_{k}(1)-f_{k}(0)}{1-0}\end{split}
\end{equation*}
\sphinxAtStartPar
We first define
\begin{equation*}
\begin{split}\vec{a}_{1}(t)=\hat{\vec{a}}\cdot t+\vec{a}_{0}\cdot(1-t)\end{split}
\end{equation*}
\sphinxAtStartPar
and evaluate the left hand side:
\begin{equation*}
\begin{split}\begin{aligned}
f'_{k}(c_{k}) & =\frac{\partial}{\partial\vec{a}}\left[\frac{\partial}{\partial a_{k}}l_{N}(\vec{a})\right]_{\vec{a}=\vec{a}_{1}(c_{k})}\cdot\frac{d}{dt}\left(\vec{a}_{1}(t)\right)_{t=c_{k}}\\
 & =\frac{\partial}{\partial\vec{a}}\left[\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{1}(c_{k}))\right]\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The right\sphinxhyphen{}hand side becomes:
\begin{equation*}
\begin{split}f_{k}(1)-f_{k}(0)=\frac{\partial}{\partial a_{k}}l_{N}(\hat{\vec{a}})-\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{0})\end{split}
\end{equation*}
\sphinxAtStartPar
We know consider the limit \(N\rightarrow+\infty\). In this limit,
\(\hat{\vec{a}}\rightarrow\vec{a}_{0}\) which implies that
\(\vec{a}_{1}(c_{k})\rightarrow\vec{a}_{0}\) for each value of
\(k\). Hence, we find that in this limit
\begin{equation*}
\begin{split}\frac{\partial}{\partial\vec{a}}\left[\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{0})\right]\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right)=\frac{\partial}{\partial a_{k}}l_{N}(\hat{\vec{a}})-\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{0})\end{split}
\end{equation*}
\sphinxAtStartPar
Since this is valid for each value of \(k\) and further more
\(\frac{\partial}{\partial a_{k}}l_{N}(\hat{\vec{a}})=0\) per
definition of the MLE, we find for \(N\rightarrow+\infty\):
\begin{equation*}
\begin{split}\begin{aligned}
\frac{\partial^{2}}{\partial\vec{a}\partial\vec{a}}l_{N}(\vec{a}_{0})\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right) & =-\frac{\partial}{\partial\vec{a}}l_{N}(\vec{a}_{0})\label{eq:asnorm_rel-1}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Or equivalently
\begin{equation*}
\begin{split}\begin{aligned}
\bar{\bar{I}}(\vec{a}_{0})\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right) & =\frac{\partial}{\partial\vec{a}}l_{N}(\vec{a}_{0})\label{eq:asnorm_rel0}\\
\sqrt{N}\left(\hat{\vec{a}}-\vec{a}_{0}\right) & =\sqrt{N}\left[\bar{\bar{I}}(\vec{a}_{0})\right]^{-1}\cdot\frac{\partial}{\partial\vec{a}}l_{N}(\vec{a}_{0})\label{eq:asnorm_rel1}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
We now focus on the distribution of
\(\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{0})\) in the limit
\(N\rightarrow+\infty\):
\begin{equation*}
\begin{split}\begin{aligned}
\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{0}) & =\frac{\partial}{\partial a_{k}}\left[\frac{1}{N}\sum_{n=1}^{N}\log p(q_{n}|\vec{a})\right]_{\vec{a}=\vec{a}_{0}}\\
 & =\frac{1}{N}\sum_{n=1}^{N}\frac{\partial}{\partial a_{k}}\log p(q_{n}|\vec{a}_{0})\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Since we already know that
\(E_{\vec{a}_{0}}\left[\frac{\partial}{\partial\vec{a}}\log\left(p(q|\vec{a}_{0})\right)\right]=0\)
we can rewrite this as:
\begin{equation*}
\begin{split}\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{0})=\bar{X}-E\left[X\right]\label{eq:asnorm_X}\end{split}
\end{equation*}
\sphinxAtStartPar
with
\begin{equation*}
\begin{split}\bar{X}=\frac{1}{N}\sum_{n=1}^{N}X_{n}\end{split}
\end{equation*}
\sphinxAtStartPar
the sample average of the random variable
\(X=\frac{\partial}{\partial\vec{a}}\log\left(p(q|\vec{a}_{0})\right)\)
with corresponding samples
\(X_{n}=\frac{\partial}{\partial\vec{a}}\log\left(p(q_{n}|\vec{a}_{0})\right)\).
As a result, the central limit theorem can be applied to Eq
{\hyperref[\detokenize{theory:eq:asnorm_X}]{\emph{{[}eq:asnorm\_X{]}}}}, which tells us:
\begin{equation*}
\begin{split}\sqrt{N}\cdot\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{0})\xrightarrow{distribution}\mathcal{N}\left(0,\bar{\bar{\sigma}}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
in which \(\bar{\bar{\sigma}}\) represents the covariance matrix of
the normal distribution, which we will now determine.
\begin{equation*}
\begin{split}\begin{aligned}
\sigma_{kl} & =E_{\vec{a}_{0}}\left[\left(\frac{\partial}{\partial a_{k}}\log\left(p(q|\vec{a}_{0})\right)-\underbrace{E_{\vec{a}_{0}}\left[\frac{\partial}{\partial a_{k}}\log p(q|\vec{a}_{0})\right]}_{=0}\right)\left(\frac{\partial}{\partial a_{l}}\log\left(p(q|\vec{a}_{0})\right)-\underbrace{E_{\vec{a}_{0}}\left[\frac{\partial}{\partial a_{l}}\log p(q|\vec{a}_{0})\right]}_{=0}\right)\right]\\
 & =E_{\vec{a}_{0}}\left[\frac{\partial}{\partial a_{k}}\log\left(p(q|\vec{a}_{0})\right)\frac{\partial}{\partial a_{l}}\log\left(p(q|\vec{a}_{0})\right)\right]\\
 & =I_{kl}(\vec{a}_{0})\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
which result in:
\begin{equation*}
\begin{split}\sqrt{N}\cdot\frac{\partial}{\partial a_{k}}l_{N}(\vec{a}_{0})\xrightarrow{distribution}\mathcal{N}\left(0,\bar{\bar{I}}(\vec{a}_{0})\right)\label{eq:asnorm_rel2}\end{split}
\end{equation*}
\sphinxAtStartPar
Combining Eq. {\hyperref[\detokenize{theory:eq:asnorm_rel1}]{\emph{{[}eq:asnorm\_rel1{]}}}} with Eq.
{\hyperref[\detokenize{theory:eq:asnorm_rel2}]{\emph{{[}eq:asnorm\_rel2{]}}}} we find:
\begin{equation*}
\begin{split}\sqrt{N}\left(\hat{\vec{a}}-\vec{a}_{0}\right)\xrightarrow{distribution}\left[\bar{\bar{I}}(\vec{a}_{0})\right]^{-1}\cdot\mathcal{N}\left(0,\bar{\bar{I}}(\vec{a}_{0})\right)=\mathcal{N}\left(0,\left[\bar{\bar{I}}(\vec{a}_{0})\right]^{-2}\bar{\bar{I}}(\vec{a}_{0})\right)=\mathcal{N}\left(0,\left[\bar{\bar{I}}(\vec{a}_{0})\right]^{-1}\right)\end{split}
\end{equation*}\begin{equation*}
\begin{split}Q.E.D.\end{split}
\end{equation*}
\sphinxAtStartPar
As a final remark, we note that usually, one does not know the true
parameters \(\vec{a}_{0}\) and hence one also does not know the
Fisher matrix. Therefore, in order to estimate the (co)variance of the
MLE estimator, we can use an important property of the MLE estimator
that expresses that for any function \(f(\vec{a})\), the estimator
\(f(\hat{\vec{a}})\) is a good estimator for \(f(\vec{a}_{0})\).
Hence, we can estimate the Fisher matrix as
\(\bar{\bar{I}}(\hat{\vec{a}})\).


\paragraph{Example 1 \sphinxhyphen{} Bernoulli experiment}
\label{\detokenize{theory:example-1-bernoulli-experiment}}
\sphinxAtStartPar
Consider performing an experiment \sphinxstepexplicit %
\begin{footnote}[3]\phantomsection\label{\thesphinxscope.3}%
\sphinxAtStartFootnote
An experiment has to be interpreted in the broad sense here, i.e. it
can also be a computational experiment or thought experiment.
%
\end{footnote} who’s outcome can be either
succes, with probability \(a>0\), or failure with probability
\(1-a>0\). If we define a random variable \(Q\) with outcome
\(q=1\) for success and \(q=0\) for failure, we can write down
the probability distribution such an experiment as:
\begin{equation*}
\begin{split}\begin{aligned}
p(q|a) & =a^{q}(1-a)^{1-q}\\
\log p(q|a) & =q\log(a)+(1-q)\log(1-a)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
which gives rise to the population average:
\begin{equation*}
\begin{split}E_{a_{0}}[q]=a_{0}\end{split}
\end{equation*}
\sphinxAtStartPar
We can also define \(l(a)\):
\begin{equation*}
\begin{split}\begin{aligned}
l(a) & =E_{a_{0}}[\log p(q|a)]\\
 & =E_{a_{0}}[q]\cdot\log(a)+\left(1-E_{a_{0}}[q]\right)\log(1-a)\\
 & =a_{0}\cdot\log(a)+\left(1-a_{0}\right)\log(1-a)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Unfortunately, we cannot not evaluate this function, as we do not know
the true parameter \(a_{0}\). However, we can easily check that
\(l(a)\) is indeed maximized by the true parameter \(a=a_{0}\).
Now assume we have actually performed the experiment \(N\) times,
i.e. we have a sample consisting of \(N\) observations
\(q_{i}\). We can then define the function \(l_{N}\):
\begin{equation*}
\begin{split}\begin{aligned}
l_{N}(a) & =\frac{1}{N}\sum_{n=1}^{N}\left[q_{n}\log(a)+(1-q_{n})\log(1-a)\right]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
which serves as an N\sphinxhyphen{}estimate of the unknown function \(l(a)\).
Furthermore, by the law of large numbers, the estimate \(l_{N}(a)\)
converges to \(l(a)\) for large sample size \(N\). The maximum
likelihood estimator (MLE) \(\hat{a}\) for the true parameter can be
found by maximizing \(l_{N}(a)\):
\begin{equation*}
\begin{split}\begin{aligned}
\frac{dl_{N}}{da} & =0=\frac{1}{N}\sum_{n=1}^{N}\left[\frac{q_{n}}{\hat{a}}-\frac{1-q_{n}}{1-\hat{a}}\right]\\
0 & =\frac{\sum_{n=1}^{N}q_{n}}{\hat{a}}-\frac{N-\sum_{n=1}^{N}q_{n}}{1-\hat{a}}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Defining \(n_{s}=\sum_{n=1}^{N}q_{n}\) as the number of successes,
we find:
\begin{equation*}
\begin{split}\hat{a}=\frac{\sum_{i=1}^{N}q_{i}}{N}=\frac{n_{s}}{N}\end{split}
\end{equation*}
\sphinxAtStartPar
To estimate the error on the MLE, we will need to compute the Fisher
information and evaluate it in the MLE.
\begin{equation*}
\begin{split}\begin{aligned}
I(\hat{a}) & =-E_{\hat{a}}\left[\frac{d^{2}}{da^{2}}\log p(q|\hat{a})\right]\\
 & =-E_{\hat{a}}\left[\frac{d^{2}}{da^{2}}\left(q\log(a)+(1-q)\log(1-a)\right)_{a=\hat{a}}\right]\\
 & =-E_{\hat{a}}\left[\frac{d}{da}\left(\frac{q}{a}-\frac{1-q}{1-a}\right)_{a=\hat{a}}\right]\\
 & =-E_{\hat{a}}\left[-\frac{q}{\hat{a}^{2}}-\frac{1-q}{(1-\hat{a})^{2}}\right]\\
 & =\frac{E_{\hat{a}}[q]}{\hat{a}^{2}}+\frac{1-E_{\hat{a}}[q]}{(1-\hat{a})^{2}}\\
 & =\frac{\hat{a}}{\hat{a}^{2}}+\frac{1-\hat{a}}{(1-\hat{a})^{2}}\\
I(\hat{a}) & =\frac{1}{\hat{a}(1-\hat{a})}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
As a result, the variance on the MLE is given by:
\begin{equation*}
\begin{split}\text{Var}[\hat{a}]=\frac{\left[I(\hat{a})\right]^{-1}}{N}=\frac{\hat{a}(1-\hat{a})}{N}=\frac{n_{s}}{N^{2}}(1-\frac{n_{s}}{N})\end{split}
\end{equation*}
\sphinxAtStartPar
Finally, we can express the \(95\)\%\sphinxhyphen{}confidence interval (i.e.
2\sphinxhyphen{}sigma interval) for an estimate of the true parameters as:
\begin{equation*}
\begin{split}\begin{aligned}
a_{0} & \approx\hat{a}\pm2\sqrt{\text{Var}[\hat{a}]}\\
 & \approx\frac{n_{s}}{N}\pm2\frac{\sqrt{n_{s}(1-\frac{n_{s}}{N})}}{N}\end{aligned}\end{split}
\end{equation*}

\paragraph{Example 2 \sphinxhyphen{} histogram estimation from MD simulation{[}subsec:Example2\sphinxhyphen{}single\sphinxhyphen{}histogram{]}}
\label{\detokenize{theory:example-2-histogram-estimation-from-md-simulation-subsec-example2-single-histogram}}
\sphinxAtStartPar
In this example, we want to estimate the probability density function
\(p(q)\) associated with finding a molecular system to have a
configuration in which the collective variable \(Q(\vec{r}^{N})\)
takes the value \(q\) through the construction of a histogram
including an errorbar. The samples required for such estimate are
provided by a molecular dynamics (or Monte Carlo) simulation (which we
also assume to be uncorrelated). As we are interested in constructing a
historgram, we define our probability model as was introduced in section
{\hyperref[\detokenize{theory:subsec:Probability-model}]{\emph{{[}subsec:Probability\sphinxhyphen{}model{]}}}}:
\begin{equation*}
\begin{split}p(q|\vec{a})=\sum_{k=1}^{K}a_{k}\phi_{k}(q)\label{eq:ex2_probdens}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\phi_{k}\) represents a function corresponding to the bin
centered around value \(Q_{k}\):
\begin{equation*}
\begin{split}\phi_{k}(q)=\begin{cases}
\frac{1}{\Delta} & q\in[Q_{k}-\frac{\Delta}{2},Q_{k}+\frac{\Delta}{2}]\\
0 & elsewhere
\end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
with \(\Delta\) an a priori chosen bin width and \(Q_{k}\) the a
priori chosen bin centers. Note that each bin function \(\phi_{k}\)
is normalized to \(1\). Hence, since the probability density
function also needs to be normalized, we require:
\begin{equation*}
\begin{split}\sum_{k=1}^{K}a_{k}=1\end{split}
\end{equation*}
\sphinxAtStartPar
This represents a constraint on the parameters
\(\vec{\ensuremath{a}}\) which we will impose on the maximization of
the likelihood using the technique of Lagrange multipliers. We therefore
replace the function \(l_{N}(\vec{a})\) with its constrained
alternative \(l_{N}^{(c)}(\vec{a},\mu)\):
\begin{equation*}
\begin{split}\begin{aligned}
l_{N}^{(c)}(\vec{a},\mu) & =l_{N}(\vec{a})+\mu\left[1-\sum_{k=1}^{K}a_{k}\right]\\
 & =\frac{1}{N}\sum_{n=1}^{N}\log p(q_{n}|\vec{a})+\mu\left[1-\sum_{k=1}^{K}a_{k}\right]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
We proceed with computing the MLE:
\begin{equation*}
\begin{split}\begin{aligned}
\frac{\partial}{\partial a_{k}}l_{N}^{(c)}(\vec{a},\mu) & =0=\frac{1}{N}\sum_{n=1}^{N}\frac{1}{p(q_{n}|\vec{a})}\frac{\partial p}{\partial a_{k}}(q_{i}|\vec{a})-\mu\label{eq:ex2_MLEeq1}\\
\frac{\partial}{\partial\mu}l_{N}^{(c)}(\vec{a},\mu) & =0=1-\sum_{k=1}^{K}a_{k}\label{eq:ex2_MLEeq2}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
From Eq. {\hyperref[\detokenize{theory:eq:ex2_probdens}]{\emph{{[}eq:ex2\_probdens{]}}}} we find:
\begin{equation*}
\begin{split}\frac{\partial p}{\partial a_{k}}(q_{n}|\vec{a})=\phi_{k}(q_{n})=\frac{\delta_{k,k_{n}}}{\Delta}\end{split}
\end{equation*}
\sphinxAtStartPar
Since \(\phi_{k}(q_{i})\) is only non\sphinxhyphen{}zero if
\(q_{i}\in[Q_{k}-\frac{\Delta}{2},Q_{k}+\frac{\Delta}{2}]\), we
introduce \(k_{n}\) which represents that \(k\)\sphinxhyphen{}value for which
the corresponding bin contains \(q_{n}\). As such, we can rewrite
Eq. {\hyperref[\detokenize{theory:eq:ex2_MLEeq1}]{\emph{{[}eq:ex2\_MLEeq1{]}}}} as:
\begin{equation*}
\begin{split}\begin{aligned}
\frac{1}{\Delta}\sum_{n=1}^{N}\frac{\delta_{k,k_{n}}}{\sum_{k=1}^{K}a_{k}\phi_{k}(q_{n})} & =N\mu\\
\sum_{n=1}^{N}\frac{\delta_{k,k_{n}}}{\sum_{l=1}^{K}a_{l}\delta_{l,k_{n}}} & =N\mu\\
\sum_{n=1}^{N}\frac{\delta_{k,k_{n}}}{a_{k_{n}}} & =N\mu\\
\frac{1}{a_{k}}\sum_{n=1}^{N}\delta_{k,k_{n}} & =N\mu\\
a_{k} & =\frac{\sum_{n=1}^{N}\delta_{k,k_{n}}}{N\mu}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
We define the quantity \(H_{k}\) as:
\begin{equation*}
\begin{split}H_{k}=\sum_{n=1}^{N}\delta_{k,k_{n}}\end{split}
\end{equation*}
\sphinxAtStartPar
which represents the number of samples with \(Q\)\sphinxhyphen{}value within the
\(k\)\sphinxhyphen{}th bin
\([Q_{k}-\frac{\Delta}{2},Q_{k}+\frac{\Delta}{2}]\). As such, we
find:
\begin{equation*}
\begin{split}a_{k}=\frac{H_{k}}{N\mu}\end{split}
\end{equation*}
\sphinxAtStartPar
To determine the Lagrange multiplier \(\mu\) we use Eq.
{\hyperref[\detokenize{theory:eq:ex2_MLEeq2}]{\emph{{[}eq:ex2\_MLEeq2{]}}}}:
\begin{equation*}
\begin{split}1=\sum_{k=1}^{K}\hat{a}_{k}=\sum_{k=1}^{K}\frac{H_{k}}{N\hat{\mu}}=\frac{\sum_{k=1}^{K}H_{k}}{N\hat{\mu}}=\frac{N}{N\hat{\mu}}\Rightarrow\hat{\mu}=1\end{split}
\end{equation*}
\sphinxAtStartPar
Hence, the MLE for the histogram populations can be found as:
\begin{equation*}
\begin{split}\begin{aligned}
\hat{a}_{k} & =\frac{H_{k}}{N}\\
p(q|\hat{\vec{a}}) & =\sum_{k=1}^{K}\frac{H_{k}}{N}\phi_{k}(q)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Note that \(\hat{a}_{k}\) also corresponds to the MLE estimator for
the probability in a Bernoulli experiment where success is defined as
“finding an MD sample with
\(Q(\vec{r}^{N})\in[Q_{k}-\frac{\Delta}{2},Q_{k}+\frac{\Delta}{2}]\)”.
To compute a reliable estimate of the error bar on each histogram count,
we first need to compute the Fisher information. Given the special
meaning of the Lagrange multiplier \(\mu\) (which isn’t a true
parameters we are interested in), we write the Fisher matrix formally as
a block matrix (for convenience, we will drop the dependence of the
Fisher matrix elements on the paramters \(\vec{a}\) and
\(\mu\)):
\begin{equation*}
\begin{split}\bar{\bar{I}}=\begin{bmatrix}\bar{\bar{I}}^{aa} & \bar{I}^{a\mu}\\
\left[\bar{I}^{a\mu}\right]^{T} & I^{\mu\mu}
\end{bmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
with the following matrix elements:
\begin{equation*}
\begin{split}\begin{aligned}
I_{k,l}^{aa} & =-E\left[\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\log p^{(c)}(q|\hat{\vec{a}},\hat{\mu})\right]\\
I_{k}^{a\mu} & =-E\left[\frac{\partial^{2}}{\partial a_{k}\partial\mu}\log p^{(c)}(q|\hat{\vec{a}},\hat{\mu})\right]\\
I^{\mu\mu} & =-E\left[\frac{\partial^{2}}{\partial\mu^{2}}\log p^{(c)}(q|\hat{\vec{a}},\hat{\mu})\right]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where we introduced the probability density function
\(p^{(c)}(q|\vec{a},\mu)\) corresponding to the constrained function
\(l_{N}^{(c)}(\vec{a},\mu)\):
\begin{equation*}
\begin{split}\begin{aligned}
l_{N}^{(c)}(\vec{a},\mu) & =\frac{1}{N}\sum_{n=1}^{N}\log p(q_{n}|\vec{a})+\mu\left[1-\sum_{k=1}^{K}a_{k}\right]=\frac{1}{N}\sum_{n=1}^{N}\log p^{(c)}(q_{n}|\vec{a})\\
\Rightarrow\log p^{(c)}(q_{n}|\vec{a}) & =\log p(q_{n}|\vec{a})+\mu\left[1-\sum_{k=1}^{K}a_{k}\right]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Using this function, we can compute the Fisher matrix elements:
\begin{equation*}
\begin{split}\begin{aligned}
I_{k,l}^{aa} & =-E\left[\frac{\partial}{\partial a_{k}}\left(\frac{1}{p(q|\hat{\vec{a}})}\frac{\partial p(q|\hat{\vec{a}})}{\partial a_{l}}-\mu\right)\right]=-E\left[\frac{\partial}{\partial a_{k}}\left(\frac{\phi_{l}(q)}{p(q|\hat{\vec{a}})}-\mu\right)\right]\\
 & =E\left[\frac{\phi_{l}(q)}{\left(p(q|\hat{\vec{a}})\right)^{2}}\frac{\partial p(q|\hat{\vec{a}})}{\partial a_{k}}\right]=E\left[\frac{\phi_{k}(q)\phi_{l}(q)}{\left(\sum_{n=1}^{K}\hat{a}_{n}\phi_{n}(q)\right)^{2}}\right]\\
 & =\int_{-\infty}^{+\infty}\frac{\phi_{k}(q)\phi_{l}(q)}{\left(\sum_{s=1}^{K}\hat{a}_{s}\phi_{s}(q)\right)^{2}}p^{(c)}(q|\vec{a},\mu)dq\\
 & =\int_{-\infty}^{+\infty}\frac{\phi_{k}(q)\phi_{l}(q)}{\left(\sum_{s=1}^{K}\hat{a}_{s}\phi_{s}(q)\right)^{2}}\left(\sum_{s=1}^{K}\hat{a}_{s}\phi_{s}(q)\right)e^{\mu\overbrace{\left(1-\sum_{s=1}^{K}\hat{a}_{s}\right)}^{=0}}dq\\
 & =\int_{-\infty}^{+\infty}\frac{\phi_{k}(q)\phi_{l}(q)}{\sum_{s=1}^{K}\hat{a}_{s}\phi_{s}(q)}dq\\
 & =\sum_{m=0}^{K}\int_{Q_{m}-\frac{\Delta}{2}}^{Q_{m}+\frac{\Delta}{2}}\frac{\phi_{k}(q)\phi_{l}(q)}{\sum_{s=1}^{K}\hat{a}_{s}\phi_{s}(q)}dq=\sum_{m=0}^{K}\int_{Q_{m}-\frac{\Delta}{2}}^{Q_{m}+\frac{\Delta}{2}}\frac{\frac{\delta_{k,m}}{\Delta}\frac{\delta_{l,m}}{\Delta}}{\frac{\hat{a}_{m}}{\Delta}}dq\\
 & =\sum_{m=0}^{K}\frac{\delta_{k,m}\delta_{l,m}}{\Delta\hat{a}_{m}}\underbrace{\int_{Q_{m}-\frac{\Delta}{2}}^{Q_{m}+\frac{\Delta}{2}}dq}_{=\Delta}\\
I_{k,l}^{aa} & =\frac{\delta_{k,l}}{\hat{a}_{k}}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The matrix elements coming from the other blocks are easier to compute:
\begin{equation*}
\begin{split}\begin{aligned}
I_{k}^{a\mu} & =-E\left[\frac{\partial}{\partial\mu}\left(\frac{1}{p(q|\hat{\vec{a}})}\frac{\partial p(q|\hat{\vec{a}})}{\partial a_{k}}-\mu\right)\right]=-E\left[-1\right]=1\\
I^{\mu\mu} & =-E\left[\frac{\partial}{\partial\mu}\left(1-\sum_{k=1}^{K}a_{k}\right)\right]=-E\left[0\right]=0\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Hence we find the following Fisher matrix:
\begin{equation*}
\begin{split}\bar{\bar{I}}=\begin{bmatrix}\frac{1}{\hat{a}_{1}} & 0 & \cdots & 0 & 1\\
0 & \frac{1}{a_{2}} & \cdots & 0 & 1\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
0 & 0 & \cdots & \frac{1}{a_{K}} & 1\\
1 & 1 & \cdots & 1 & 0
\end{bmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
The inverse of this matrix, which is proportional to the covariance we
are interested in, is given by (taking into account the constraint
\(\sum_{k=1}^{K}a_{k}=1\)):
\begin{equation*}
\begin{split}\left[\bar{\bar{I}}\right]^{-1}=\begin{bmatrix}\hat{a}_{1}(1-\hat{a}_{1}) & -\hat{a}_{1}\hat{a}_{2} & \cdots & -\hat{a}_{1}\hat{a}_{K} & \hat{a}_{1}\\
-\hat{a}_{1}\hat{a}_{2} & \hat{a}_{2}(1-\hat{a}_{2}) & \cdots & -\hat{a}_{2}\hat{a}_{K} & \hat{a}_{2}\\
\vdots & \vdots & \ddots & \vdots & \vdots\\
-\hat{a}_{1}\hat{a}_{K} & -\hat{a}_{2}\hat{a}_{K} & \cdots & \hat{a}_{K}(1-\hat{a}_{K}) & \hat{a}_{K}\\
\hat{a}_{1} & \hat{a}_{2} & \cdots & \hat{a}_{K} & -1
\end{bmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
Since we are only interested in the true parameters \(\vec{a}\), we
find the following covariance matrix for these parameters:
\begin{equation*}
\begin{split}\text{Cov\ensuremath{\left[\hat{\vec{a}},\hat{\vec{a}}\right]}}=\frac{1}{N}\begin{bmatrix}\hat{a}_{1}(1-\hat{a}_{1}) & -\hat{a}_{1}\hat{a}_{2} & \cdots & -\hat{a}_{1}\hat{a}_{K}\\
-\hat{a}_{1}\hat{a}_{2} & \hat{a}_{2}(1-\hat{a}_{2}) & \cdots & -\hat{a}_{2}\hat{a}_{K}\\
\vdots & \vdots & \ddots & \vdots\\
-\hat{a}_{1}\hat{a}_{K} & -\hat{a}_{2}\hat{a}_{K} & \cdots & \hat{a}_{K}(1-\hat{a}_{K})
\end{bmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
Finally, this allows us to write down the error bar (again using
95\%\sphinxhyphen{}confidence interval or 2\sphinxhyphen{}sigma) on the histogram probability for bin
\(k\):
\begin{equation*}
\begin{split}a_{0,k}\approx\frac{H_{k}}{N}\pm2\frac{\sqrt{H_{k}(1-\frac{H_{k}}{N})}}{N}\label{eq:histogram_estimation_errorbar}\end{split}
\end{equation*}
\sphinxAtStartPar
Note that this is again the same result as for the MLE estimator for the
probability in a Bernoulli experiment. However, we now also have access
to the covariance (and hence the correlation) between e.g. the
probability in bin \(k\) and that in bin \(l\):
\begin{equation*}
\begin{split}\begin{aligned}
\text{Cov}\left[\hat{a}_{k},\hat{a}_{l}\right] & =\frac{-\hat{a}_{k}\hat{a}_{l}}{N}=-\frac{H_{k}H_{l}}{N^{3}}\label{eq:histogram_estimation_covariance}\\
\text{Corr}\left[\hat{a}_{k},\hat{a}_{l}\right] & =\frac{\text{Cov}\left[\hat{a}_{k},\hat{a}_{l}\right]}{\sqrt{\text{Var}\left[\hat{a}_{k}\right]\cdot\text{Var}\left[\hat{a}_{l}\right]}}=\frac{\frac{-\hat{a}_{k}\hat{a}_{l}}{N}}{\sqrt{\frac{\hat{a}_{k}(1-\hat{a}_{k})}{N}\frac{\hat{a}_{l}(1-\hat{a}_{l})}{N}}}=-\sqrt{\frac{\hat{a}_{k}\hat{a}_{l}}{(1-\hat{a}_{k})(1-\hat{a}_{l})}}\label{eq:histogram_estimation_correlation}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
From this, we can conclude that two large histogram probabilities are
more strongly correlated than two small probabilities, which is
intuïtively clear due to the constraint \(\sum_{k=1}^{K}a_{k}=1\).


\subsubsection{Estimation from combining multiple simulation data sets}
\label{\detokenize{theory:estimation-from-combining-multiple-simulation-data-sets}}
\sphinxAtStartPar
In the previous section, we investigated the problem of estimating the
unkown parameters \(\vec{a}\) (and their error bar) figuring in the
probability density function \(p(q|\vec{a})\) from sampled data
coming from a single simulation which samples the unknown probability
density. However, in many cases a regular moleculare simulation cannot
access all relevant parts of phase space because of high barriers in
(free) energy separating various (meta)stable equilibrium states. In
that case, one can apply various so\sphinxhyphen{}called enhanced sampling techniques.
An example is given by umbrella sampling, which involves performing not
1, but multiple equilibrium simulations each with a different additional
bias potential aiming at enhancing the sampling in a certain region of
phase space. As a result, each simulation will not sample the original
probability density function, which we will now rename
\(p^{(0)}(q|\vec{a})\) for clarity, but the biased probability
density function. Consider a series of \(M\) simulations, where
simulation \(i\) is run with the bias potential \(W^{(i)}(q)\)
expressed in terms of the collective variable of interest. The biased
probability density of this simulation will be given by:
\begin{equation*}
\begin{split}p^{(i)}(q|\vec{a})=f_{i}(\vec{a})\cdot p^{(0)}(q|\vec{a})\cdot e^{-\beta W^{(i)}(q)}\end{split}
\end{equation*}
\sphinxAtStartPar
where
\begin{equation*}
\begin{split}\frac{1}{f_{i}(\vec{a})}=\int p^{(0)}(q|\vec{a})e^{-\beta W^{(i)}(q)}dq\end{split}
\end{equation*}
\sphinxAtStartPar
represents the normalisation factor for the biases probability density
of simulation \(i\) and depends on the unknown parameters
\(\vec{a}\) of the unbiased probability density. We now find
ourselves with a new hurdle. We have access to \(M\) simulations,
each delivering \(N_{i}\) samples
\(\left\{ q_{n_{i}}^{(i)}\right\} _{n_{i}=1}^{N_{i}}\) , generated
by a biases probability density \(p^{(i)}(q|\vec{a})\) all related
to the underlying unbiased probability density
\(p^{(0)}(q|\vec{a})\) we are interested in. The question we now
have to answer is: how can be combine samples
\(\left\{ q_{n_{i}}^{(i)}\right\} _{n_{i}=1}^{N_{i}}\) taken from
different probability densities \(p^{(i)}(q|\vec{a})\) to estimate a
common set of parameters \(\vec{a}\). We will tackle this question
in the remainder of this section. In section
{\hyperref[\detokenize{theory:subsec:Mixed-log-likelihood}]{\emph{{[}subsec:Mixed\sphinxhyphen{}log\sphinxhyphen{}likelihood{]}}}} we
introduce the weighted log\sphinxhyphen{}likelihood which is defined as the weighted
sum of the log\sphinxhyphen{}likelihood functions of each simulation indepedently.
This function will generate the MLE after maximalisation as an estimator
for the true parameters. In section
{\hyperref[\detokenize{theory:subsec:Covariance-of-MLE-mixedloglikelihood}]{\emph{{[}subsec:Covariance\sphinxhyphen{}of\sphinxhyphen{}MLE\sphinxhyphen{}mixedloglikelihood{]}}}}
we derive the corresponding covariance. Finally, in section
{\hyperref[\detokenize{theory:subsec:Example:-Multiple-histograms}]{\emph{{[}subsec:Example:\sphinxhyphen{}Multiple\sphinxhyphen{}histograms{]}}}}
we apply the theory to estimate the unbiased probability density using a
histogram estimator using input from multiple biased simulations as done
in umbrella sampling.


\paragraph{Weighted log\sphinxhyphen{}likelihood functions{[}subsec:Mixed\sphinxhyphen{}log\sphinxhyphen{}likelihood{]}}
\label{\detokenize{theory:weighted-log-likelihood-functions-subsec-mixed-log-likelihood}}
\sphinxAtStartPar
In section {\hyperref[\detokenize{theory:subsec:Likelihood-and-MLE}]{\emph{{[}subsec:Likelihood\sphinxhyphen{}and\sphinxhyphen{}MLE{]}}}}
we introduced the sample\sphinxhyphen{}average log\sphinxhyphen{}likelihood function \(l_{N}\)
of the random variable \(\log p(q|\vec{a})\) using the samples taken
from the simulation. However, as we now have \(M\) different
simulations, each with their own samples, we can define a sample\sphinxhyphen{}average
log\sphinxhyphen{}likelihood for each simulation:
\begin{equation*}
\begin{split}l_{N_{i}}^{(i)}(\vec{a})=\frac{1}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\log\left[p^{(i)}(q_{n_{i}}^{(i)}|\vec{a})\right]\end{split}
\end{equation*}
\sphinxAtStartPar
Similarly, we can also define a population\sphinxhyphen{}mean log\sphinxhyphen{}likelihood function
corresponding to each simulation:
\begin{equation*}
\begin{split}l^{(i)}(\vec{a})=E^{(i)}\left[\log p^{(i)}(q|\vec{a})\right]=\int_{-\infty}^{+\infty}\log p^{(i)}(q|\vec{a})\cdot p^{(i)}(q|\vec{a})dq\end{split}
\end{equation*}
\sphinxAtStartPar
in which \(E^{(i)}[\cdot]\) represents the true population mean in
simulation \(i\) (with its corresponding bias). As was discussed in
section {\hyperref[\detokenize{theory:subsec:Likelihood-and-MLE}]{\emph{{[}subsec:Likelihood\sphinxhyphen{}and\sphinxhyphen{}MLE{]}}}},
the law of large numbers implies:
\begin{equation*}
\begin{split}l_{N_{i}}^{(i)}(\vec{a})\xrightarrow{N_{i}\rightarrow+\infty}l^{(i)}(\vec{a})\end{split}
\end{equation*}
\sphinxAtStartPar
In order to be able to combine all simulation samples, we define the
weighted versions of both the sample average and population mean of the
log\sphinxhyphen{}likilihood as a weighted average of the simulation contributions:
\begin{equation*}
\begin{split}\begin{aligned}
l_{\vec{N}}(\vec{a}) & =\sum_{i=1}^{M}c_{i}l_{N_{i}}^{(i)}(\vec{a})=\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\log\left[p^{(i)}(q_{n_{i}}^{(i)}|\vec{a})\right]\\
l(\vec{a}) & =\sum_{i=1}^{M}c_{i}l^{(i)}(\vec{a})=\sum_{i=1}^{M}c_{i}E^{(i)}\left[\log p^{(i)}(q|\vec{a})\right]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Where we used the notation \(\vec{N}=(N_{1},N_{2},\ldots,N_{M})\).
The weights \(c_{i}\) will be determined later, for now they
represent positive real numbers that sum to \(1\) \sphinxstepexplicit %
\begin{footnote}[4]\phantomsection\label{\thesphinxscope.4}%
\sphinxAtStartFootnote
Both \(l_{\vec{N}}\) and \(l\) can be multiplied (or divided)
by a constant without any impact on its derived features such as the
MLE and its covariance. Therefore, we can see that the weights are
determined up to a constant factor which we choose such that the sum
of the weights equals 1.
%
\end{footnote}. Given the
fact that the true paramaters \(\vec{a}_{0}\) will result in the
true biased probability density \(p^{(i)}(q|\vec{a}_{0})\) for each
simulation \(i\), we can also state that these true parameters will
maximize the population\sphinxhyphen{}mean log\sphinxhyphen{}likelihood of each simulation
individually:
\begin{equation*}
\begin{split}\left.\frac{\partial}{\partial\vec{a}}l^{(i)}(\vec{a})\right|_{\vec{a}=\vec{a}_{0}}=0\end{split}
\end{equation*}
\sphinxAtStartPar
and hence the true parameters will also maximize the weighted
population\sphinxhyphen{}mean log\sphinxhyphen{}likelihood:
\begin{equation*}
\begin{split}\left.\frac{\partial}{\partial\vec{a}}l(\vec{a})\right|_{\vec{a}=\vec{a}_{0}}=0\label{eq:truepars_max_popmeanloglik}\end{split}
\end{equation*}
\sphinxAtStartPar
It is trivial to see that the law of large numbers again implies:
\begin{equation*}
\begin{split}l_{\vec{N}}(\vec{a})\xrightarrow{\vec{N}\rightarrow+\infty}l(\vec{a})\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\vec{N}\rightarrow+\infty\) is short for
\(\forall i:N_{i}\rightarrow+\infty\). We can now compute the
maximum likelihood estimator by maximizing \(l_{\vec{N}}(\vec{a})\):
\begin{equation*}
\begin{split}\begin{aligned}
\forall k & :\frac{\partial}{\partial a_{k}}l_{\vec{N}}(\vec{a})=0\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
its solution gives the MLE \(\hat{\vec{a}}\).


\paragraph{Covariance of the MLE for the weighted log\sphinxhyphen{}likelihood{[}subsec:Covariance\sphinxhyphen{}of\sphinxhyphen{}MLE\sphinxhyphen{}mixedloglikelihood{]}}
\label{\detokenize{theory:covariance-of-the-mle-for-the-weighted-log-likelihood-subsec-covariance-of-mle-mixedloglikelihood}}
\sphinxAtStartPar
In section
{\hyperref[\detokenize{theory:subsec:Asymptotic-normality}]{\emph{{[}subsec:Asymptotic\sphinxhyphen{}normality{]}}}} we
discussed how the covariance matrix of the MLE can be computed from the
Fisher matrix. Similarly as we did for the individual log\sphinxhyphen{}likelihood
functions in the previous section, we first define the Fisher matrices
for each simulation individually:
\begin{equation*}
\begin{split}\begin{aligned}
I_{kl}^{(i)} & =-E^{(i)}\left[\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\left(\log p^{(i)}(q|\vec{a}_{0}\right)\right]=-\frac{\partial^{2}}{\partial\vec{a}\partial\vec{a}}l(\vec{a}_{0})\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
The final question that remains now is: how do we combine the Fisher
matrices of the various simulations to obtain the covariance matrix on
the MLE derived from the weighted log\sphinxhyphen{}likelihood? For this purpose, we
start by recalling how we have proven prove the asymptotic normality of
the MLE in section
{\hyperref[\detokenize{theory:subsec:Asymptotic-normality}]{\emph{{[}subsec:Asymptotic\sphinxhyphen{}normality{]}}}}.
Therein, by using the Mean Value Theorem, we could derive the relation
as expressed by Eq. {\hyperref[\detokenize{theory:eq:asnorm_rel-1}]{\emph{{[}eq:asnorm\_rel\sphinxhyphen{}1{]}}}}:
\begin{equation*}
\begin{split}\frac{\partial^{2}}{\partial\vec{a}\partial\vec{a}}l_{N}(\vec{a}_{0})\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right)=-\frac{\partial}{\partial\vec{a}}l_{N}(\vec{a}_{0})\text{ as }N\rightarrow+\infty\end{split}
\end{equation*}
\sphinxAtStartPar
In the derivation of this relation, we used the fact that
\(\hat{\vec{a}}\) maximizes \(l_{N}(\vec{a})\) as the MLE. Here,
one has to be careful in the current situation of multiple simulations:
we do not know at this point if \(\hat{\vec{a}}\) maximizes each
\(l_{N_{i}}^{(i)}(\vec{a})\) individually. However,
\(\hat{\vec{a}}\) does maximize the weighted log\sphinxhyphen{}likelihood
\(l_{\vec{N}}(\vec{a})\), therefore we can write:
\begin{equation*}
\begin{split}\frac{\partial^{2}}{\partial\vec{a}\partial\vec{a}}l_{\vec{N}}(\vec{a}_{0})\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right)=-\frac{\partial}{\partial\vec{a}}l_{\vec{N}}(\vec{a}_{0})\text{ as }\vec{N}\rightarrow+\infty\end{split}
\end{equation*}
\sphinxAtStartPar
which we can now rewrite as:
\begin{equation*}
\begin{split}\begin{aligned}
\left[\frac{\partial^{2}}{\partial\vec{a}\partial\vec{a}}\left(\sum_{i=1}^{M}c_{i}l_{N_{i}}^{(i)}(\vec{a})\right)\right]\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right) & =-\frac{\partial}{\partial\vec{a}}\left(\sum_{i=1}^{M}c_{i}l_{N_{i}}^{(i)}(\vec{a})\right)\nonumber \\
\left[\sum_{i=1}^{M}c_{i}\left(\frac{\partial^{2}}{\partial\vec{a}\partial\vec{a}}l_{N_{i}}^{(i)}(\vec{a}_{0})\right)\right]\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right) & =-\sum_{i=1}^{M}c_{i}\left(\frac{\partial}{\partial\vec{a}}l_{N_{i}}^{(i)}(\vec{a}_{0})\right)\nonumber \\
\left[\sum_{i=1}^{M}c_{i}\bar{\bar{I}}^{(i)}\right]\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right) & =\sum_{i=1}^{M}c_{i}\left(\frac{\partial}{\partial\vec{a}}l_{N_{i}}^{(i)}(\vec{a}_{0})\right)\label{eq:CovMLE_mixed_rel0}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
If we now focus on the right\sphinxhyphen{}hand side, then we can rewrite this as:
\begin{equation*}
\begin{split}\begin{aligned}
\sum_{i=1}^{M}c_{i}\left(\frac{\partial}{\partial\vec{a}}l_{N_{i}}^{(i)}(\vec{a}_{0})\right) & =\sum_{i=1}^{M}c_{i}\left[\frac{1}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\frac{\partial}{\partial\vec{a}}\left(\log p^{(i)}(q_{n_{i}}^{(i)}|\vec{a}_{0}\right)\right]\nonumber \\
 & =\sum_{i=1}^{M}c_{i}\left[\frac{1}{N_{i}}\sum_{n_{i}=1}^{N_{i}}X_{n_{i}}^{(i)}\right]\nonumber \\
 & =\sum_{i=1}^{M}c_{i}\bar{X}^{(i)}\label{eq:CovMLE_mixed_rel1}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where we define the random variable \(X^{(i)}\), its samples
\(X_{n_{i}}^{(i)}\) and its sample average \(\bar{X}^{(i)}\) of
simulation \(i\) as follows:
\begin{equation*}
\begin{split}\begin{aligned}
X^{(i)} & =\frac{\partial}{\partial\vec{a}}\left(\log p^{(i)}(q|\vec{a}_{0}\right)\\
X_{n_{i}}^{(i)} & =\frac{\partial}{\partial\vec{a}}\left(\log p^{(i)}(q_{n_{i}}^{(i)}|\vec{a}_{0}\right)\\
\bar{X}^{(i)} & =\frac{1}{N_{i}}\sum_{n_{i}=1}^{N_{i}}X_{n_{i}}^{(i)}=\frac{1}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\frac{\partial}{\partial\vec{a}}\left(\log p^{(i)}(q_{n_{i}}^{(i)}|\vec{a}_{0}\right)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
Furthermore, we also know that the sample averages \(\bar{X}^{(i)}\)
satisfy:
\begin{equation*}
\begin{split}\begin{aligned}
\sum_{i=1}^{M}c_{i}\left(E^{(i)}\left[\bar{X}^{(i)}\right]\right) & =\sum_{i=1}^{M}c_{i}\left(E^{(i)}\left[X^{(i)}\right]\right)\\
 & =\sum_{i=1}^{M}c_{i}\left(E^{(i)}\left[\frac{\partial}{\partial\vec{a}}\left(\log p^{(i)}(q|\vec{a}_{0}\right)\right]\right)\\
 & =\sum_{i=1}^{M}c_{i}\left(\frac{\partial}{\partial\vec{a}}l^{(i)}(\vec{a}_{0})\right)\\
 & =\frac{\partial}{\partial\vec{a}}\left(\sum_{i=1}^{M}c_{i}l^{(i)}(\vec{a}_{0})\right)\\
 & =\frac{\partial}{\partial\vec{a}}l(\vec{a}_{0})\\
 & =0\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
where we remind the reader that the notation
\(\frac{\partial}{\partial x}f(x_{0})\) means we first take the
derivative of \(f\) towards \(x\) and then evaluate the
derivative in \(x=x_{0}\). Furthermore, in the last line we used the
fact that the true parameters \(\vec{a}_{0}\) maximize the weighted
population\sphinxhyphen{}mean log\sphinxhyphen{}likelihood (see Eq.
{\hyperref[\detokenize{theory:eq:truepars_max_popmeanloglik}]{\emph{{[}eq:truepars\_max\_popmeanloglik{]}}}}).
This result can now be used to rewrite Eq.
{\hyperref[\detokenize{theory:eq:CovMLE_mixed_rel1}]{\emph{{[}eq:CovMLE\_mixed\_rel1{]}}}} as:
\begin{equation*}
\begin{split}\begin{aligned}
\sum_{i=1}^{M}c_{i}\left(\frac{\partial}{\partial\vec{a}}l_{N_{i}}^{(i)}(\vec{a}_{0})\right) & =\sum_{i=1}^{M}c_{i}\bar{X}^{(i)}-\sum_{i=1}^{M}c_{i}\left(E^{(i)}\left[\bar{X}^{(i)}\right]\right)\\
 & =\sum_{i=1}^{M}c_{i}\left(\bar{X}^{(i)}-E^{(i)}\left[\bar{X}^{(i)}\right]\right)\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
As was discussed earlier (see Eq.
{\hyperref[\detokenize{theory:eq:asnorm_rel2}]{\emph{{[}eq:asnorm\_rel2{]}}}}), the central limit theorem
implies for each simulation seperately:
\begin{equation*}
\begin{split}\bar{X}^{(i)}-E^{(i)}\left[\bar{X}^{(i)}\right]\xrightarrow{N_{i}\rightarrow+\infty}\mathcal{N}\left(0,\frac{\bar{\bar{I}}^{(i)}}{N_{i}}\right)\label{eq:CovMLE_mixed_rel2}\end{split}
\end{equation*}
\sphinxAtStartPar
If we now put Eqs. {\hyperref[\detokenize{theory:eq:CovMLE_mixed_rel0}]{\emph{{[}eq:CovMLE\_mixed\_rel0{]}}}},
{\hyperref[\detokenize{theory:eq:CovMLE_mixed_rel1}]{\emph{{[}eq:CovMLE\_mixed\_rel1{]}}}} and
{\hyperref[\detokenize{theory:eq:CovMLE_mixed_rel2}]{\emph{{[}eq:CovMLE\_mixed\_rel2{]}}}} together, we arrive
at:
\begin{equation*}
\begin{split}\left[\sum_{i=1}^{M}c_{i}\bar{\bar{I}}^{(i)}\right]\cdot\left(\hat{\vec{a}}-\vec{a}_{0}\right)=\sum_{i=1}^{M}c_{i}\left(\bar{X}^{(i)}-E^{(i)}\left[\bar{X}^{(i)}\right]\right)\xrightarrow{\vec{N}\rightarrow+\infty}\sum_{i=1}^{M}c_{i}\cdot\mathcal{N}\left(0,\frac{\bar{\bar{I}}^{(i)}}{N_{i}}\right)=\mathcal{N}\left(0,\sum_{i=1}^{M}\frac{c_{i}^{2}}{N_{i}}\bar{\bar{I}}^{(i)}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
or equivalently with covariance matrix \(\bar{\bar{\sigma}}\):
\begin{equation*}
\begin{split}\begin{aligned}
\hat{\vec{a}} & \xrightarrow{\vec{N}\rightarrow+\infty}\mathcal{N}\left(\vec{a}_{0},\bar{\bar{\sigma}}\right)\nonumber \\
\bar{\bar{\sigma}} & =\left[\sum_{i=1}^{M}c_{i}\bar{\bar{I}}^{(i)}\right]^{-2}\cdot\left[\sum_{i=1}^{M}\frac{c_{i}^{2}}{N_{i}}\bar{\bar{I}}^{(i)}\right]\label{eq:covariance_MLE_multiplesims}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
At this point, it is interesting to discuss the impact of the weights
\(c_{i}\). The covariance of the MLE clearly depends on the choice
of the weights \sphinxstepexplicit %
\begin{footnote}[5]\phantomsection\label{\thesphinxscope.5}%
\sphinxAtStartFootnote
However, it can easily be seen that multiplying each weight with the
same factor does not influence the covariance. Hence, we choose this
factor so that the sum of the weights is \(1\) as was already
discussed earlier.
%
\end{footnote} . To illustrate this depende, we consider a few
limiting cases:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(c_{i}=\delta_{i,j}\), corresponding to the situation we
actually only consider a single simulation, that is simulation
\(j\). In this case the covariance becomes:
\begin{equation*}
\begin{split}\bar{\bar{\sigma}}=\left[\bar{\bar{I}}^{(j)}\right]^{-2}\cdot\left[\frac{1}{N_{j}}\bar{\bar{I}}^{(j)}\right]=\left[N_{j}\bar{\bar{I}}^{(j)}\right]^{-1}\end{split}
\end{equation*}
\sphinxAtStartPar
corresponding indeed to the previous results of section
{\hyperref[\detokenize{theory:subsec:Asymptotic-normality}]{\emph{{[}subsec:Asymptotic\sphinxhyphen{}normality{]}}}}.

\item {} 
\sphinxAtStartPar
\(c_{i}=\frac{1}{M}\), corresponding to the same weight given to
each simulation. The covariance matrix becomes:
\begin{equation*}
\begin{split}\bar{\bar{\sigma}}=\left[\sum_{i=1}^{M}\bar{\bar{I}}^{(i)}\right]^{-2}\cdot\left[\sum_{i=1}^{M}\frac{1}{N_{i}}\bar{\bar{I}}^{(i)}\right]\end{split}
\end{equation*}
\sphinxAtStartPar
If the number of steps in one particular simulation would approach
zero, say \(N_{j}\rightarrow\)0, we found that
\(\bar{\bar{\sigma}}\) would be predominantly determined by the
Fisher matrix of that simulation and moreover, the covariance would
approach infinity. This is offcourse something we want to avoid at
all cost, hence setting all weights equal is not a good idea.

\item {} 
\sphinxAtStartPar
\(c_{i}=\frac{N_{i}}{N}\) with \(N=\sum_{i}N_{i}\) the
accumulated number of simulation steps. This choice corresponds to
giving a weight proportional to the size of the simulation, i.e. its
number of simulation steps. This makes sens \sphinxstyleemphasis{a priori} as larger
simulations generally mean more information. The resulting covariance
matrix for this choice takes on a much more simple form:
\begin{equation*}
\begin{split}\begin{aligned}
\bar{\bar{\sigma}} & =\left[\sum_{i=1}^{M}\frac{N_{i}}{N}\bar{\bar{I}}^{(i)}\right]^{-2}\cdot\left[\sum_{i=1}^{M}\frac{N_{i}}{N^{2}}\bar{\bar{I}}^{(i)}\right]\\
 & =\left[\sum_{i=1}^{M}N_{i}\bar{\bar{I}}^{(i)}\right]^{-2}\cdot\left[\sum_{i=1}^{M}N_{i}\bar{\bar{I}}^{(i)}\right]\\
 & =\left[\sum_{i=1}^{M}N_{i}\bar{\bar{I}}^{(i)}\right]^{-1}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
This expression is makes much sense as it represents the inverse of
the accumulated information, giving larger weight to larger
simulations. Furthermore, if one simulation approaches zero in size
(\(N_{j}\rightarrow\)0 ), its contribution simply drops out.
Furthermore, it can be proven that this choice of weights minimizes
the variance, i.e. diagonal covariance matrix elements, and hence
error on each parameters {[} \sphinxstepexplicit %
\begin{footnote}[6]\phantomsection\label{\thesphinxscope.6}%
\sphinxAtStartFootnote
I have not proven this (yet), but as this choice of weights
corresponds to WHAM (see Example 3 in next section) and WHAM is known
to correspond to the choice of weights that minimizes tha variance,
this makes sense.
%
\end{footnote}{]}.

\end{enumerate}


\paragraph{Example 3 \sphinxhyphen{} Multiple histograms from umbrella sampling{[}subsec:Example:\sphinxhyphen{}Multiple\sphinxhyphen{}histograms{]}}
\label{\detokenize{theory:example-3-multiple-histograms-from-umbrella-sampling-subsec-example-multiple-histograms}}
\sphinxAtStartPar
In this section, we apply the relations derived in the previous sections
to estimate the optimal histogram\sphinxhyphen{}based probability density function
using samples taken from various biased simulations. The proposed model
for the unbiased probability density is identical as in section
{\hyperref[\detokenize{theory:subsec:Example2-single-histogram}]{\emph{{[}subsec:Example2\sphinxhyphen{}single\sphinxhyphen{}histogram{]}}}}:
\begin{equation*}
\begin{split}p^{(0)}(q|\vec{a})=\sum_{k=1}^{K}a_{k}\phi_{k}(q)\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\phi_{k}\) represents a function corresponding to the bin
centered around value \(Q_{k}\):
\begin{equation*}
\begin{split}\phi_{k}(q)=\begin{cases}
\frac{1}{\Delta} & q\in[Q_{k}-\frac{\Delta}{2},Q_{k}+\frac{\Delta}{2}]\\
0 & elsewhere
\end{cases}\end{split}
\end{equation*}
\sphinxAtStartPar
with \(\Delta\) an a priori chosen bin width and \(Q_{k}\) the a
priori chosen bin centers. Note that each bin function \(\phi_{k}\)
is normalized to \(1\). Hence, since the probability density
function also needs to be normalized, we require:
\begin{equation*}
\begin{split}\sum_{k=1}^{K}a_{k}=1\end{split}
\end{equation*}
\sphinxAtStartPar
which we will address using Lagrange multipliers. The biased probability
density of simulation \(i\) will be given by:
\begin{equation*}
\begin{split}p^{(i)}(q|\vec{a})=f_{i}(\vec{a})\cdot p^{(0)}(q|\vec{a})\cdot e^{-\beta W^{(i)}(q)}\end{split}
\end{equation*}
\sphinxAtStartPar
where we can now compute the normalisation factors:
\begin{equation*}
\begin{split}\begin{aligned}
\frac{1}{f_{i}(\vec{a})} & =\int p^{(0)}(q|\vec{a})e^{-\beta W^{(i)}(q)}dq\\
 & =\sum_{k=1}^{K}a_{k}\int_{-\infty}^{+\infty}\phi_{k}(q)e^{-\beta W^{(i)}(q)}dq\\
 & =\sum_{k=1}^{K}a_{k}\underbrace{\frac{1}{\Delta}\int_{Q_{k}-\frac{\Delta}{2}}^{Q_{k}+\frac{\Delta}{2}}e^{-\beta W^{(i)}(q)}dq}_{\triangleq b_{ik}}\\
\frac{1}{f_{i}(\vec{a})} & =\sum_{k=1}^{K}b_{ik}a_{k}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
and where we introduced the overlap \(b_{ik}\) of the bias in
simulation \(i\) with bin \(k\). In order to compute the MLE, we
construct the mixed sample\sphinxhyphen{}average log\sphinxhyphen{}likelihood function:
\begin{equation*}
\begin{split}\begin{aligned}
l_{\vec{N}}(\vec{a}) & =\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\log p^{(i)}(q_{n_{i}}^{(i)}|\vec{a})\\
 & =\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\left[\log p^{(0)}(q_{n_{i}}^{(i)}|\vec{a})+\log f_{i}(\vec{a})-\beta W^{(i)}(q_{n_{i}}^{(i)})\right]\\
 & =\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\left[\log\left(\sum_{k=1}^{K}a_{k}\phi_{k}(q_{n_{i}}^{(i)})\right)-\log\left(\sum_{k=1}^{K}b_{ik}a_{k}\right)-\beta W^{(i)}(q_{n_{i}}^{(i)})\right]\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
This function needs to be maximized with respect to the parameters
\(\vec{a}\) under the constraint \(\sum_{k=1}^{K}a_{k}=1\).
Since the last term in the equation above, i.e. the contribution of the
bias, does not depend on the parameters, we can ommit it when doing the
maximization. The constraint is implemented using Lagrange multipliers:
\begin{equation*}
\begin{split}\begin{aligned}
\forall s & :\frac{\partial}{\partial a_{k}}\left(\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\left[\log\left(\sum_{s=1}^{K}a_{s}\phi_{s}(q_{n_{i}}^{(i)})\right)-\log\left(\sum_{s=1}^{K}b_{is}a_{s}\right)\right]+\mu\left[1-\sum_{s=1}^{K}a_{s}\right]\right)=0\\
 & \sum_{s=1}^{K}a_{s}=1\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
We now proceed by rewriting the first set of equations:
\begin{equation*}
\begin{split}\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\sum_{n_{i}=1}^{N_{i}}\left[\frac{\phi_{k}(q_{n_{i}}^{(i)})}{\sum_{s=1}^{K}a_{s}\phi_{s}(q_{n_{i}}^{(i)})}-\frac{b_{ik}}{\sum_{s=1}^{K}b_{is}a_{s}}\right]-\mu=0\end{split}
\end{equation*}
\sphinxAtStartPar
Since \(\phi_{k}(q_{n_{i}}^{(i)})\) is only non\sphinxhyphen{}zero if
\(q_{n_{i}}^{(i)}\in[Q_{k}-\frac{\Delta}{2},Q_{k}+\frac{\Delta}{2}]\),
we introduce \(k_{n_{i}}^{(i)}\) which represents the bin
\(k\)\sphinxhyphen{}value for which the corresponding bin contains
\(q_{n_{i}}^{(i)}\). We can rewrite the above equation as:
\begin{equation*}
\begin{split}\begin{aligned}
\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\left[\sum_{n_{i}=1}^{N_{i}}\frac{\delta_{k,k_{n_{i}}^{(i)}}/\Delta}{\sum_{s=1}^{K}a_{s}\delta_{s,k_{n_{i}}^{(i)}}/\Delta}-N_{i}\frac{b_{ik}}{\sum_{s=1}^{K}b_{is}a_{s}}\right] & =\mu\\
\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\left[\sum_{n_{i}=1}^{N_{i}}\frac{\delta_{k,k_{n_{i}}^{(i)}}}{a_{k_{n_{i}}^{(i)}}}-N_{i}\frac{b_{ik}}{\sum_{s=1}^{K}b_{is}a_{s}}\right] & =\mu\\
\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\left[\frac{1}{a_{k}}\sum_{n_{i}=1}^{N_{i}}\delta_{k,k_{n_{i}}^{(i)}}-N_{i}\frac{b_{ik}}{\sum_{s=1}^{K}b_{is}a_{s}}\right] & =\mu\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
We define \(H_{ik}\) as the histogram count in bin \(k\) from
simulation \(i\):
\begin{equation*}
\begin{split}H_{ik}=\sum_{n_{i}=1}^{N_{i}}\delta_{k,k_{n_{i}}^{(i)}}\end{split}
\end{equation*}
\sphinxAtStartPar
which allows us to further rewrite the expression as:
\begin{equation*}
\begin{split}\frac{1}{a_{k}}\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}H_{ik}-\sum_{i=1}^{M}c_{i}\frac{b_{ik}}{\sum_{s=1}^{K}b_{is}a_{s}}=\mu\label{eq:ex3_rel1}\end{split}
\end{equation*}
\sphinxAtStartPar
We now first proceed by computing the value of the lagrange multiplier
\(\mu\), which we do by multiplying both sides of the above equation
by \(a_{k}\) a,d summing over \(k\):
\begin{equation*}
\begin{split}\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}\sum_{k=1}^{K}H_{ik}-\sum_{i=1}^{M}c_{i}\frac{\sum_{k=1}^{K}b_{ik}a_{k}}{\sum_{s=1}^{K}b_{is}a_{s}}=\mu\sum_{k=1}^{K}a_{k}\end{split}
\end{equation*}
\sphinxAtStartPar
Taking into account the constraint \(\sum_{k=1}^{K}a_{k}=1\) as well
as the relation \(\sum_{k=1}^{K}H_{ik}=N_{i}\) (i.e. the total
histogram count in simulation \(i\) equals the number of simulation
steps), we find:
\begin{equation*}
\begin{split}\sum_{i=1}^{M}c_{i}-\sum_{i=1}^{M}c_{i}=\mu\end{split}
\end{equation*}
\sphinxAtStartPar
In other words: \(\hat{\mu}=0\). Substituting this result in Eq.
{\hyperref[\detokenize{theory:eq:ex3_rel1}]{\emph{{[}eq:ex3\_rel1{]}}}} we find the MLE estimator for the
parameters:
\begin{equation*}
\begin{split}\hat{a}_{k}=\frac{\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}H_{ik}}{\sum_{i=1}^{M}c_{i}\frac{b_{ik}}{\sum_{s=1}^{K}b_{is}a_{s}}}\end{split}
\end{equation*}
\sphinxAtStartPar
which we rewrite using the definition of the normalisation factors
\(f_{i}\):
\begin{equation*}
\begin{split}\begin{aligned}
\hat{a}_{k} & =\frac{\sum_{i=1}^{M}\frac{c_{i}}{N_{i}}H_{ik}}{\sum_{i=1}^{M}c_{i}f_{i}b_{ik}}\\
f_{i}^{-1} & =\sum_{k=1}^{K}b_{ik}\hat{a}_{k}\end{aligned}\end{split}
\end{equation*}
\sphinxAtStartPar
These two coupled equations need to be solved iteratively to obtain the MLE estimator. As we recall from Section {\hyperref[\detokenize{theory:subsec:Covariance-of-MLE-mixedloglikelihood}]{\emph{{[}subsec:Covariance\sphinxhyphen{}of\sphinxhyphen{}MLE\sphinxhyphen{}mixedloglikelihood{]}}}} an optimal choice of the weight factors was given by \(c_{i}=\frac{N_{i}}{N}\), which results in:
\begin{equation}\label{equation:theory:ex3_WHAM_eq2}
\begin{split}\begin{aligned}
\hat{a}_{k} & =\frac{\sum_{i=1}^{M}H_{ik}}{\sum_{i=1}^{M}N_{i}f_{i}b_{ik}}\\
f_{i}^{-1} & =\sum_{k=1}^{K}b_{ik}\hat{a}_{k}\end{aligned}\end{split}
\end{equation}
\sphinxAtStartPar
These equations represent the WHAM (i.e. Weighted\sphinxhyphen{}Histogram Analysis
Method) equations. Finally, we also compute the covariance matrix of the
MLE. Therefore, we first compute the Fisher matrix for each biases
simulation separately:
\begin{equation*}
\begin{split}\bar{\bar{I}}^{(i)}=\begin{bmatrix}\bar{\bar{I}}^{(i),(aa)} & \bar{1}\\
\bar{1}^{T} & 0
\end{bmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
where we already applied the block matrix structure resulting from the
Lagrange multiplier \(\mu\) for the applied constraint
\(\sum_{k=1}^{K}a_{k}=1\) as was discussed in section
{\hyperref[\detokenize{theory:subsec:Example2-single-histogram}]{\emph{{[}subsec:Example2\sphinxhyphen{}single\sphinxhyphen{}histogram{]}}}}
with \(\bar{1}\) a \(K\)\sphinxhyphen{}dimensional column matrix with only
ones. The matrix elements of the \(aa\)\sphinxhyphen{}block corresponding to the
paramaters \(\vec{a}\) can be computed as follows:
\begin{equation*}
\begin{split}\begin{aligned}
I_{kl}^{(i),(aa)} & =-E^{(i)}\left[\frac{\partial^{2}}{\partial a_{k}\partial a_{l}}\log p^{(i)}(q|\vec{a})\right]\\
 & =-E^{(i)}\left[\frac{\partial}{\partial a_{k}}\left(\frac{\phi_{l}(q)}{\sum_{s=1}^{K}a_{s}\phi_{s}(q)}-\frac{b_{il}}{\sum_{s=1}^{K}b_{is}a_{s}}-\mu\right)\right]\\
 & =E^{(i)}\left[\frac{\phi_{k}(q)\phi_{l}(q)}{\left[\sum_{s=1}^{K}a_{s}\phi_{s}(q)\right]^{2}}-\frac{b_{ik}b_{il}}{\left[\sum_{s=1}^{K}b_{is}a_{s}\right]^{2}}\right]\\
 & =\int_{-\infty}^{+\infty}\frac{\phi_{k}(q)\phi_{l}(q)}{\left[\sum_{s=1}^{K}a_{s}\phi_{s}(q)\right]^{2}}p^{(i)}(q|\vec{a})dq-\frac{b_{ik}b_{il}}{\left[\sum_{s=1}^{K}b_{is}a_{s}\right]^{2}}\\
 & =\int_{-\infty}^{+\infty}\frac{\phi_{k}(q)\phi_{l}(q)}{\left[\sum_{s=1}^{K}a_{s}\phi_{s}(q)\right]^{2}}f_{i}\left(\sum_{s=1}^{K}a_{s}\phi_{s}(q)\right)e^{-\beta U^{(i)}(q)}dq-\frac{b_{ik}b_{il}}{\left[\sum_{s=1}^{K}b_{is}a_{s}\right]^{2}}\\
 & =f_{i}\int_{-\infty}^{+\infty}\frac{\phi_{k}(q)\phi_{l}(q)}{\sum_{s=1}^{K}a_{s}\phi_{s}(q)}e^{-\beta U^{(i)}(q)}dq-f_{i}^{2}b_{ik}b_{il}\\
 & =f_{i}\int_{Q_{k}-\frac{\Delta}{2}}^{Q_{k}+\frac{\Delta}{2}}\frac{\frac{1}{\Delta}\frac{\delta_{kl}}{\Delta}}{\frac{a_{k}}{\Delta}}e^{-\beta U^{(i)}(q)}dq-f_{i}^{2}b_{ik}b_{il}\\
 & =f_{i}\frac{\delta_{kl}}{a_{k}}\frac{1}{\Delta}\int_{Q_{k}-\frac{\Delta}{2}}^{Q_{k}+\frac{\Delta}{2}}e^{-\beta U^{(i)}(q)}dq-f_{i}^{2}b_{ik}b_{il}\\
I_{kl}^{(i),(aa)} & =\frac{f_{i}b_{ik}}{a_{k}}\delta_{kl}-f_{i}^{2}b_{ik}b_{il}\end{aligned}\end{split}
\end{equation*}

\chapter{Contact}
\label{\detokenize{index:contact}}
\sphinxAtStartPar
For support and bug reports, please contact us at \sphinxhref{mailto:louis.vanduyfhuys@ugent.be}{louis.vanduyfhuys@ugent.be}.


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{t}
\item\relax\sphinxstyleindexentry{thermolib.kinetics.rate}\sphinxstyleindexpageref{rg:\detokenize{module-thermolib.kinetics.rate}}
\item\relax\sphinxstyleindexentry{thermolib.thermodynamics.bias}\sphinxstyleindexpageref{rg:\detokenize{module-thermolib.thermodynamics.bias}}
\item\relax\sphinxstyleindexentry{thermolib.thermodynamics.condprob}\sphinxstyleindexpageref{rg:\detokenize{module-thermolib.thermodynamics.condprob}}
\item\relax\sphinxstyleindexentry{thermolib.thermodynamics.cv}\sphinxstyleindexpageref{rg:\detokenize{module-thermolib.thermodynamics.cv}}
\item\relax\sphinxstyleindexentry{thermolib.tools}\sphinxstyleindexpageref{rg:\detokenize{module-thermolib.tools}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}